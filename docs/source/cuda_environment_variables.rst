.. _cuda_environment_variables:

متغيرات بيئة CUDA
================
لمزيد من المعلومات حول متغيرات بيئة وقت تشغيل CUDA، راجع `متغيرات بيئة CUDA <https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars>`_.

**متغيرات بيئة PyTorch**

.. list-table::
  :header-rows: 1

  * - المتغير
    - الوصف
  * - ``PYTORCH_NO_CUDA_MEMORY_CACHING``
    - إذا تم تعيينه على ``1``، فإنه يعطل ذاكرة التخزين المؤقت للتعيينات في CUDA. يمكن أن يكون هذا مفيدًا للتصحيح.
  * - ``PYTORCH_CUDA_ALLOC_CONF``
    - للحصول على شرح أكثر تفصيلاً لهذا المتغير البيئي، راجع :ref:`cuda-memory-management`.
  * - ``PYTORCH_NVML_BASED_CUDA_CHECK``
    - إذا تم تعيينه على ``1``، وقبل استيراد وحدات PyTorch التي تتحقق مما إذا كانت CUDA متاحة، ستستخدم PyTorch NVML للتحقق مما إذا كان برنامج تشغيل CUDA يعمل بدلاً من استخدام وقت تشغيل CUDA. قد يكون هذا مفيدًا إذا فشلت العمليات المتفرعة مع خطأ تهيئة CUDA.
  * - ``TORCH_CUDNN_V8_API_LRU_CACHE_LIMIT``
    - حد التخزين المؤقت لـ واجهة برمجة تطبيقات cuDNN v8. يستخدم هذا للحد من الذاكرة التي تستخدمها واجهة برمجة تطبيقات cuDNN v8. القيمة الافتراضية هي 10000، والتي تقابل تقريبًا 2 جيجابايت بافتراض 200 كيلوبايت لكل ExecutionPlan. قم بالتعيين إلى ``0`` لعدم وجود حد أو قيمة سالبة لعدم التخزين المؤقت.
  * - ``TORCH_CUDNN_V8_API_DISABLED``
    - إذا تم تعيينه على ``1``، فإنه يعطل واجهة برمجة تطبيقات cuDNN v8. وسيتم الرجوع إلى واجهة برمجة تطبيقات cuDNN v7.
  * - ``TORCH_ALLOW_TF32_CUBLAS_OVERRIDE``
    - إذا تم تعيينه على ``1``، فإنه يجبر على تمكين TF32، متجاوزًا إعداد ``set_float32_matmul_precision``.
  * - ``TORCH_NCCL_USE_COMM_NONBLOCKING``
    - إذا تم تعيينه على ``1``، فإنه يمكّن التعامل مع الأخطاء غير المتزامنة في NCCL.
  * - ``TORCH_NCCL_AVOID_RECORD_STREAMS``
    - إذا تم تعيينه على ``0``، فإنه يمكّن التراجع إلى سلوك المزامنة القائم على تدفقات التسجيل في NCCL.
  * - ``TORCH_CUDNN_V8_API_DEBUG``
    - إذا تم تعيينه على ``1``، فإنه يتحقق من سلامة ما إذا كانت cuDNN V8 قيد الاستخدام.

**متغيرات بيئة وقت تشغيل CUDA والمكتبات**

.. list-table::
  :header-rows: 1

  * - المتغير
    - الوصف
  * - ``CUDA_VISIBLE_DEVICES``
    - قائمة مفصولة بفواصل لأجهزة GPU التي يجب أن تكون متاحة لوقت تشغيل CUDA. إذا تم تعيينه على ``-1``، فلن تكون أي من وحدات معالجة الرسوميات (GPU) متاحة.
  * - ``CUDA_LAUNCH_BLOCKING``
    - إذا تم تعيينه على ``1``، فإنه يجعل مكالمات CUDA متزامنة. يمكن أن يكون هذا مفيدًا للتصحيح.
  * - ``CUBLAS_WORKSPACE_CONFIG``
    - يستخدم هذا المتغير البيئي لتعيين تكوين مساحة العمل لـ cuBLAS لكل تخصيص. التنسيق هو ``:[SIZE]:[COUNT]``.
      على سبيل المثال، حجم مساحة العمل الافتراضي لكل تخصيص هو ``CUBLAS_WORKSPACE_CONFIG=:4096:2:16:8`` والذي يحدد حجمًا إجماليًا يبلغ ``2 * 4096 + 8 * 16 KiB``.
      لإجبار cuBLAS على تجنب استخدام مساحات العمل، قم بتعيين ``CUBLAS_WORKSPACE_CONFIG=:0:0``.
  * - ``CUDNN_CONV_WSCAP_DBG``
    - مشابه لـ ``CUBLAS_WORKSPACE_CONFIG``، يستخدم هذا المتغير البيئي لتعيين تكوين مساحة العمل لـ cuDNN لكل تخصيص.
  * - ``CUBLASLT_WORKSPACE_SIZE``
    - مشابه لـ ``CUBLAS_WORKSPACE_CONFIG``، يستخدم هذا المتغير البيئي لتعيين حجم مساحة العمل لـ cuBLASLT.
  * - ``CUDNN_ERRATA_JSON_FILE``
    - يمكن تعيينه إلى مسار ملف لمرشح errata الذي يمكن تمريره إلى cuDNN لتجنب تكوينات المحرك المحددة، ويستخدم بشكل أساسي للتصحيح أو للترميز اليدوي لضبط الضبط التلقائي.
  * - ``NVIDIA_TF32_OVERRIDE``
    - إذا تم تعيينه على ``0``، فإنه يعطل TF32 عالميًا عبر جميع النواة، متجاوزًا جميع إعدادات PyTorch.