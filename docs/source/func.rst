torch.func
==========

.. currentmodule:: torch.func

torch.func، المعروف سابقًا باسم "functorch"، هو
`JAX-like <https://github.com/google/jax>`_ قابل للتركيب تحويلات الدوال لبايثون.

.. note::
   هذه المكتبة حاليا في مرحلة `beta <https://pytorch.org/blog/pytorch-feature-classification-changes/#beta>`_.
   ما يعنيه هذا هو أن الميزات تعمل بشكل عام (ما لم يتم توثيقها بشكل آخر)
   ونحن (فريق PyTorch) ملتزمون بتطوير هذه المكتبة. ومع ذلك، قد تتغير واجهات برمجة التطبيقات
   بناءً على تعليقات المستخدمين ولا يوجد لدينا تغطية كاملة لعمليات PyTorch.

   إذا كان لديك أي اقتراحات حول واجهة برمجة التطبيقات أو حالات الاستخدام التي تود تغطيتها، يرجى
   فتح مشكلة على GitHub أو التواصل معنا. نود أن نعرف كيف تستخدم المكتبة.

ما هي تحويلات الدوال القابلة للتركيب؟
----------------------------

- "تحويل الدالة" هو دالة من الدرجة العليا تقبل دالة رقمية
  ويعيد دالة جديدة تقوم بحساب كمية مختلفة.

- :mod:`torch.func` لديه تحويلات تفاضلية تلقائية (``grad(f)`` يعيد دالة تقوم بحساب تدرج ``f``)،
  تحويل التجهيز/الدفعات (``vmap(f)`` يعيد دالة تقوم بحساب ``f`` على دفعات من المدخلات)، وغيرها.

- يمكن لهذه الدوال القابلة للتحويل أن تتركب مع بعضها البعض بشكل تعسفي. على سبيل المثال،
  يقوم تكوين ``vmap(grad(f))`` بحساب كمية تسمى per-sample-gradients
  لا يمكن لبايثون الأسهم حسابها بكفاءة اليوم.

لماذا تحويلات الدوال القابلة للتركيب؟
-----------------------

هناك عدد من حالات الاستخدام التي يصعب تنفيذها في PyTorch اليوم:

- حساب التدرجات لكل عينة (أو كميات أخرى لكل عينة)
- تشغيل مجموعات من النماذج على آلة واحدة
- دمج المهام بكفاءة في الحلقة الداخلية لـ MAML
- حساب المصفوفات والمصفوفات المتقابلة بكفاءة
- حساب المصفوفات المصفوفة والمصفوفات المتقابلة بكفاءة

تكوين تحويلات :func:`vmap`، :func:`grad`، و:func:`vjp` يسمح لنا بالتعبير عن ما سبق دون تصميم نظام فرعي منفصل لكل منها.
جاءت فكرة تحويلات الدوال القابلة للتركيب هذه من `إطار عمل JAX <https://github.com/google/jax>`_.

اقرأ المزيد
---------

.. toctree::
   :maxdepth: 2

   func.whirlwind_tour
   func.api
   func.ux_limitations
   func.migrating