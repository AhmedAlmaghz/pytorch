أسئلة شائعة
==========================

يقوم النموذج الخاص بي بالإبلاغ عن "خطأ وقت التشغيل CUDA (2): نفاد الذاكرة"
-------------------------------------------------------

كما يوحي رسالة الخطأ، لقد نفدت الذاكرة على
وحدة معالجة الرسوميات (GPU). نظرًا لأننا غالبًا ما نتعامل مع كميات كبيرة من البيانات في PyTorch،
يمكن للأخطاء الصغيرة أن تتسبب بسرعة في استخدام برنامجك لجميع
وحدة معالجة الرسوميات (GPU)؛ لحسن الحظ، فإن الإصلاحات في هذه الحالات تكون غالبًا بسيطة.
فيما يلي بعض الأشياء الشائعة التي يجب التحقق منها:

**لا تتراكم التاريخ عبر حلقة التدريب الخاصة بك.**
بافتراضي، ستستمر الحسابات التي تتضمن متغيرات تتطلب تدرجات
في الاحتفاظ بالتاريخ. وهذا يعني أنه يجب عليك تجنب استخدام هذه
المتغيرات في الحسابات التي ستستمر بعد حلقات التدريب الخاصة بك،
على سبيل المثال، عند تتبع الإحصائيات. بدلاً من ذلك، يجب عليك فصل المتغير
أو الوصول إلى بياناته الأساسية.

في بعض الأحيان، قد لا يكون من الواضح عندما يمكن أن تحدث المتغيرات القابلة للاشتقاق.
خذ في الاعتبار حلقة التدريب التالية (مختصرة من `المصدر
<https://discuss.pytorch.org/t/high-memory-usage-while-training/162>`_):

.. code-block:: python

    total_loss = 0
    for i in range(10000):
        optimizer.zero_grad()
        output = model(input)
        loss = criterion(output)
        loss.backward()
        optimizer.step()
        total_loss += loss

هنا، ``total_loss`` تتراكم التاريخ عبر حلقة التدريب الخاصة بك، منذ
``loss`` هو متغير قابل للاشتقاق مع تاريخ autograd. يمكنك إصلاح هذا عن طريق
كتابة `total_loss += float(loss)` بدلاً من ذلك.

أمثلة أخرى على هذه المشكلة:
`1 <https://discuss.pytorch.org/t/resolved-gpu-out-of-memory-error-with-batch-size-1/3719>`_.

**لا تحتفظ بالموترات والمتغيرات التي لا تحتاجها.**
إذا قمت بتعيين موتر أو متغير إلى محلي، فلن يقوم Python
إلغاء تخصيص حتى يخرج المحلي عن النطاق. يمكنك تحرير
هذه الإشارة باستخدام ``del x``. وبالمثل، إذا قمت بتعيين
موتر أو متغير إلى متغير عضو كائن، فلن يتم إلغاء تخصيصه حتى
يخرج الكائن عن النطاق. ستحصل على
أفضل استخدام للذاكرة إذا لم تحتفظ بالمتغيرات المؤقتة
أنت لا تحتاج.

نطاقات المحليات يمكن أن تكون أكبر مما تتوقع.  على سبيل المثال:

.. code-block:: python

    for i in range(5):
        intermediate = f(input[i])
        result += g(intermediate)
    output = h(result)
    return output

هنا، ``intermediate`` لا يزال نشطًا حتى أثناء تنفيذ ``h`` ،
لأن نطاقه يبرز بعد نهاية الحلقة. لإلغاء تخصيصه في وقت سابق، يجب عليك
``del intermediate`` عند الانتهاء منه.

**تجنب تشغيل RNNs على تسلسلات طويلة جدًا.**
كمية الذاكرة المطلوبة للانتشار الخلفي من خلال RNN تتناسب طرديًا مع
طول إدخال RNN؛ وبالتالي، ستنفد الذاكرة
إذا حاولت إطعام RNN تسلسلًا طويلًا جدًا.

المصطلح الفني لهذه الظاهرة هو `الانتشار الخلفي عبر الوقت
<https://en.wikipedia.org/wiki/Backpropagation_through_time>`_،
وهناك الكثير من المراجع حول كيفية تنفيذ BPTT المقطوع، بما في ذلك في `نموذج اللغة الكلمة <https://github.com/pytorch/examples/tree/master/word_language_model>`_ مثال؛ يتم التعامل مع الاقتصاص بواسطة
دالة ``repackage`` كما هو موصوف في
`هذه المشاركة في المنتدى <https://discuss.pytorch.org/t/help-clarifying-repackage-hidden-in-word-language-model/226>`_.

**لا تستخدم الطبقات الخطية الكبيرة جدًا.**
تستخدم الطبقة الخطية ``nn.Linear(m، n)`` :math:`O(nm)` الذاكرة: أي أن
متطلبات الذاكرة للأوزان
تتناسب تربيعيًا مع عدد الميزات. من السهل جدًا
`نفخ ذاكرتك <https://github.com/pytorch/pytorch/issues/958>`_
بهذه الطريقة (وتذكر أنك ستحتاج إلى ضعف حجم
الأوزان، لأنك تحتاج أيضًا إلى تخزين التدرجات.)

**ضع في اعتبارك نقاط التفتيش.**
يمكنك المقايضة بين الذاكرة والحوسبة باستخدام `النقطة المرجعية <https://pytorch.org/docs/stable/checkpoint.html>`_.

لا يتم تحرير ذاكرة GPU الخاصة بي بشكل صحيح
----------------------------------
يستخدم PyTorch مخصص ذاكرة التخزين المؤقت لتسريع عمليات تخصيص الذاكرة. نتيجة لذلك،
عادة ما لا تعكس القيم المعروضة في ``nvidia-smi`` استخدام الذاكرة الحقيقي. راجع :ref: `cuda-memory-management` لمزيد من التفاصيل حول إدارة ذاكرة GPU.

إذا لم يتم تحرير ذاكرة GPU الخاصة بك حتى بعد خروج Python، فمن المحتمل جدًا أن
بعض عمليات Python الفرعية لا تزال نشطة. يمكنك العثور عليها عبر
``ps -elf | grep python`` وقتلها يدويًا باستخدام ``kill -9 [pid]``.

لا يمكن لمعالج استثناء نفاد الذاكرة الخاص بي تخصيص الذاكرة
---------------------------------------------------
قد يكون لديك بعض التعليمات البرمجية التي تحاول التعافي من أخطاء نفاد الذاكرة.

.. code-block:: python

    try:
        run_model(batch_size)
    except RuntimeError: # Out of memory
        for _ in range(batch_size):
            run_model(1)

ولكنك تجد أنه عندما تنفد الذاكرة، لا يمكن لرمز الاسترداد الخاص بك تخصيص
أيضا. ويرجع ذلك إلى أن كائن الاستثناء Python يحتفظ بإشارة إلى
إطار المكدس حيث تم رفع الخطأ. مما يمنع كائنات tensor الأصلية من أن يتم تحريرها. الحل هو نقل رمز OOM الخاص بك خارج
عبارة ``except`` .

.. code-block:: python

    oom = False
    try:
        run_model(batch_size)
    except RuntimeError: # Out of memory
        oom = True

    if oom:
        for _ in range(batch_size):
            run_model(1)


.. _dataloader-workers-random-seed:

تعيد عمال محمل البيانات الخاص بي أرقامًا عشوائية متطابقة
-------------------------------------------------------
من المحتمل أنك تستخدم مكتبات أخرى لتوليد أرقام عشوائية في مجموعة البيانات
يتم بدء عمليات العامل الفرعي عبر ``fork``. راجع
توثيق :class: `torch.utils.data.DataLoader` لمعرفة كيفية
إعداد بذور الأرقام العشوائية بشكل صحيح في العاملين باستخدام خيارها: `worker_init_fn` .

.. _pack-rnn-unpack-with-data-parallelism:

لا تعمل شبكتي المتكررة مع الموازاة للبيانات
-------------------------------------------------------
هناك دقة في استخدام
نمط "حزم التسلسل -> الشبكة المتكررة -> فك حزم التسلسل" في
:class:`~torch.nn.Module` مع :class:`~torch.nn.DataParallel` أو
:func:`~torch.nn.parallel.data_parallel`. سيكون الإدخال إلى كل :meth: `forward` على
كل جهاز فقط جزءًا من الإدخال بالكامل. نظرًا لأن عملية فك الحزم :func: `torch.nn.utils.rnn.pad_packed_sequence` افتراضيًا لا تقوم بالوسادة إلا حتى
أطول إدخال تراه، أي الأطول على هذا الجهاز المحدد، سيحدث عدم تطابق في الحجم
عندما يتم تجميع النتائج معًا. لذلك، يمكنك
بدلاً من ذلك، استفد من حجة :attr: `total_length` من
:func:`~torch.nn.utils.rnn.pad_packed_sequence` للتأكد من أن
تعود مكالمات :meth: `forward` تسلسلات بنفس الطول. على سبيل المثال، يمكنك
اكتب::

    from torch.nn.utils.rnn import pack_padded_sequence، pad_packed_sequence

    class MyModule(nn.Module):
        # ... __init__، طرق أخرى، إلخ.

        # padded_input هو من الشكل [B x T x *] (وضع batch_first) ويحتوي على
        # التسلسلات التي تم فرزها حسب الأطوال
        # ب هو حجم الدفعة
        # ت هو طول التسلسل الأقصى
        def forward(self، padded_input، input_lengths):
            total_length = padded_input.size(1) # احصل على طول التسلسل الأقصى
            packed_input = pack_padded_sequence(padded_input، input_lengths،
                                                batch_first=True)
            packed_output، _ = self.my_lstm(packed_input)
            output، _ = pad_packed_sequence(packed_output، batch_first=True،
                                            total_length=total_length)
            return output


    m = MyModule().cuda()
    dp_m = nn.DataParallel(m)


بالإضافة إلى ذلك، يجب توخي مزيد من الحذر عندما يكون البعد الدفعي dim ``1``
(أي ``batch_first=False``) مع الموازاة للبيانات. في هذه الحالة، سيكون الحجة الأولى من ``padding_input``
من الشكل ``[T x B x *]`` ويجب أن يتم تفرقتها على طول dim ``1``، ولكن الحجة الثانية
``input_lengths`` سيكون من الشكل ``[B]`` ويجب أن يتم تفرقتها على طول dim
``0``. ستكون هناك حاجة إلى تعليمات برمجية إضافية للتلاعب بأشكال tensor.