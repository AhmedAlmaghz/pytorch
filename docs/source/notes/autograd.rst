.. _autograd-mechanics:

آلية حساب المشتقات التلقائي
=================
هذه الملاحظة ستقدم نظرة عامة على كيفية عمل Autograd وتسجيل العمليات. ليس من الضروري تمامًا فهم كل هذا، ولكننا نوصي بالتعرف عليه، حيث سيساعدك ذلك في كتابة برامج أكثر كفاءة ونظافة، ويمكن أن يساعدك في تصحيح الأخطاء.

كيف يقوم Autograd بتشفير التاريخ
----------------------------

Autograd هو نظام تفاضل تلقائي عكسي. من الناحية النظرية، يسجل Autograd رسمًا بيانيًا يسجل جميع العمليات التي أنشأت البيانات أثناء تنفيذ العمليات، مما يمنحك رسمًا بيانيًا موجّهًا غير دوري تكون أوراقه هي تنسيقات الإدخال وجذوره هي تنسيقات الإخراج. من خلال تتبع هذا الرسم البياني من الجذور إلى الأوراق، يمكنك تلقائيًا حساب المشتقات باستخدام قاعدة السلسلة.

داخليا، يمثل Autograd هذا الرسم البياني على أنه رسم بياني لـ :class:`Function` الكائنات (التعبيرات حقًا)، والتي يمكن :meth:`~torch.autograd.Function.apply` حسابه لحساب نتيجة تقييم الرسم البياني. عند إجراء عملية الحساب للأمام، يقوم Autograd في نفس الوقت بإجراء الحسابات المطلوبة وبناء رسم بياني يمثل الدالة التي تحسب المشتق (``.grad_fn`` الخاصية لكل فئة :class:`torch.Tensor` هي نقطة دخول إلى هذا الرسم البياني). عندما يتم الانتهاء من عملية الحساب للأمام، نقوم بتقييم هذا الرسم البياني في عملية الحساب للخلف لحساب المشتقات.

من المهم ملاحظة أن الرسم البياني يتم إعادة إنشائه من الصفر في كل تكرار، وهذا بالضبط ما يسمح باستخدام عبارات التحكم في تدفق Python التعسفي، والتي يمكن أن تغير الشكل والحجم الإجمالي للرسم البياني في كل تكرار. لا يتعين عليك تشفير جميع المسارات الممكنة قبل بدء التدريب - ما تقوم بتشغيله هو ما تقوم بالتفاضل عليه.

التنسيقات المحفوظة
^^^^^^^^^^^^^^^^

تحتاج بعض العمليات إلى نتائج وسيطة ليتم حفظها أثناء عملية الحساب للأمام من أجل تنفيذ عملية الحساب للخلف. على سبيل المثال، تقوم الدالة :math:`x\mapsto x^2` بحفظ الإدخال :math:`x` لحساب المشتق.

عند تحديد دالة Python مخصصة لـ :class:`~torch.autograd.Function`، يمكنك استخدام :func:`~torch.autograd.function._ContextMethodMixin.save_for_backward` لحفظ التنسيقات أثناء عملية الحساب للأمام و :attr:`~torch.autograd.function.Function.saved_tensors` لاسترجاعها أثناء عملية الحساب للخلف. راجع :doc:`/notes/extending` لمزيد من المعلومات.

بالنسبة للعمليات التي تحددها PyTorch (على سبيل المثال :func:`torch.pow`)، يتم حفظ التنسيقات تلقائيًا حسب الحاجة. يمكنك استكشاف (لأغراض تعليمية أو لأغراض التصحيح) التنسيقات التي يتم حفظها بواسطة ``grad_fn`` معين عن طريق البحث عن سماته التي تبدأ بالبادئة ``_saved``.

.. code::

    x = torch.randn(5, requires_grad=True)
    y = x.pow(2)
    print(x.equal(y.grad_fn._saved_self))  # True
    print(x is y.grad_fn._saved_self)  # True


في الكود السابق، يشير ``y.grad_fn._saved_self`` إلى نفس كائن Tensor مثل `x`.
ولكن قد لا يكون هذا هو الحال دائمًا. على سبيل المثال:

.. code::

    x = torch.randn(5, requires_grad=True)
    y = x.exp()
    print(y.equal(y.grad_fn._saved_result))  # True
    print(y is y.grad_fn._saved_result)  # False


تحت الغطاء، لمنع دورات المرجع، قامت PyTorch بتغليف التنسيق عند الحفظ وفك تغليفه إلى تنسيق مختلف للقراءة. هنا، فإن التنسيق الذي تحصل عليه من خلال الوصول إلى ``y.grad_fn._saved_result`` هو كائن تنسيق مختلف عن ``y`` (ولكنهما لا يزالان يتشاركان نفس التخزين).

ما إذا كان سيتم تغليف التنسيق في كائن تنسيق مختلف يعتمد على ما إذا كان إخراج ``grad_fn`` الخاص به، والذي يعد تفاصيل تنفيذ عرضة للتغيير ولا يجب أن يعتمد عليها المستخدمون.

يمكنك التحكم في كيفية قيام PyTorch بالتغليف / فك التغليف باستخدام :ref:`saved-tensors-hooks-doc`.

المشتقات للوظائف غير القابلة للاشتقاق
-------------------------

حساب المشتق باستخدام التفاضل التلقائي صالح فقط عندما تكون كل دالة ابتدائية مستخدمة قابلة للاشتقاق.
لسوء الحظ، فإن العديد من الدوال التي نستخدمها في الممارسة العملية لا تمتلك هذه الخاصية (على سبيل المثال ``relu`` أو ``sqrt`` عند ``0``).
للمحاولة والحد من تأثير الدوال غير القابلة للاشتقاق، نقوم بتعريف مشتقات العمليات الابتدائية عن طريق تطبيق القواعد التالية بالترتيب:

1. إذا كانت الدالة قابلة للاشتقاق وبالتالي فإن المشتق موجود في النقطة الحالية، فاستخدمه.
2. إذا كانت الدالة محدبة (على الأقل محليًا)، فاستخدم المشتق الفرعي لقاعدة القيمة الدنيا (فهو اتجاه الانحدار الأشد).
3. إذا كانت الدالة مقعرة (على الأقل محليًا)، فاستخدم المشتق الفائق لقاعدة القيمة الدنيا (ضع في اعتبارك `-f(x)` وقم بتطبيق النقطة السابقة).
4. إذا كانت الدالة محددة، فحدد المشتق في النقطة الحالية بالاستمرارية (لاحظ أن ``inf`` ممكن هنا، على سبيل المثال لـ ``sqrt(0)``). إذا كانت هناك عدة قيم ممكنة، فاختر واحدة بشكل تعسفي.
5. إذا كانت الدالة غير محددة (على سبيل المثال ``sqrt(-1)``، ``log(-1)`` أو معظم الدوال عندما يكون الإدخال ``NaN``)، فإن القيمة المستخدمة كمشتق تعسفي (قد نرفع أيضًا خطأً ولكن هذا غير مضمون). ستستخدم معظم الدوال ``NaN`` كمشتق، ولكن لأسباب تتعلق بالأداء، ستستخدم بعض الدوال قيمًا أخرى (على سبيل المثال ``log(-1)``).
6. إذا لم تكن الدالة عبارة عن خريطة محددة (أي أنها ليست `دالة رياضية`_)، فسيتم تمييزها على أنها غير قابلة للاشتقاق. سيؤدي هذا إلى حدوث خطأ في الخلف إذا تم استخدامه على تنسيقات تتطلب تدرجًا خارج بيئة ``no_grad``.

.. _mathematical function: https://en.wikipedia.org/wiki/Function_(mathematics)

.. _locally-disable-grad-doc:

تعطيل حساب المشتق محليًا
-------------------

هناك العديد من الآليات المتاحة في بايثون لإيقاف حساب المشتق المحلي:

لإيقاف حساب المشتق عبر كتل كاملة من التعليمات البرمجية، هناك برامج إدارة السياق مثل وضع عدم حساب المشتق ووضع الاستنتاج.
لاستبعاد أكثر دقة للرسوم البيانية الفرعية من حساب المشتق، هناك تعيين حقل "requires_grad" للمؤثر.

فيما يلي، بالإضافة إلى مناقشة الآليات المذكورة أعلاه، نقوم أيضًا بوصف
وضع التقييم (:meth:`nn.Module.eval()`)، وهي طريقة لا تستخدم
لإيقاف حساب المشتق ولكن، بسبب اسمها، غالبًا ما يتم خلطها مع الثلاثة الآخرين.

تعيين "requires_grad"
^^^^^^^^^^^^^^^^^^^^^^

:attr:`requires_grad` هو علم، الافتراضي إلى false *ما لم يتم لفها
في* ``nn.Parameter``، والذي يسمح باستبعاد دقيق لل
الرسوم البيانية الفرعية من حساب المشتق. إنه يؤثر في كل من
المرور الأمامي والخلفي:

أثناء المرور الأمامي، يتم تسجيل العملية في الرسم البياني الخلفي فقط إذا
يتطلب أحد مدخلاتها على الأقل المشتق.
أثناء المرور الخلفي (``.backward()``)، لن يتم سوى المشتقات الورقية مع
``requires_grad=True`` سيكون لها درجات متراكمة في حقولها ``.grad``.

من المهم ملاحظة أنه على الرغم من أن كل مؤثر لديه هذا العلم،
*تعيين* له معنى فقط للمؤثرات الورقية (المؤثرات التي ليس لها "grad_fn"، على سبيل المثال،
معلمات "nn.Module").
المؤثرات غير الورقية (المؤثرات التي لها "grad_fn") هي مؤثرات لها
رسم بياني خلفي مرتبط بها. وبالتالي ستكون مشتقاتها مطلوبة
كنتيجة وسيطة لحساب المشتق لورقة مؤثر تتطلب المشتق. من هذا التعريف، من الواضح أن جميع المؤثرات غير الورقية
سيكون لها تلقائيًا ``require_grad=True``.

يجب أن يكون تعيين "requires_grad" الطريقة الرئيسية التي تتحكم بها في أجزاء
من النموذج الذي يشكل جزءًا من حساب المشتق، على سبيل المثال، إذا كنت بحاجة إلى
تجميد أجزاء من نموذجك المسبق التدريب أثناء ضبط دقيق للنموذج.

لتجميد أجزاء من نموذجك، قم ببساطة بتطبيق ``.requires_grad_(False)`` على
المعلمات التي لا تريد تحديثها. وكما هو موضح أعلاه،
نظرًا لأن الحسابات التي تستخدم هذه المعلمات كمدخلات لن يتم تسجيلها في
المرور الأمامي، فلن يتم تحديث حقولها ``.grad`` في المرور الخلفي لأنها لن تكون جزءًا من الرسم البياني الخلفي في المقام الأول، كما هو مطلوب.

نظرًا لأن هذا النمط شائع جدًا، يمكن أيضًا تعيين "requires_grad" على
مستوى الوحدة النمطية مع :meth:`nn.Module.requires_grad_()`.
عند تطبيقه على وحدة نمطية، ``.requires_grad_()`` يؤثر على
جميع
معلمات الوحدة النمطية (التي يكون لها افتراضيًا ``requires_grad=True``).

وضع المشتق
^^^^^^^^^^

بصرف النظر عن تعيين "requires_grad"، هناك أيضًا ثلاث أوضاع للمشتق يمكن
تحديدها من بايثون والتي يمكن أن تؤثر على كيفية معالجة العمليات في PyTorch
داخليا بواسطة autograd: الوضع الافتراضي (وضع المشتق)، ووضع عدم حساب المشتق،
وضع الاستنتاج، وجميعها يمكن التبديل بينها عبر برامج إدارة السياق والزخارف.

.. list-table::
   :widths: 50 50 50 50 50
   :header-rows: 1

   * - الوضع
     - يستبعد العمليات من التسجيل في الرسم البياني الخلفي
     - يتخطى النفقات العامة الإضافية لتتبع autograd
     - يمكن استخدام المؤثرات المُنشأة أثناء تمكين الوضع في وضع المشتق لاحقًا
     - أمثلة
   * - الافتراضي
     -
     -
     - ✓
     - المرور الأمامي
   * - عدم حساب المشتق
     - ✓
     -
     - ✓
     - تحديثات المحسن
   * - الاستنتاج
     - ✓
     - ✓
     -
     - معالجة البيانات، تقييم النموذج

الوضع الافتراضي (وضع المشتق)
^^^^^^^^^^^^^^^^^^^^^^^^

"الوضع الافتراضي" هو الوضع الذي نكون فيه ضمنيًا عندما لا يتم تمكين أي أوضاع أخرى مثل
عدم حساب المشتق ووضع الاستنتاج. لمقارنته
مع "وضع عدم حساب المشتق"، يُطلق على الوضع الافتراضي أيضًا أحيانًا "وضع المشتق".

أهم شيء يجب معرفته حول الوضع الافتراضي هو أنه الوضع الوحيد الذي يكون فيه
"requires_grad" ساري المفعول. يتم دائمًا تجاوز "requires_grad"
ليكون ``False`` في كلا الوضعين الآخرين.

وضع عدم حساب المشتق
^^^^^^^^^^^^^^^^^^

تتصرف الحسابات في وضع عدم حساب المشتق كما لو أن أيا من المدخلات لا تتطلب المشتق.
بعبارة أخرى، لا يتم أبدًا تسجيل الحسابات في وضع عدم حساب المشتق في الرسم البياني الخلفي
حتى إذا كانت هناك مدخلات لها ``require_grad=True``.

قم بتمكين وضع عدم حساب المشتق عندما تحتاج إلى إجراء عمليات لا يجب أن يتم
تسجيلها بواسطة autograd، ولكنك ما زلت ترغب في استخدام مخرجات هذه
الحسابات في وضع المشتق لاحقًا. يجعل برنامج إدارة السياق هذا من الملائم
تعطيل المشتقات لكتل التعليمات البرمجية أو الوظائف دون
الاضطرار إلى تعيين المؤثرات مؤقتًا إلى أن يكون لها ``requires_grad=False``، ثم
العودة إلى ``True``.

على سبيل المثال، قد يكون وضع عدم حساب المشتق مفيدًا عند كتابة محسن: عند
أداء التحديث التدريبي، تريد تحديث المعلمات
مكانيًا دون تسجيل التحديث بواسطة autograd.
أنت تنوي أيضًا استخدام المعلمات المحدثة لحسابات في
وضع المشتق في المرور الأمامي التالي.

تعتمد التطبيقات في :ref:`nn-init-doc` أيضًا
على وضع عدم حساب المشتق عند تهيئة المعلمات لتجنب
تتبع autograd عند تحديث المعلمات المُهيئة في المكان.

وضع الاستنتاج
^^^^^^^^^^

وضع الاستنتاج هو النسخة المتطرفة من وضع عدم حساب المشتق. تمامًا مثل وضع عدم حساب المشتق،
لا يتم تسجيل الحسابات في وضع الاستنتاج في الرسم البياني الخلفي، ولكن
تمكين وضع الاستنتاج سيسمح لـ PyTorch بزيادة سرعة نموذجك.
تأتي هذه السرعة المحسنة بعيب: لن يكون المؤثرون المُنشئون في وضع الاستنتاج قادرين على
يتم استخدامها في الحسابات التي سيتم تسجيلها بواسطة autograd بعد
الخروج من وضع الاستنتاج.

قم بتمكين وضع الاستنتاج عندما تقوم بأداء حسابات لا تحتاج إلى
يتم تسجيلها في الرسم البياني الخلفي، وأنت لا تخطط لاستخدام المؤثرات
التي تم إنشاؤها في وضع الاستنتاج في أي حساب يتم تسجيله بواسطة autograd لاحقًا.

من المستحسن أن تجرب وضع الاستنتاج في أجزاء من التعليمات البرمجية الخاصة بك
التي لا تتطلب تتبع autograd (على سبيل المثال، معالجة البيانات وتقييم النموذج).
إذا نجح الأمر خارج الصندوق
لحالتك الاستخدامية، فهي فوز مجاني بالأداء. إذا واجهت أخطاء بعد
تمكين وضع الاستنتاج، تحقق من أنك لا تستخدم المؤثرات المُنشأة في
وضع الاستنتاج في الحسابات التي يتم تسجيلها بواسطة autograd بعد الخروج من وضع الاستنتاج. إذا لم تتمكن من تجنب مثل هذا الاستخدام في حالتك، فيمكنك دائمًا التبديل مرة أخرى
إلى وضع عدم حساب المشتق.

للحصول على التفاصيل حول وضع الاستنتاج، يرجى الاطلاع على
`وضع الاستنتاج <https://pytorch.org/cppdocs/notes/inference_mode.html>`_.

للحصول على تفاصيل التنفيذ حول وضع الاستنتاج، راجع
`RFC-0011-InferenceMode <https://github.com/pytorch/rfcs/pull/17>`_.

وضع التقييم (``nn.Module.eval()``)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

وضع التقييم ليس آلية لإيقاف حساب المشتق محليًا.
تم تضمينه هنا على أي حال لأنه يتم الخلط بينه أحيانًا وبين آلية من هذا القبيل.

من الناحية الوظيفية، فإن ``module.eval()`` (أو ما يعادله ``module.train(False)``) تمامًا
متعامد مع وضع عدم حساب المشتق ووضع الاستنتاج. كيف ``model.eval()`` يؤثر
يعتمد نموذجك تمامًا على الوحدات النمطية المحددة المستخدمة في نموذجك
وما إذا كانت تحدد أي سلوك محدد لوضع التدريب.

أنت مسؤول عن استدعاء ``model.eval()`` و ``model.train()`` إذا كان نموذجك يعتمد على الوحدات النمطية مثل :class:`torch.nn.Dropout` و
:class:`torch.nn.BatchNorm2d` التي قد تتصرف
بشكل مختلف اعتمادًا على وضع التدريب، على سبيل المثال، لتجنب تحديث إحصائيات التشغيل الخاصة بك
متوسط ​​القيمة على بيانات التحقق.

من المستحسن دائمًا استخدام ``model.train()`` عند
التدريب و ``model.eval()`` عند تقييم نموذجك (التحقق من الصحة/الاختبار) حتى لو لم تكن
تأكد من أن نموذجك لديه سلوك محدد لوضع التدريب، لأنه قد يتم تحديث وحدة نمطية تستخدمها للتصرف بشكل مختلف في وضعي التدريب والتقييم.

العمليات في المكان مع autograd
-------------------------

إن دعم العمليات في المكان في autograd أمر صعب، ونحن لا نشجع
استخدامها في معظم الحالات. يؤدي تحرير الذاكرة العدواني وإعادة استخدامها بواسطة autograd إلى
جعله فعالًا للغاية، وهناك مناسبات قليلة جدًا عندما تقلل العمليات في المكان
استخدام الذاكرة بأي مبلغ كبير. ما لم تكن تعمل
تحت ضغط الذاكرة الشديد، فقد لا تحتاج أبدًا إلى استخدامها.

هناك سببان رئيسيان يحدان من قابلية تطبيق العمليات في المكان:

1. يمكن أن تقوم العمليات في المكان بمسح القيم المطلوبة لحساب المشتقات.

2. تتطلب كل عملية في المكان أن يقوم التنفيذ بإعادة كتابة
الرسم البياني الحسابي. تُنشئ الإصدارات غير الموجودة في المكان ببساطة كائنات جديدة وتحتفظ بالإشارات إلى الرسم البياني القديم، بينما تتطلب العمليات في المكان، تغيير منشئ جميع المدخلات إلى :class:`Function` الذي يمثل
هذه العملية. يمكن أن يكون هذا الأمر معقدًا، خاصة إذا كان هناك العديد من المؤثرات التي تشير إلى نفس التخزين (على سبيل المثال، تم إنشاؤها عن طريق الفهرسة أو التحويل)،
وستؤدي وظائف في المكان إلى حدوث خطأ إذا كان التخزين الخاص بالمدخلات المعدلة
تمت الإشارة إليه بواسطة أي مؤثر آخر.

فحوصات صحة العمليات في المكان
^^^^^^^^^^^^^^^^^^^^^^^^^^^

يحتفظ كل مؤثر بمؤشر إصدار، يتم زيادته كلما تم تمييزه
قذر في أي عملية. عندما تقوم دالة بحفظ أي مؤثرات للخلف،
يتم أيضًا حفظ مؤشر الإصدار لمؤثرها الحاوي. بمجرد الوصول إلى ``self.saved_tensors``، يتم التحقق منه، وإذا كان أكبر من القيمة المحفوظة، يتم إثارة خطأ. يضمن هذا أنه إذا كنت تستخدم وظائف في المكان
ولا ترى أي أخطاء، فيمكنك التأكد من أن المشتقات المحسوبة صحيحة.

Autograd متعدد الخيوط
هذا النص يشرح كيفية استخدام محرك "أوتوجراد" (Autograd) في بيئة متعددة الخيوط، مع تسليط الضوء على بعض السلوكيات التي يجب أن يكون المستخدم على دراية بها.

محرك "أوتوجراد" مسؤول عن تشغيل جميع العمليات الخلفية اللازمة لحساب تمرير الخلف. وسيصف هذا القسم جميع التفاصيل التي يمكن أن تساعدك على الاستفادة القصوى منه في بيئة متعددة الخيوط. (هذا مناسب فقط لـ PyTorch 1.6+ لأن السلوك في الإصدارات السابقة كان مختلفًا).

يمكن للمستخدم تدريب نموذجه باستخدام كود متعدد الخيوط (مثل التدريب Hogwild)، ولا يمنع الحسابات الخلفية المتزامنة، ويمكن أن يكون الكود على النحو التالي:

.. code::

    # تحديد دالة التدريب لاستخدامها في خيوط مختلفة
    def train_fn():
        x = torch.ones(5, 5, requires_grad=True)
        # forward
        y = (x + 3) * (x + 4) * 0.5
        # backward
        y.sum().backward()
        # تحديث المحسن المحتمل


    # يقوم المستخدم بكتابة كود الخيوط الخاص به لتشغيل train_fn
    threads = []
    for _ in range(10):
        p = threading.Thread(target=train_fn, args=())
        p.start()
        threads.append(p)

    for p in threads:
        p.join()


لاحظ أن هناك بعض السلوكيات التي يجب أن يكون المستخدم على دراية بها:

التزامن على وحدة المعالجة المركزية (CPU)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

عند تشغيل ``backward()`` أو ``grad()`` عبر واجهة برمجة التطبيقات (API) الخاصة بـ Python أو C++ في خيوط متعددة على وحدة المعالجة المركزية (CPU)، من المتوقع أن تشاهد تزامنًا إضافيًا بدلاً من تسلسل جميع مكالمات الخلف بترتيب محدد أثناء التنفيذ (السلوك قبل PyTorch 1.6).

عدم الحتمية
^^^^^^^^^

إذا كنت تستدعي ``backward()`` من خيوط متعددة بشكل متزامن ولديها مدخلات مشتركة (أي تدريب CPU Hogwild)، فيجب توقع عدم الحتمية. يمكن أن يحدث هذا لأن المعلمات مشتركة تلقائيًا عبر الخيوط، وبالتالي، قد تقوم خيوط متعددة بالوصول ومحاولة تراكم نفس سمة ``.grad`` أثناء تراكم التدرجات. هذا غير آمن من الناحية الفنية، وقد يؤدي إلى حالة سباق وقد تكون النتيجة غير صالحة للاستخدام.

يجب على المستخدمين الذين يطورون نماذج متعددة الخيوط ذات معلمات مشتركة أن يضعوا في اعتبارهم نموذج الخيوط وأن يفهموا المشكلات الموضحة أعلاه.

يمكن استخدام واجهة برمجة التطبيقات (API) الوظيفية :func:`torch.autograd.grad` لحساب التدرجات بدلاً من ``backward()`` لتجنب عدم الحتمية.

الاحتفاظ بالرسم البياني
^^^^^^^^^^^^^^^^

إذا كان جزء من رسم بياني لـ "أوتوجراد" مشتركًا بين الخيوط، أي تشغيل الجزء الأول من التغذية الأمامية في خيط واحد، ثم تشغيل الجزء الثاني في خيوط متعددة، فإن الجزء الأول من الرسم البياني مشترك. في هذه الحالة، قد تواجه الخيوط المختلفة التي تنفذ ``grad()`` أو ``backward()`` على نفس الرسم البياني مشكلة تدمير الرسم البياني أثناء الطيران في أحد الخيوط، وسيتحطم الخيط الآخر في هذه الحالة. سوف يخطئ "أوتوجراد" للمستخدم بشكل مشابه لما يحدث عند استدعاء ``backward()`` مرتين دون ``retain_graph=True``، وإبلاغ المستخدم بأنه يجب عليهم استخدام ``retain_graph=True``.

أمان الخيوط على عقدة "أوتوجراد"
^^^^^^^^^^^^^^^^^^^^^^^^

نظرًا لأن "أوتوجراد" يسمح لخيط المتصل بتشغيل تنفيذ الخلف الخاص به من أجل إمكانية التنفيذ المتوازي، فمن المهم التأكد من أمان الخيوط على وحدة المعالجة المركزية (CPU) مع مكالمات ``backward()`` الموازية التي تشترك في جزء/كل من GraphTask.

دالات Python المخصصة ``autograd.Function`` آمنة تلقائيًا للخيوط بسبب قفل التفسير العالمي (GIL).

بالنسبة لعقد "أوتوجراد" المدمجة في C++ (مثل AccumulateGrad وCopySlices) ودالات ``autograd::Function`` المخصصة، يستخدم محرك "أوتوجراد" قفل مؤشر التزامن (mutex) للخيوط لضمان أمان الخيوط على عقد "أوتوجراد" التي قد يكون لها حالة كتابة/قراءة.

عدم وجود أمان للخيوط على الخطافات المكتوبة بلغة C++
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

يعتمد "أوتوجراد" على المستخدم لكتابة خطافات C++ آمنة للخيوط. إذا كنت تريد تطبيق الخطاف بشكل صحيح في بيئة متعددة الخيوط، فستحتاج إلى كتابة كود قفل الخيط الصحيح لضمان أمان الخطافات للخيوط.

.. _complex_autograd-doc:

"التفاضل التلقائي" للأعداد المركبة
-----------------------

النسخة المختصرة:

- عندما تستخدم PyTorch لاشتقاق أي دالة :math:`f(z)` ذات مجال و/أو مشفرة معقدة،
  يتم حساب المشتقات تحت افتراض أن الدالة هي جزء من دالة خسارة ذات قيمة حقيقية أكبر :math:`g(input)=L`. المشتق المحسوب هو :math:`\frac{\partial L}{\partial z^*}`
  (لاحظ التآمر من z)، والذي يمثل بالضبط الاتجاه المعاكس للانحدار الأشد استخدامًا
  في خوارزمية الانحدار التدريجي. وبالتالي، هناك مسار قابل للتطبيق لجعل المحسنات الحالية
  تعمل خارج الصندوق مع المعلمات المعقدة.
- تتطابق هذه الاتفاقية مع اتفاقية TensorFlow للتفاضل المعقد، ولكنها تختلف عن JAX (التي تحسب
  :math:`\frac{\partial L}{\partial z}`).
- إذا كان لديك دالة حقيقية إلى حقيقية تستخدم داخليًا عمليات معقدة، فإن الاتفاقية هنا لا تهم: فستحصل دائمًا على
  نفس النتيجة التي كنت ستحصل عليها إذا تم تنفيذها
  مع عمليات حقيقية فقط.

إذا كنت فضوليًا بشأن التفاصيل الرياضية، أو تريد معرفة كيفية
تعريف المشتقات المعقدة في PyTorch، فاستمر في القراءة.

ما هي المشتقات المعقدة؟
^^^^^^^^^^^^^^^^^

يأخذ التعريف الرياضي للاشتقاق المعقد حد التعريف للاشتقاق ويعممه للعمل على
الأرقام المعقدة. ضع في اعتبارك دالة :math:`f: ℂ → ℂ`،

    .. math::
        f(z=x+yj) = u(x, y) + v(x, y)j

حيث :math:`u` و:math:`v` هما دالتان ذواتا قيمة حقيقية
و:math:`j` هي الوحدة التخيلية.

باستخدام تعريف المشتق، يمكننا الكتابة:

    .. math::
        f'(z) = \lim_{h \to 0, h \in C} \frac{f(z+h) - f(z)}{h}

لكي يوجد هذا الحد، يجب ألا يكون :math:`u` و:math:`v` قابلتين للاشتقاق الحقيقي فحسب، بل يجب أن تلبي :math:`f` أيضًا معادلات كوشي-ريمان `
<https://en.wikipedia.org/wiki/Cauchy%E2%80%93Riemann_equations>`_.  بعبارة أخرى: يجب أن يكون الحد المحسوب للخطوات الحقيقية والخيالية (:math:`h`)
متساوية. هذا شرط أكثر تقييدًا.

تُعرف الدوال القابلة للاشتقاق المعقد باسم الدوال التحليلية.
إنها حسنة التصرف، ولديها جميع الخصائص اللطيفة التي
رأيتها من الدوال الحقيقية القابلة للاشتقاق، ولكنها غير مفيدة عمليًا في
عالم التحسين. بالنسبة لمشكلات التحسين، يتم استخدام دالات الهدف ذات القيمة الحقيقية فقط في مجتمع البحث لأن الأرقام المعقدة ليست جزءًا من أي
مجال مرتب، وبالتالي فإن وجود خسارة ذات قيمة معقدة لا معنى له.

اتضح أيضًا أن أي دالة هدف ذات قيمة حقيقية مثيرة للاهتمام لا تفي
بمعادلات كوشي-ريمان. لذلك لا يمكن استخدام النظرية مع الدالة التحليلية في التحسين ومعظم الأشخاص يستخدمون حساب ويرتنجر.

يدخل حساب ويرتنجر في الصورة ...
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

لذلك، لدينا هذه النظرية العظيمة للاشتقاق المعقد والدوال التحليلية، ولا يمكننا استخدام أي منها على الإطلاق، لأن العديد
من الدوال الشائعة الاستخدام ليست تحليلية. ماذا يفعل عالم الرياضيات الفقير؟ حسنًا، لاحظ ويرتنجر أنه حتى إذا لم تكن :math:`f(z)`
تحليلية، فيمكن إعادة كتابتها كدالة ذات متغيرين
:math:`f(z, z*)` والتي تكون دائمًا تحليلية. ويرجع ذلك إلى أنه يمكن التعبير عن الجزء الحقيقي والخيالي من
:math:`z` من حيث :math:`z` و:math:`z^*` كما يلي:

    .. math::
        \begin{aligned}
            \mathrm{Re}(z) &= \frac {z + z^*}{2} \\
            \mathrm{Im}(z) &= \frac {z - z^*}{2j}
        \end{aligned}

يقترح حساب ويرتنجر دراسة :math:`f(z, z^*)` بدلاً من ذلك، والتي تكون
مضمونة أن تكون تحليلية إذا كانت :math:`f` قابلة للاشتقاق الحقيقي (طريقة أخرى للتفكير فيها هي كـ
تغيير نظام الإحداثيات، من :math:`f(x, y)`
إلى :math:`f(z, z^*)`.)  لهذه الدالة مشتقات جزئية
:math:`\frac{\partial }{\partial z}` و:math:`\frac{\partial}{\partial z^{*}}`.
يمكننا استخدام قاعدة السلسلة لإنشاء
علاقة بين هذه المشتقات الجزئية والمشتقات الجزئية.،
بالنسبة إلى المكونات الحقيقية والخيالية لـ :math:`z`.

    .. math::
        \begin{aligned}
            \frac{\partial }{\partial x} &= \frac{\partial z}{\partial x} * \frac{\partial }{\partial z} + \frac{\partial z^*}{\partial x} * \frac{\partial }{\partial z^*} \\
                                         &= \frac{\partial }{\partial z} + \frac{\partial }{\partial z^*}   \\
            \\
            \frac{\partial }{\partial y} &= \frac{\partial z}{\partial y} * \frac{\partial }{\partial z} + \frac{\partial z^*}{\partial y} * \frac{\partial }{\partial z^*} \\
                                         &= 1j * \left(\frac{\partial }{\partial z} - \frac{\partial }{\partial z^*}\right)
        \end{aligned}

من المعادلات أعلاه، نحصل على:

    .. math::
        \begin{aligned}
            \frac{\partial }{\partial z} &= 1/2 * \left(\frac{\partial }{\partial x} - 1j * \frac{\partial }{\partial y}\right)   \\
            \frac{\partial }{\partial z^*} &= 1/2 * \left(\frac{\partial }{\partial x} + 1j * \frac{\partial }{\partial y}\right)
        \end{aligned}

وهو التعريف الكلاسيكي لحساب ويرتنجر الذي ستجده على `Wikipedia <https://en.wikipedia.org/wiki/Wirtinger_derivatives>`_.

هناك الكثير من النتائج الجميلة لهذا التغيير.

- أولاً، تترجم معادلات كوشي-ريمان ببساطة إلى القول بأن :math:`\frac{\partial f}{\partial z^*} = 0` (أي أن الدالة :math:`f` يمكن كتابتها
  بالكامل من حيث :math:`z`، دون الإشارة إلى :math:`z^*`).
- النتيجة المهمة الأخرى (وغير البديهية إلى حد ما)، كما سنرى لاحقًا، هي أنه عند إجراء التحسين على دالة خسارة ذات قيمة حقيقية، فإن الخطوة التي يجب
  اتخاذها أثناء تحديث المتغير تعطى بواسطة :math:`\frac{\partial Loss}{\partial z^*}` (وليس :math:`\frac{\partial Loss}{\partial z}`).

للمزيد من القراءة، راجع: https://arxiv.org/pdf/0906.4835.pdf

كيف يكون حساب ويرتنجر مفيدًا في التحسين؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

يستخدم الباحثون في مجال الصوت والمجالات الأخرى، بشكل أكثر شيوعًا، الانحدار التدريجي لتحسين دالة الخسارة ذات القيمة الحقيقية ذات المتغيرات المعقدة.
عادةً، يعامل هؤلاء الأشخاص القيم الحقيقية والخيالية كقنوات منفصلة يمكن تحديثها. بالنسبة لحجم الخطوة :math:`\alpha/2` والخسارة
:math:`L`، يمكننا كتابة المعادلات التالية في :math:`ℝ^2`:

    .. math::
        \begin{aligned}
            x_{n+1} &= x_n - (\alpha/2) * \frac{\partial L}{\partial x}  \\
            y_{n+1} &= y_n - (\alpha/2) * \frac{\partial L}{\partial y}
        \end{aligned}

كيف تترجم هذه المعادلات إلى الفضاء المعقد :math:`ℂ`؟

    .. math::
        \begin{aligned}
            z_{n+1} &= x_n - (\alpha/2) * \frac{\partial L}{\partial x} + 1j * (y_n - (\alpha/2) * \frac{\partial L}{\partial y}) \\
                    &= z_n - \alpha * 1/2 * \left(\frac{\partial L}{\partial x} + j \frac{\partial L}{\partial y}\right) \\
                    &= z_n - \alpha * \frac{\partial L}{\partial z^*}
        \end{aligned}

حدث شيء مثير للاهتمام: يخبرنا حساب ويرتنجر
بأنه يمكننا تبسيط صيغة تحديث المتغيرات المعقدة أعلاه بحيث تشير فقط إلى
مشتق ويرتنجر التآمري
:math:`\frac{\partial L}{\partial z^*}`، مما يمنحنا الخطوة التي نتخذها بالضبط في التحسين.

نظرًا لأن مشتق ويرتنجر التآمري يعطينا الخطوة الصحيحة تمامًا لدالة الخسارة ذات القيمة الحقيقية، فإن PyTorch يمنحك هذا المشتق
عندما تقوم باشتقاق دالة ذات دالة خسارة ذات قيمة حقيقية.

كيف تحسب PyTorch مشتق ويرتنجر التآمري؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

عادةً، تأخذ صيغ المشتقات لدينا `grad_output` كإدخال،
تمثيل منتج المصفوفة-المشتقة الذي قمنا بحسابه بالفعل، أي :math:`\frac{\partial L}{\partial s^*}`، حيث :math:`L`
هي خسارة الحساب بأكمله (إنتاج خسارة حقيقية)
و:math:`s` هو إخراج دالتنا. الهدف هنا هو حساب
:math:`\frac{\partial L}{\partial z^*}`، حيث :math:`z` هو إدخال الدالة.  اتضح أنه في حالة الخسارة الحقيقية، يمكننا
الاستغناء عن *حساب* :math:`\frac{\partial L}{\partial s^*}` فقط،
على الرغم من أن قاعدة السلسلة تعني أننا نحتاج أيضًا إلى
الوصول إلى :math:`\frac{\partial L}{\partial s}`.  إذا كنت تريد
تخطي هذا الاشتقاق، فانظر إلى المعادلة الأخيرة في هذا القسم
ثم انتقل إلى القسم التالي.

دعنا نواصل العمل مع :math:`f: ℂ → ℂ` المعرفة
:math:`f(z) = f(x+yj) = u(x, y) + v(x, y)j`. كما نوقش أعلاه،
تتمحور اتفاقية التدرج التلقائي حول التحسين لدالة الخسارة ذات القيمة الحقيقية، لذلك دعنا نفترض أن :math:`f` هي جزء من دالة خسارة ذات قيمة حقيقية أكبر :math:`g`. باستخدام قاعدة السلسلة، يمكننا الكتابة:

    .. math::
        \frac{\partial L}{\partial z^*} = \frac{\partial L}{\partial u} * \frac{\partial u}{\partial z^*} + \frac{\partial L}{\partial v} * \frac{\partial v}{\partial z^*}
        :label: [1]

الآن باستخدام تعريف مشتق ويرتنجر، يمكننا الكتابة:

    .. math::
        \begin{aligned}
            \frac{\partial L}{\partial s} = 1/2 * \left(\frac{\partial L}{\partial u} - \frac{\partial L}{\partial v} j\right) \\
            \frac{\partial L}{\partial s^*} = 1/2 * \left(\frac{\partial L}{\partial u} + \frac{\partial L}{\partial v} j\right)
        \end{aligned}

يجب ملاحظة أنه نظرًا لأن :math:`u` و:math:`v` هما دالتان حقيقيتان، و:math:`L` حقيقي بافتراضنا أن :math:`f` هو
جزء من دالة ذات قيمة حقيقية، لدينا:

    .. math::
        \left( \frac{\partial L}{\partial s} \right)^* = \frac{\partial L}{\partial s^*}
        :label: [2]

أي أن :math:`\frac{\partial L}{\partial s}` يساوي :math:`grad\_output^*`.

باستبدال المعادلات أعلاه في :eq:`[1]`، نحصل على:

    .. math::
        \begin{aligned}
            \frac{\partial L}{\partial z^*} &= \left(\frac{\partial L}{\partial s} + \frac{\partial L}{\partial s^*}\right) * \frac{\partial u}{\partial z^*} + 1j * \left(\frac{\partial L}{\partial s} - \frac{\partial L}{\partial s^*}\right) * \frac{\partial v}{\partial z^*}  \\
                                            &= \frac{\partial L}{\partial s} * \left(\frac{\partial u}{\partial z^*} + \frac{\partial v}{\partial z^*} j\right) + \frac{\partial L}{\partial s^*} * \left(\frac{\partial u}{\partial z^*} - \frac{\partial v}{\partial z^*} j\right)  \\
                                            &= \frac{\partial L}{\partial s} * \frac{\partial (u + vj)}{\partial z^*} + \frac{\partial L}{\partial s^*} * \frac{\partial (u + vj)^*}{\partial z^*}  \\
                                            &= \frac{\partial L}{\partial s} * \frac{\partial s}{\partial z^*} + \frac{\partial L}{\partial s^*} * \frac{\partial s^*}{\partial z^*}    \\
        \end{aligned}

باستخدام :eq:`[2]`، نحصل على:

    .. math::
        \begin{aligned}
            \frac{\partial L}{\partial z^*} &= \left(\frac{\partial L}{\partial s^*}\right)^* * \frac{\partial s}{\partial z^*} + \frac{\partial L}{\partial s^*} * \left(\frac{\partial s}{\partial z}\right)^*  \\
                                            &= \boxed{ (grad\_output)^* * \frac{\partial s}{\partial z^*} + grad\_output * \left(\frac{\partial s}{\partial z}\right)^* }       \\
        \end{aligned}
        :label: [4]

هذه المعادلة الأخيرة هي المهمة لكتابة صيغ المشتقات الخاصة بك،
حيث تقوم بتفكيك صيغة المشتق لدينا إلى صيغة أبسط يسهل
حسابها يدويًا.

كيف يمكنني كتابة صيغة المشتق الخاصة بي لدالة معقدة؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

تعطينا المعادلة أعلاه الصيغة العامة لجميع
المشتقات للدوال المعقدة. ومع ذلك، ما زلنا بحاجة إلى
حساب :math:`\frac{\partial s}{\partial z}` و:math:`\frac{\partial s}{\partial z^*}`.
هناك طريقتان يمكنك القيام بذلك:
بالتأكيد! هذا النص مترجم إلى اللغة العربية بتنسيق ReStructuredText:

- تتمثل الطريقة الأولى في استخدام تعريف مشتقات ويرتنغر مباشرة وحساب :math:`\frac{\partial s}{\partial z}` و :math:`\frac{\partial s}{\partial z^*}` باستخدام :math:`\frac{\partial s}{\partial x}` و :math:`\frac{\partial s}{\partial y}` (التي يمكن حسابها بالطريقة المعتادة).

- أما الطريقة الثانية فتتمثل في استخدام حيلة تغيير المتغيرات وإعادة كتابة :math:`f(z)` كدالة ذات متغيرين :math:`f(z، z^*)`، وحساب مشتقات ويرتنغر التآلفية من خلال التعامل مع :math:`z` و :math:`z^*` كمتغيرين مستقلين. وهذا غالبا ما يكون أسهل؛ على سبيل المثال، إذا كانت الدالة المعنية قابلة للتفاضل العقدي، فلن يتم استخدام سوى :math:`z` (وسيكون :math:`\frac{\partial s}{\partial z^*}`` صفرا).

لنأخذ دالة :math:`f(z = x + yj) = c * z = c * (x+yj)` كمثال، حيث :math:`c \in ℝ`.

باستخدام الطريقة الأولى لحساب مشتقات ويرتنغر، نحصل على:

.. math::
    \begin{aligned}
        \frac{\partial s}{\partial z} &= 1/2 * \left(\frac{\partial s}{\partial x} - \frac{\partial s}{\partial y} j\right) \\
                                      &= 1/2 * (c - (c * 1j) * 1j)  \\
                                      &= c                          \\
        \\
        \\
        \frac{\partial s}{\partial z^*} &= 1/2 * \left(\frac{\partial s}{\partial x} + \frac{\partial s}{\partial y} j\right) \\
                                        &= 1/2 * (c + (c * 1j) * 1j)  \\
                                        &= 0                          \\
    \end{aligned}

باستخدام :eq:`[4]`، و `grad_output = 1.0` (وهي قيمة grad_output الافتراضية المستخدمة عند استدعاء :func:`backward` على إخراج قياسي في PyTorch)، نحصل على:

    .. math::
        \frac{\partial L}{\partial z^*} = 1 * 0 + 1 * c = c

باستخدام الطريقة الثانية لحساب مشتقات ويرتنغر، نحصل مباشرة على:

    .. math::
        \begin{aligned}
           \frac{\partial s}{\partial z} &= \frac{\partial (c*z)}{\partial z}       \\
                                         &= c                                       \\
            \frac{\partial s}{\partial z^*} &= \frac{\partial (c*z)}{\partial z^*}       \\
                                         &= 0
        \end{aligned}

وباستخدام :eq:`[4]` مرة أخرى، نحصل على :math:`\frac{\partial L}{\partial z^*} = c`. كما ترى، تتضمن الطريقة الثانية حسابات أقل، وهي أكثر فائدة للعمليات الحسابية الأسرع.

ماذا عن الدوال متعددة المجالات؟
^^^^^^^^^^^^^^^^^^^^^^^^^

تقوم بعض الدوال برسم الخرائط من المدخلات العقدية إلى المخرجات الحقيقية، أو العكس.
تشكل هذه الدوال حالة خاصة من :eq:`[4]`، والتي يمكن اشتقاقها باستخدام قاعدة السلسلة:

- بالنسبة لـ :math:`f: ℂ → ℝ`، نحصل على:

    .. math::
        \frac{\partial L}{\partial z^*} = 2 * grad_output * \frac{\partial s}{\partial z^{*}}

- بالنسبة لـ :math:`f: ℝ → ℂ`، نحصل على:

    .. math::
        \frac{\partial L}{\partial z^*} = 2 * \mathrm{Re}(grad_output^* * \frac{\partial s}{\partial z^{*}})

.. _saved-tensors-hooks-doc:

خطافات للموترات المحفوظة
يمكنك التحكم في كيفية :ref: `حزم/فك حزم التنسورات المحفوظة <saved-tensors-doc>` عن طريق تحديد زوج من الخطافين ``pack_hook`` / ``unpack_hook``. يجب أن تأخذ دالة ``pack_hook`` تنسور كحجة الوحيدة لها ولكن يمكنها إرجاع أي كائن بايثون (على سبيل المثال، تنسور آخر، أو زوج، أو حتى سلسلة تحتوي على اسم ملف). يجب أن تأخذ دالة ``unpack_hook`` كحجة الوحيدة لها ناتج ``pack_hook`` ويجب أن ترجع تنسور الذي سيستخدم في تمرير الخلفي. التنسور الذي ترجعه ``unpack_hook`` يحتاج فقط إلى نفس المحتوى مثل التنسور الذي تم تمريره كإدخال إلى ``pack_hook``. على وجه الخصوص، يمكن تجاهل أي بيانات وصفية ذات صلة بـ autograd لأنها ستتم الكتابة فوقها أثناء فك الحزم.

مثال على مثل هذا الزوج هو:

.. code::

    class SelfDeletingTempFile():
        def __init__(self):
            self.name = os.path.join(tmp_dir, str(uuid.uuid4()))

        def __del__(self):
            os.remove(self.name)

    def pack_hook(tensor):
        temp_file = SelfDeletingTempFile()
        torch.save(tensor, temp_file.name)
        return temp_file

    def unpack_hook(temp_file):
        return torch.load(temp_file.name)

لاحظ أن ``unpack_hook`` يجب ألا يحذف الملف المؤقت لأنه قد يتم استدعاؤه عدة مرات: يجب أن يظل الملف المؤقت نشطًا طالما أن كائن ``SelfDeletingTempFile`` المرتجع نشطًا. في المثال أعلاه، نمنع تسرب الملف المؤقت عن طريق إغلاقه عندما لم تعد هناك حاجة إليه (عند حذف كائن ``SelfDeletingTempFile``).

.. note::

    نضمن أن ``pack_hook`` سيتم استدعاؤه مرة واحدة فقط ولكن يمكن استدعاء ``unpack_hook`` عدة مرات حسب ما يتطلبه تمرير الخلفي، ونتوقع أن يرجع نفس البيانات في كل مرة.

.. warning::

    يُمنع إجراء عمليات في المكان على إدخال أي من الدالتين، حيث قد يؤدي ذلك إلى حدوث تأثيرات جانبية غير متوقعة. سيرمي PyTorch خطأً إذا تم تعديل إدخال خطاف الحزم في المكان، ولكنه لا يلتقط الحالة التي يتم فيها تعديل إدخال خطاف فك الحزم في المكان.


تسجيل الخطافات لتنسور محفوظ
^^^^^^^^^^^^^^^^^^^^^^^

يمكنك تسجيل زوج من الخطافات على تنسور محفوظ عن طريق استدعاء طريقة :meth: `~ torch.autograd.SavedTensor.register_hooks` على كائن :class: `SavedTensor`. يتم عرض هذه الكائنات كسمات ل ``grad_fn`` وتبدأ بالبادئة ``_raw_saved_``.

.. code::

    x = torch.randn(5, requires_grad=True)
    y = x.pow(2)
    y.grad_fn._raw_saved_self.register_hooks(pack_hook, unpack_hook)

يتم استدعاء طريقة ``pack_hook`` بمجرد تسجيل الزوج. يتم استدعاء طريقة ``unpack_hook`` كلما كان هناك حاجة إلى الوصول إلى التنسور المحفوظ، إما عن طريق ``y.grad_fn._saved_self`` أو أثناء التمرير الخلفي.

.. warning::

    إذا كنت تحتفظ بإشارة إلى :class: `SavedTensor` بعد إطلاق التنسورات المحفوظة (أي بعد استدعاء الخلفي)، فإن استدعاء :meth: `~ torch.autograd.SavedTensor.register_hooks` الخاص به محظور. سيرمي PyTorch خطأً في معظم الأحيان ولكنه قد يفشل في القيام بذلك في بعض الحالات وقد ينشأ عنه سلوك غير محدد.

تسجيل الخطافات الافتراضية للتنسورات المحفوظة
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

بدلاً من ذلك، يمكنك استخدام مدير السياق :class: `~ torch.autograd.graph.saved_tensors_hooks` لتسجيل زوج من الخطافات التي سيتم تطبيقها على *جميع* التنسورات المحفوظة التي تم إنشاؤها في ذلك السياق.

مثال:

.. code::

    # احفظ على القرص فقط التنسورات التي يكون حجمها >= 1000
    SAVE_ON_DISK_THRESHOLD = 1000

    def pack_hook(x):
        if x.numel() < SAVE_ON_DISK_THRESHOLD:
            return x
        temp_file = SelfDeletingTempFile()
        torch.save(tensor, temp_file.name)
        return temp_file

    def unpack_hook(tensor_or_sctf):
        if isinstance(tensor_or_sctf, torch.Tensor):
            return tensor_or_sctf
        return torch.load(tensor_or_sctf.name)

    class Model(nn.Module):
        def forward(self, x):
            with torch.autograd.graph.saved_tensors_hooks(pack_hook, unpack_hook):
              # ... احسب الإخراج
              output = x
            return output

    model = Model()
    net = nn.DataParallel(model)



الخطافات المحددة باستخدام مدير السياق هذا محلية للخيط. وبالتالي، فإن الكود التالي لن ينتج التأثيرات المرجوة لأن الخطافات لا تمر عبر `DataParallel`.

.. code::

      # مثال ما لا يجب فعله

      net = nn.DataParallel(model)
      with torch.autograd.graph.saved_tensors_hooks(pack_hook, unpack_hook):
          output = net(input)


لاحظ أن استخدام هذه الخطافات يعطل جميع التحسينات في المكان لتقليل إنشاء كائن التنسور. على سبيل المثال:

.. code::

    with torch.autograd.graph.saved_tensors_hooks(lambda x: x, lambda x: x):
        x = torch.randn(5, requires_grad=True)
        y = x * x

بدون الخطافات، تشير ``x`` و ``y.grad_fn._saved_self`` و ``y.grad_fn._saved_other`` جميعها إلى نفس كائن التنسور. مع الخطافات، سيقوم PyTorch بحزم وفك حزم `x` إلى كائني تنسور جديدين يتشاركان نفس التخزين مع `x` الأصلي (بدون إجراء نسخة).

.. _backward-hooks-execution:

تنفيذ الخطافات الخلفية
-------------------

سيناقش هذا القسم متى يتم تشغيل الخطافات المختلفة أو عدم تشغيلها. بعد ذلك، سيناقش الترتيب الذي يتم تشغيلها فيه. الخطافات التي سيتم تغطيتها هي: الخطافات الخلفية المسجلة في Tensor عبر :meth: `torch.Tensor.register_hook`، والخطافات بعد تراكم الخلفي المسجلة في Tensor عبر :meth: `torch.Tensor.register_post_accumulate_grad_hook`، والخطافات اللاحقة المسجلة في Node عبر :meth: `torch.autograd.graph.Node.register_hook`، والخطافات السابقة المسجلة في Node عبر :meth: `torch.autograd.graph.Node.register_prehook`.

ما إذا كان سيتم تشغيل خطاف معين
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

يتم تنفيذ الخطافات المسجلة في Tensor عبر :meth: `torch.Tensor.register_hook` عندما يتم حساب الخرائط لتلك التنسور. (لاحظ أن هذا لا يتطلب تنفيذ grad_fn للتنسور. على سبيل المثال، إذا تم تمرير التنسور كجزء من حجة "الإدخالات" إلى :func: `torch.autograd.grad`، فقد لا يتم تنفيذ grad_fn للتنسور، ولكن سيتم دائمًا تشغيل الخطاف المسجل لهذا التنسور.)

يتم تنفيذ الخطافات المسجلة في Tensor عبر :meth: `torch.Tensor.register_post_accumulate_grad_hook` بعد تراكم الخرائط للتنسور، مما يعني أنه تم تحديث حقل "التدرج" للتنسور. في حين يتم تشغيل الخطافات المسجلة عبر :meth: `torch.Tensor.register_hook` أثناء حساب الخرائط، يتم تشغيل الخطافات المسجلة عبر :meth: `torch.Tensor.register_post_accumulate_grad_hook` فقط بعد تحديث حقل "التدرج" للتنسور بواسطة autograd في نهاية التمرير الخلفي. وبالتالي، يمكن تسجيل خطافات ما بعد تراكم الخلفي فقط للتنسورات الورقية. سيؤدي تسجيل خطاف عبر :meth: `torch.Tensor.register_post_accumulate_grad_hook` على تنسور غير ورقي إلى حدوث خطأ، حتى إذا استدعيت `backward (retain_graph = True)`.

يتم تشغيل الخطافات المسجلة في :class: `torch.autograd.graph.Node` باستخدام :meth: `torch.autograd.graph.Node.register_hook` أو :meth: `torch.autograd.graph.Node.register_prehook` فقط إذا تم تنفيذ العقدة التي تم تسجيلها.

قد يعتمد ما إذا كان يتم تنفيذ عقدة معينة على ما إذا كان يتم استدعاء التمرير الخلفي باستخدام :func: `torch.autograd.grad` أو :func: `torch.autograd.backward`. على وجه التحديد، يجب أن تكون على دراية بهذه الاختلافات عند تسجيل خطاف على عقدة مطابقة لتنسور تقوم بتمريره إلى :func: `torch.autograd.grad` أو :func: `torch.autograd.backward` كجزء من حجة "الإدخالات".

إذا كنت تستخدم :func: `torch.autograd.backward`، فسيتم تشغيل جميع الخطافات المذكورة أعلاه، سواء قمت بتحديد حجة "الإدخالات" أم لا. ويرجع ذلك إلى أن `.backward()` ينفذ جميع العقد، حتى إذا كانت تتوافق مع تنسور محدد كإدخال. (لاحظ أن تنفيذ هذه العقدة الإضافية المقابلة لتنسورات الإدخال غير ضروري عادة، ولكنه يتم على أي حال. هذا السلوك عرضة للتغيير؛ لا يجب أن تعتمد عليه.)

من ناحية أخرى، إذا كنت تستخدم :func: `torch.autograd.grad`، فقد لا يتم تشغيل الخطافات الخلفية المسجلة في العقد التي تتوافق مع التنسورات التي يتم تمريرها إلى "الإدخالات"، لأن تلك العقد لن يتم تنفيذها ما لم يكن هناك إدخال آخر يعتمد على نتيجة التدرج لهذه العقدة.

ترتيب تشغيل الخطافات المختلفة
^^^^^^^^^^^^^^^^^^^^^^

يحدث الترتيب الذي تحدث فيه الأشياء على النحو التالي:

1. يتم تنفيذ الخطافات المسجلة في Tensor
2. يتم تنفيذ الخطافات السابقة المسجلة في العقدة (إذا تم تنفيذ العقدة).
3. يتم تحديث حقل ".grad" للتنسورات التي تحتفظ بـ "التدرج"
4. يتم تنفيذ العقدة (تخضع للقواعد المذكورة أعلاه)
5. بالنسبة للتنسورات الورقية التي تم تراكم "التدرج" لها، يتم تنفيذ الخطافات بعد تراكم الخلفي
6. يتم تنفيذ الخطافات اللاحقة المسجلة في العقدة (إذا تم تنفيذ العقدة)

إذا تم تسجيل عدة خطافات من نفس النوع على نفس التنسور أو العقدة، فسيتم تنفيذها بالترتيب الذي تم تسجيلها به. يمكن للخطافات التي يتم تنفيذها لاحقًا ملاحظة التعديلات التي أجرتها الخطافات السابقة على التدرج.

خطافات خاصة
^^^^^^^^^^^^^

يتم تنفيذ :func: `torch.autograd.graph.register_multi_grad_hook` باستخدام الخطافات المسجلة في التنسورات. يتم تشغيل كل خطاف تنسور فردي وفقًا لترتيب خطاف التنسور المحدد أعلاه، ويتم استدعاء الخطاف متعدد الخرائط المسجل عند حساب آخر تدرج للتنسور.

يتم تنفيذ :meth: `torch.nn.modules.module.register_module_full_backward_hook` باستخدام الخطافات المسجلة في العقدة. أثناء الحساب، يتم تسجيل الخطافات للعقدة المقابلة لـ grad_fn للإدخالات والمخرجات للوحدة. نظرًا لأن الوحدة قد تأخذ عدة إدخالات وترجع عدة مخرجات، يتم أولاً تطبيق دالة Autograd مخصصة على إدخالات الوحدة قبل الحساب وعلى مخرجات الوحدة قبل إرجاع إخراج الحساب لضمان مشاركة تلك التنسورات في دالة grad_fn واحدة، والتي يمكننا بعد ذلك إرفاق خطافاتنا بها.

سلوك خطافات التنسور عند تعديل التنسور في المكان
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

عادةً ما تتلقى الخطافات المسجلة في تنسور تدرج المخرجات فيما يتعلق بذلك التنسور، حيث يتم أخذ قيمة التنسور لتكون قيمته في الوقت الذي يتم فيه حساب الخلفي.

ومع ذلك، إذا قمت بتسجيل الخطافات في تنسور، ثم قمت بتعديل ذلك التنسور في المكان، فإن الخطافات المسجلة قبل التعديل في المكان تتلقى أيضًا تدرج المخرجات فيما يتعلق بالتنسور، ولكن يتم أخذ قيمة التنسور لتكون قيمته قبل التعديل في المكان.

إذا كنت تفضل السلوك في الحالة السابقة، فيجب عليك تسجيلها في التنسور بعد إجراء جميع التعديلات في المكان عليه. على سبيل المثال:

.. code::

    t = torch.tensor(1., requires_grad=True).sin()
    t.cos_()
    t.register_hook(fn)
    t.backward()

علاوة على ذلك، قد يكون من المفيد معرفة أنه تحت الغطاء، عندما يتم تسجيل الخطافات في تنسور، فإنها تصبح مرتبطة بشكل دائم بـ grad_fn لذلك التنسور، لذا إذا تم بعد ذلك تعديل التنسور في المكان، حتى إذا كان لدى التنسور الآن grad_fn جديد، فإن الخطافات المسجلة قبل التعديل في المكان ستظل مرتبطة بـ grad_fn القديم، على سبيل المثال، سيتم تشغيلها عندما تصل autograd engine إلى grad_fn القديم للتنسور.