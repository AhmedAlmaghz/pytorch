.. _fsdp_notes:

ملاحظات FSDP
==========

.. _fsdp_prefetch:

التفاصيل الدقيقة لآلية استباق FSDP
---------------------

بالنسبة لعمليات "all-gather" المتداخلة ``forward`` مع الحساب ``forward``، هناك آليتان ممكنتان:

1. الاستباق الضمني للأمام (مفعل دائمًا)
2. الاستباق الصريح للأمام (``forward_prefetch=True``)

يشير الاستباق الضمني "forward" إلى الاعتماد على إصدار عمليات "all-gather" من تيار CUDA منفصل للسماح بالتداخل بين عملية "all-gather" والحساب "forward" الصادر قبلها (من منظور وحدة المعالجة المركزية). على سبيل المثال، إذا كان لدينا طبقة 0 "all-gather" -> طبقة 0 حساب "forward" -> طبقة 1 "all-gather" -> ...، فيمكن لطبقة 1 "all-gather" أن تتداخل مع طبقة 0 حساب "forward" على الرغم من أن خيط وحدة المعالجة المركزية أصدره لاحقًا. (لن تتمكن أول عملية "all-gather" من التداخل مع أي شيء.)

يشير الاستباق الصريح "forward" إلى تغيير ترتيب الإصدار لخيط وحدة المعالجة المركزية: على سبيل المثال، طبقة 0 "all-gather" -> طبقة 1 "all-gather" -> طبقة 0 حساب "forward" -> ... في الوضع الحريص، لا توجد طريقة لمعرفة أي طبقة هي الطبقة التالية (مثل الطبقة 1 في المثال) عند التنفيذ لا يزال على الطبقة 0. لذلك، يجب استخدام الاستباق الصريح للأمام فقط للنماذج التي يكون ترتيب التنفيذ الخاص بها ثابتًا من تكرار إلى آخر (والذي نسميه أحيانًا "الرسم البياني الثابت"). مثال على نموذج لا يفي بهذا القيد هو `FLAVA <https://pytorch.org/blog/scaling-multimodal-foundation-models-in-torchmultimodal-with-pytorch-distributed/>`_).

لا يوفر الاستباق الصريح "forward" سوى الوقت المستغرق في إصدار نوى الحساب "forward" لطبقة ما مقابل أن يجب تخصيص موتر الإخراج لعملية "all-gather" التالية أثناء استخدام الحالي. من خلال إصدار "all-gather" التالي قبل نوى الحساب "forward" الحالية، يمكن لـ "all-gather" التالي البدء في وقت سابق على GPU. بالنسبة لمعظم أعباء العمل LLM، هذه ليست الحالة، لذلك لا يوجد دافع لتمكين ``forward_prefetch=True``.

على النقيض من ذلك، بالنسبة لـ "backward"، يجب علينا استخدام الاستباق الصريح "backward" وإلا فلن يكون هناك أي تداخل للاتصال والحساب. والسبب هو أننا نستخدم مجموعة عمليات NCCL واحدة لكل من "all-gather" و"reduce-scatter" (جزئيًا لأن الإصدارات الأقدم من NCCL لم تكن آمنة للاستخدام المتزامن على نفس الجهاز عبر نفس الرتب). تعني مجموعة عمليات NCCL واحدة تيار NCCL داخلي واحد تعمل عليه عمليات "reduce-scatter" و"all-gather" بشكل متسلسل. وبالتالي، ما لم نعيد صراحة ترتيب الإصدار الخاص بوحدة المعالجة المركزية ليكون "all-gather" التالي -> "reduce-scatter" الحالي، فإن "reduce-scatter" الحالي سيحظر "all-gather" التالي وبالتالي الحساب "backward" التالي، مما يمنع "reduce-scatter" الحالي من التداخل.

.. _fsdp_comms_payload_size:

حجم حمولة الاتصال
-------------

في FSDP، تتم الاتصالات على النحو التالي:

1. "all-gather" على المعلمات في "forward"
2. "all-gather" على المعلمات في "backward"
3. "reduce-scatter" على التدرجات في "backward"

إذا تم استخدام نقطة تفتيش التنشيط (:func:`~torch.utils.checkpoint.checkpoint`)، فلن يكون هناك اتصال إضافي نظرًا لأنه يتم استباق المعلمات على أي حال أثناء "backward".

في تصميم FSDP، يتم تحديد حجم الحمولة لكل رتبة على النحو التالي: يؤدي كل استدعاء إلى :class:`FullyShardedDataParallel` إلى إنشاء مجموعة اتصال واحدة تتكون من المعلمات في ``module.parameters()`` باستثناء أي منها تم تعيينه بالفعل لمثيل :class:`FullyShardedDataParallel` متداخل. على سبيل المثال، بالنسبة لـ Llama، إذا قمت بتطبيق :class:`FullyShardedDataParallel` على كل كتلة محول وحدات عصبية وكذلك على وحدة التحكم الجذرية، فستكون هناك مجموعة اتصال واحدة لكل كتلة محول وحدات عصبية وأخيرًا مجموعة اتصال واحدة مع تضمين التعليق والخطي النهائي. تتوافق كل مجموعة اتصال مع مكالمة "all-gather" واحدة ومكالمة "reduce-scatter" واحدة. بهذه الطريقة، فإن كيفية تطبيق :class:`FullyShardedDataParallel` تحدد حجم الاتصال. بشكل عام، يعد تطبيق FSDP على كل كتلة محول وحدات عصبية طريقة جيدة للنماذج اللغوية العصبية، ومن الصعب القيام بأفضل من ذلك بالنظر إلى التصميم الحالي.

لنأخذ مثالاً حيث لدينا نموذج قائم على محول وحدات عصبية مجزأ عبر 8 وحدات معالجة رسومية، حيث يحدث التجزئة على مستوى كتلة المحول وحدات عصبية فقط، وتحتوي كل كتلة محول وحدات عصبية على 1.6 مليار معلمة والمعلمات في fp32 (4 بايت لكل منها). وهذا يعني أنه بمجرد تجزئة، ستتضمن كل كتلة محول وحدات عصبية 0.2 مليار معلمة على كل رتبة.

* سيتم التواصل في تمرير "forward" بقطع من ``0.2*4 = 0.8GB`` في "all-gather"
* سيتم التواصل في تمرير "backward" مرتين ``0.8GB`` لكل منهما (1x "all-gather" و 1x "reduce-scatter")

بعبارة أخرى، ستكون هناك 3 اتصالات بحمولة ``0.8GB`` لكل منها. إذا كان النموذج يتكون من 10 كتل محول وحدات عصبية، فستكون هناك 30 عملية اتصال بإجمالي ``30*0.8=24GB``.

لتحديد حجم الحمولة لكل اتصال لكل رتبة، يكون ``total_transformer_block_params_in_B*dtype_bytes/num_gpus`` (جيجابايت).

يرجى ملاحظة أننا في هذا المثال لم ندرج الاتصالات الإضافية المطلوبة للتضمين، والتي يجب حسابها أيضًا. وستعتمد الرياضيات على ما إذا كانت التعليقات الواردة والصادرة مرتبطة بالوزن أم لا. إذا لم تكن مرتبطة بالوزن، فستكون هناك 2x اتصالات أكثر.

.. _fsdp_buffers_sizes:

أحجام المخازن المؤقتة FSDP
------------------

أولاً، دعنا نغطي المخازن المؤقتة المخصصة للاتصالات:

يتطلب "forward" حاليًا حجم مخزن مؤقت "all-gather" 2x. إليك السبب:

كما هو موضح في :ref:`fsdp_prefetch` في حالة الاستباق الصريح "forward" (``forward_prefetch=True``) حالة طبقة 0 "all-gather" -> طبقة 0 حساب "forward" -> طبقة 1 "all-gather" هناك حاجة إلى مخزن مؤقت بحجم "all-gather" 2، لأن أحد المخازن المؤقتة يستخدم في "forward" الحالي بينما يستخدم الآخر للاستباق.

في حين أن حالة الاستباق الضمني "forward" (``forward_prefetch=False``، الافتراضي) لنفس التسلسل من الناحية النظرية يجب أن تحتاج فقط إلى مخزن مؤقت واحد، في الواقع لا يزال الأمر يتعلق بحجم مخزن مؤقت "all-gather" 2x. والسبب هو أنه في تصميم FSDP المسطح، لا نقوم بنسخ من مخزن مؤقت "all-gather". يتم عرض المعلمات المستخدمة للحساب مباشرة في مخزن مؤقت "all-gather" (في الواقع، الفائدة الرئيسية من "المعلمة المسطحة" هي بالضبط هذا السبب). في هذه الحالة، في حين أن 'طبقة 1 all-gather' تتداخل مع 'طبقة 0 حساب forward'، فإن 'طبقة 0 حساب forward' تستخدم المعلمات التي يتم عرضها في 'طبقة 0 all-gather' المخزن المؤقت.

ثم يطرح سؤال طبيعي وهو، متى تريد ``forward_prefetch=False``؟ بالنسبة لنماذج الرسم البياني الثابت (مثل معظم LLMs)، هناك سبب تقني رئيسي. إنه أكثر من ذلك، من الناحية العملية، أضفنا هذا الخيار بسرعة لبعض النماذج الداخلية المحدودة بوحدة المعالجة المركزية ولم نقم باختبار كل مسار التعليمات البرمجية معها في اختبار الوحدة، لذلك نحن أقل ثقة فيه. يمكن أن يكون ``forward_prefetching=False`` أسهل في الاستدلال لأنه لا يتعين علينا التحقق من ترتيب forward المسجل كـ "وضع فشل محتمل"؛ يمكن دائمًا العثور على "all-gather" للوحدة النمطية تحت تسمية "record_function" الخاصة بها في تتبع الملف الشخصي لها.

يتطلب "backward" حاليًا حجم مخزن مؤقت "all-gather" 2x على الأقل وقد يكون أكثر قليلاً. إليك السبب:

يستخدم التصميم الحالي لـ FSDP ``recordStream`` لإدارة المخصصات التي يتم إنتاجها في تيار واحد والتي يتم استهلاكها في تيار آخر، والتي يمكن أن تؤدي إلى زيادة استخدام الذاكرة أكثر مما هو متوقع. يعتمد مقدار الزيادة على توقيت نواة GPU بالنسبة إلى وحدة المعالجة المركزية. حجة ``limit_all_gathers=True`` هي تخفيف لذلك - لمزيد من التفاصيل، راجع هذه المناقشة هي `FSDP & CUDACachingAllocator <https://dev-discuss.pytorch.org/t/fsdp-cudacachingallocator-an-outsider-newb-perspective/1486/1>`_.

هذه هي طريقة عمل FSDP الحالي مع autograd:

* تقوم FSDP الحالية بـ "all-gather" لـ ``flat_param``، والتي تعد ورقة autograd.
* يستدعي ``torch.split`` للحصول على طرق عرض 1D في ``flat_param`` المقابلة لمعلماتها الأصلية.
* يستدعي ``torch.view`` على كل تقسيم 1D لعرضه مرة أخرى إلى ND.
* هذا يعني أنه في "backward"، ينتهي بنا الأمر بـ ``ViewBackward`` (ND -> 1D) و ``SplitWithSizesBackward`` (والذي عبارة عن عملية دمج). على وجه الخصوص، يتم حساب كل تدرج فردي كمخصص منفصل، ويحدث دمج صريح لبناء مخزن مؤقت لإدخال "reduce-scatter". هذا يعني في الواقع حجم مخزن مؤقت 2x لـ "reduce-scatter" في تلك الذروة نقطة الذاكرة.

خلاصة القول، بالنسبة لـ "backward"، هناك حوالي 2x حجم المخزن المؤقت لـ "reduce-scatter" بالإضافة إلى أي آثار "recordStream".

ثانيًا، دعنا نناقش المخازن المؤقتة الإضافية:

بمجرد تجميع المعلمات المجزأة من جميع الرتب، فإنها تتطلب مخزنًا مؤقتًا إضافيًا لـ `total_transformer_block_params_in_B*dtype_bytes` للمعلمات الكاملة - لذا فإن الاستمرار في المثال السابق، إذا كانت كل كتلة محول وحدات عصبية تحتوي على 1.6 مليار معلمة والمعلمات في fp32، فسيكون `1.6*4=6.4GB` المخزن المؤقت.

وهناك حاجة إلى مخزن مؤقت 2 من هذه المخازن المؤقتة، حيث يتم استخدام أحدها حاليًا والآخر يتم استباقه.

لتلخيص، لدينا:

1. 2 مرات مخازن مؤقتة للاتصال بحجم ``total_transformer_block_params_in_B*dtype_bytes/num_gpus``
2. 2 مرات مخازن مؤقتة للمعلمات غير المجزأة بحجم الكتلة المحولة ````total_transformer_block_params_in_B*dtype_bytes``

أو إذا كنت تتبع المثال:

1. ``2*1.6*4/8=1.6GB``
2. ``2**1.6*4=12.8GB``

والمجموع هو ``14.4GB``.

والآن دعنا نناقش باختصار ما يحدث للتعليقات حيث تركناها خارج الحسابات:

بالنظر إلى القاعدة التي ناقشناها والتي أدرجتها في الملاحظة التي تبدأ بـ "يتم تحديد حجم مخزن مؤقت الاتصال على النحو التالي"، يمكننا التحليل على النحو التالي:

* افترض أننا نطبق FSDP على وحدة التحكم الجذرية (على سبيل المثال، فئة "محول وحدات عصبية"). افترض أننا نطبق FSDP أيضًا على كل كتلة محول وحدات عصبية (على سبيل المثال، فئة "كتلة محول وحدات عصبية").
* الأكثر شيوعًا، التعليق والتعليق النهائي عبارة عن أطفال مباشرين لوحدة التحكم الجذرية "محول وحدات عصبية".
* وفقًا لقاعدتنا، فإن هذا يعني أن التعليق والتعليق النهائي يتم تعيينهما إلى "المعلمة المسطحة" لوحدة التحكم الجذرية "محول وحدات عصبية".
* لدينا _قاعدة خاصة أخرى_، وهي أن الجذر لا يقوم بتحرير معلماته بعد "forward" لأنه سيتم على أي حال "all-gather" في "backward".
* وضع هذا معًا، يعني هذا أن "المعلمة المسطحة" لوحدة التحكم الجذرية بما في ذلك التعليق والتعليق النهائي يتم "all-gather" لبدء "forward" والاحتفاظ بها في ذاكرة GPU حتى نهاية "backward".
* إذا لم تكن التعليقات الواردة والصادرة مرتبطة بالوزن، فيمكننا _إضافة_ تطبيق FSDP على التعليق وعلى التعليق النهائي. بالنسبة للمعلمات المرتبطة بالوزن، نطلب منهم أن يكونوا جزءًا من نفس "المعلمة المسطحة" (وإلا فسيتم حسابها مرتين). من شأن ذلك أن يسمح بإلغاء تنشيط التعليق بعد استخدامه في "forward" وعدم "all-gather" إلا نحو نهاية "backward".
* نأمل أن يعطي هذا إحساسًا أفضل - يتم تعيين كل وحدة نمطية FSDP المعلمات في ``module.parameters`` باستثناء تلك المعينة بالفعل لمثيل FSDP متداخل آخر، ويحدد "forward" للوحدة النمطية "فترة الحياة" لمعلماتها. وبالتالي، يمكن لهيكل "nn.Module" المتداخل أن يؤثر على جدول "all-gather"/free وبالتالي أداء الذاكرة/السرعة.