.. _numerical_accuracy:

الدقة الرقمية
==============

في أجهزة الكمبيوتر الحديثة، يتم تمثيل الأعداد العشرية العائمة باستخدام معيار IEEE 754.
للحصول على مزيد من التفاصيل حول الحساب العشري العائم ومعيار IEEE 754، يرجى الاطلاع على
`حساب عشري عائم <https://en.wikipedia.org/wiki/Floating-point_arithmetic>`_
وعلى وجه الخصوص، لاحظ أن العشرية العائمة توفر دقة محدودة (حوالي 7 أرقام عشرية
لأرقام الفاصلة العائمة ذات الدقة الفردية، وحوالي 16 رقم عشري لأرقام الفاصلة العائمة ذات الدقة المزدوجة)
وأن الجمع والضرب العشريين العائمين غير
ترابطي، لذلك يؤثر ترتيب العمليات على النتائج.
بسبب هذا، لا يتم ضمان PyTorch
لإنتاج نتائج متطابقة بت لكل بت للحسابات العشرية العائمة التي هي
متطابقة رياضيا. وبالمثل، لا يتم ضمان نتائج متطابقة بت لكل بت عبر
إصدارات PyTorch، الالتزامات الفردية، أو المنصات المختلفة. وعلى وجه الخصوص، قد تختلف نتائج وحدة المعالجة المركزية ووحدة معالجة الرسومات
حتى للإدخالات المتطابقة بت لكل بت وحتى بعد التحكم في
مصادر العشوائية.

عمليات الدفعات أو شرائح العمليات
--------------------------

تدعم العديد من العمليات في PyTorch الحساب الدفعي، حيث يتم تنفيذ نفس العملية
لعناصر دفعات الإدخالات. ومن أمثلة ذلك :meth:`torch.mm` و
:meth:`torch.bmm`. من الممكن تنفيذ الحساب الدفعي كحلقة عبر عناصر الدفعة،
وتطبيق عمليات الرياضيات اللازمة على عناصر الدفعة الفردية، لأسباب تتعلق بالكفاءة
نحن لا نفعل ذلك، وعادة ما نقوم بأداء الحساب للدفعة بأكملها. قد تنتج المكتبات الرياضية التي نستدعيها، وتنفيذات PyTorch الداخلية للعمليات
نتائج مختلفة قليلاً في هذه الحالة، مقارنة بالعمليات غير الدفعية. على وجه الخصوص،
دع ``A`` و ``B`` تكون المنسوجات ثلاثية الأبعاد مع الأبعاد المناسبة للضرب المصفوفي الدفعي.
ثم ``(A@B) [0]`` (العنصر الأول من نتيجة الدفعة) غير مضمون أن يكون متطابقًا بتًا بـتًا
إلى ``A [0] @ B [0]`` (ضرب المصفوفة للعناصر الأولى من دفعات الإدخال)
على الرغم من أنه حسابياً متطابق.

بالمثل، فإن العملية المطبقة على شريحة المنسوجة غير مضمونة لإنتاج نتائج
مطابقة لشريحة نتيجة العملية نفسها المطبقة على المنسوجة الكاملة. على سبيل المثال، دعنا
``A`` تكون منسوجة ثنائية الأبعاد. ``A.sum (-1) [0]`` غير مضمون أن يكون متساويًا بتًا مع
``A [:، 0].sum ()``.

القيم المتطرفة
----------

عندما تحتوي الإدخالات على قيم كبيرة بحيث قد تفيض النتائج الوسيطة نطاق
نوع البيانات المستخدمة، فقد تفيض النتيجة النهائية أيضًا، على الرغم من أنه يمكن تمثيلها في
نوع البيانات الأصلي. على سبيل المثال:

.. code:: python

    import torch
    a=torch.tensor ([1e20، 1e20]) # نوع fp32 بشكل افتراضي
    a.norm () # ينتج tensor (inf)
    a.double (). norm () # ينتج tensor (1.4142e + 20، dtype=torch.float64)، قابل للتمثيل في fp32

.. _الجبر الخطي:

الجبر الخطي (``torch.linalg``)
---------------------------------

القيم غير المحدودة
"""""""""""

المكتبات الخارجية (الواجهات الخلفية) التي تستخدمها ``torch.linalg`` لا تقدم أي ضمانات بشأن سلوكها
عندما تحتوي الإدخالات على قيم غير محدودة مثل ``inf`` أو ``NaN``. وبالتالي، لا تفعل ذلك أيضًا PyTorch.
قد تعيد العمليات مصفوفة ذات قيم غير محدودة، أو تثير استثناءً، أو حتى تتسبب في حدوث خطأ في تجزئة الذاكرة.

ضع في اعتبارك استخدام :func:`torch.isfinite` قبل استدعاء هذه الوظائف للكشف عن هذا الموقف.

القيم المتطرفة في الجبر الخطي
"""""""""""""""""""

تحتوي الوظائف الموجودة داخل ``torch.linalg`` على المزيد من `القيم المتطرفة`_ أكثر من وظائف PyTorch الأخرى.

يفترض :ref:`linalg solvers` و :ref:`linalg inverses` أن المصفوفة المدخلة ``A`` قابلة للعكس. إذا كان قريبًا من
أن تكون غير قابلة للعكس (على سبيل المثال، إذا كان لها قيمة ذاتية صغيرة جدًا)، فقد تعيد هذه الخوارزميات بشكل صامت
نتائج غير صحيحة. يُقال إن هذه المصفوفات `غير جيدة الشرط <https://nhigham.com/2020/03/19/what-is-a-condition-number/>`_.
إذا تم تزويدها بإدخالات غير جيدة الشرط، فقد تختلف نتائج هذه الوظائف عند استخدام نفس الإدخالات على أجهزة مختلفة
أو عند استخدام واجهات خلفية مختلفة عبر الكلمة الأساسية ``driver``.

قد تعيد العمليات الطيفية مثل ``svd`` و ``eig`` و ``eigh`` أيضًا نتائج غير صحيحة (وقد تكون تدرجاتها غير محدودة)
عندما تحتوي إدخالاتها على قيم ذاتية قريبة من بعضها البعض. ويرجع ذلك إلى أن الخوارزميات المستخدمة لحساب هذه التحليلات
تناضل من أجل التقارب لهذه الإدخالات.

غالبًا ما يساعد تشغيل الحساب في ``float64`` (كما هو الحال في NumPy بشكل افتراضي)، ولكنه لا يحل هذه المشكلات في جميع الحالات.
قد يساعد تحليل طيف الإدخالات عبر :func:`torch.linalg.svdvals` أو رقم شرطها عبر :func:`torch.linalg.cond`
للكشف عن هذه القضايا.

TensorFloat-32(TF32) على أجهزة Nvidia Ampere (والأحدث)
-------------------------------------------------------

على أجهزة GPU Ampere (والأحدث) من Nvidia، يمكن لـ PyTorch استخدام TensorFloat32 (TF32) لتسريع العمليات المكثفة رياضيًا، خاصة عمليات الضرب المصفوفية والضربات.
عندما يتم تنفيذ عملية باستخدام نوى Tensor ذات 32 بت، يتم قراءة البتات العشرة الأولى فقط من فاصلة الكلمة المدخلة.
قد يؤدي هذا إلى تقليل الدقة وإنتاج نتائج مفاجئة (على سبيل المثال، قد يؤدي ضرب مصفوفة بمصفوفة الهوية إلى إنتاج نتائج مختلفة عن الإدخال).
بشكل افتراضي، يتم تعطيل نوى Tensor ذات 32 بت للضرب المصفوفي وممكنة للضربات، على الرغم من أن معظم أعباء العمل لشبكة العصبية لها نفس سلوك التقارب عند استخدام TF32 كما هو الحال مع fp32.
نوصي بتمكين نوى Tensor ذات 32 بت للضرب المصفوفي مع ``torch.backends.cuda.matmul.allow_tf32 = True`` إذا لم تكن شبكتك بحاجة إلى دقة الفاصلة العائمة 32 بت الكاملة.
إذا كانت شبكتك بحاجة إلى دقة الفاصلة العائمة 32 بت الكاملة لكل من الضرب المصفوفي والضربات، فيمكن أيضًا تعطيل نوى Tensor ذات 32 بت للضربات باستخدام ``torch.backends.cudnn.allow_tf32 = False``.

للحصول على مزيد من المعلومات، راجع :ref:`TensorFloat32<tf32_on_ampere>`.

الدقة المخفضة لعمليات الضرب المصفوفي FP16 و BF16
-------------------------------------------
عادةً ما يتم تنفيذ عمليات الضرب المصفوفي ذات الدقة النصفية باستخدام تراكمات وسيطة (تخفيض) بدقة مفردة من أجل الدقة الرقمية وتحسين المرونة ضد الفيض. لأسباب تتعلق بالأداء، تسمح بعض بنيات GPU، خاصةً الأحدث، ببعض عمليات الاقتصاص لنتائج التراكم الوسيطة إلى الدقة المخفضة (على سبيل المثال، الدقة النصفية). غالبًا ما يكون هذا التغيير غير ضار من منظور تقارب النموذج، على الرغم من أنه قد يؤدي إلى نتائج غير متوقعة (على سبيل المثال، قيم "inf" عندما يجب أن تكون النتيجة النهائية قابلة للتمثيل في الدقة النصفية).
إذا كانت عمليات التخفيض ذات الدقة المخفضة تسبب مشكلات، فيمكن إيقاف تشغيلها باستخدام
``torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = False``

يوجد علم مماثل لعمليات الضرب المصفوفي BF16 وهو مُمكّن بشكل افتراضي. إذا كانت عمليات التخفيض ذات الدقة المخفضة لـ BF16 تسبب مشكلات، فيمكن إيقاف تشغيلها باستخدام
``torch.backends.cuda.matmul.allow_bf16_reduced_precision_reduction = False``

للحصول على مزيد من المعلومات، راجع :ref:`allow_fp16_reduced_precision_reduction<fp16reducedprecision>` و :ref:`allow_bf16_reduced_precision_reduction<bf16reducedprecision>`

.. _fp16_on_mi200:

الدقة المخفضة لعمليات الضرب المصفوفي والضربات FP16 و BF16 على أجهزة AMD Instinct MI200
----------------------------------------------------------------------------
على أجهزة GPU AMD Instinct MI200، تقوم تعليمات مصفوفة FP16 و BF16 V_DOT2 و MFMA بمسح قيم الإدخال والإخراج دون القيمة الدنيا إلى الصفر. لا تقوم تعليمات مصفوفة FP32 و FP64 MFMA بمسح قيم الإدخال والإخراج دون القيمة الدنيا إلى الصفر. يتم استخدام التعليمات المتأثرة فقط بواسطة نوى rocBLAS (GEMM) و MIOpen (convolution)؛ لن تواجه جميع عمليات PyTorch الأخرى هذا السلوك. لن تواجه جميع أجهزة AMD GPU الأخرى هذا السلوك.

يوفر rocBLAS و MIOpen تنفيذات بديلة للعمليات FP16 المتأثرة. لا يتم توفير تنفيذات بديلة للعمليات BF16؛ تحتوي أرقام BF16 على نطاق ديناميكي أكبر من أرقام FP16 ومن المحتمل أن تواجه قيمًا دون القيمة الدنيا. للتنفيذ البديل لـ FP16، يتم صب قيم الإدخال FP16 إلى قيمة BF16 وسيطة ثم صبها مرة أخرى إلى إخراج FP16 بعد عمليات التراكم FP32. بهذه الطريقة، تظل أنواع الإدخال والإخراج دون تغيير.

عند التدريب باستخدام دقة FP16، قد تفشل بعض النماذج في التقارب مع مسح قيم FP16 دون القيمة الدنيا إلى الصفر. تحدث القيم دون القيمة الدنيا بشكل متكرر في تمرير الخلف أثناء حساب التدرج. بشكل افتراضي، ستستخدم PyTorch التنفيذات البديلة لـ rocBLAS و MIOpen أثناء التمرير الخلفي. يمكن تجاوز السلوك الافتراضي باستخدام متغيرات البيئة، ROCBLAS_INTERNAL_FP16_ALT_IMPL و MIOPEN_DEBUG_CONVOLUTION_ATTRIB_FP16_ALT_IMPL. سلوك هذه المتغيرات البيئية كما يلي:

+---------------+-----------+-----------+
|               | forward   | backward  |
+===============+===========+===========+
| غير محدد     | الأصلي  | بديل |
+---------------+-----------+-----------+
| تم تعيينه إلى 1  | بديل | بديل |
+---------------+-----------+-----------+
| تم تعيينه إلى 0  | الأصلي  | الأصلي  |
+---------------+-----------+-----------+

فيما يلي قائمة بالعمليات التي قد يتم استخدامها فيها rocBLAS:

* torch.addbmm
* torch.addmm
* torch.baddbmm
* torch.bmm
* torch.mm
* torch.nn.GRUCell
* torch.nn.LSTMCell
* torch.nn.Linear
* torch.sparse.addmm
* التنفيذات التالية لـ torch._C._ConvBackend:

  * slowNd
  * slowNd_transposed
  * slowNd_dilated
  * slowNd_dilated_transposed

فيما يلي قائمة بالعمليات التي قد يتم استخدامها فيها MIOpen:

* torch.nn.Conv [Transpose] Nd
* التنفيذات التالية لـ torch._C._ConvBackend:

  * ConvBackend::Miopen
  * ConvBackend::MiopenDepthwise
  * ConvBackend::MiopenTranspose