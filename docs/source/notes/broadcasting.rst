.. _broadcasting-semantics:

دلالات البث
==========

تدعم العديد من عمليات PyTorch دلالات البث الخاصة بـ NumPy.
راجع https://numpy.org/doc/stable/user/basics.broadcasting.html لمزيد من التفاصيل.

باختصار، إذا كانت عملية PyTorch تدعم البث، فيمكن توسيع وسائط Tensor الخاصة بها تلقائيًا لتكون ذات أحجام متساوية (دون إجراء نسخ من البيانات).

دلالات عامة
---------
يُعتبر وسيطا Tensor "قابلين للبث" إذا تحققت القواعد التالية:

- يجب أن يكون لكل Tensor بُعد واحد على الأقل.
- عند التكرار عبر أحجام الأبعاد، بدءًا من البعد الأخير، يجب أن تكون أحجام الأبعاد إما متساوية، أو أن يكون أحدها 1، أو أن أحدها لا يوجد.

على سبيل المثال::

    >>> x=torch.empty(5,7,3)
    >>> y=torch.empty(5,7,3)
    # نفس الأشكال قابلة للبث دائمًا (أي أن القواعد المذكورة أعلاه دائمًا ما تكون صحيحة)

    >>> x=torch.empty((0,))
    >>> y=torch.empty(2,2)
    # x و y غير قابلين للبث، لأن x لا يحتوي على بُعد واحد على الأقل

    # يمكن محاذاة الأبعاد الأخيرة
    >>> x=torch.empty(5,3,4,1)
    >>> y=torch.empty(  3,1,1)
    # x و y قابلان للبث.
    # البعد الأخير الأول: كلاهما له حجم 1
    # البعد الأخير الثاني: حجم y هو 1
    # البعد الأخير الثالث: حجم x == حجم y
    # البعد الأخير الرابع: البعد غير موجود في y

    # لكن:
    >>> x=torch.empty(5,2,4,1)
    >>> y=torch.empty(  3,1,1)
    # x و y غير قابلين للبث، لأن الحجم في البعد الأخير الثالث 2 != 3

إذا كان وسيطا Tensor :attr:`x`، :attr:`y` "قابلين للبث"، فيتم حساب حجم Tensor الناتج على النحو التالي:

- إذا كان عدد أبعاد :attr:`x` و :attr:`y` غير متساويين، فقم بإلحاق 1 بأبعاد Tensor ذات الأبعاد الأقل لجعلها ذات طول متساوٍ.
- بعد ذلك، لكل حجم بُعد، يكون حجم البعد الناتج هو الحد الأقصى لأحجام :attr:`x` و :attr:`y` على طول ذلك البعد.

على سبيل المثال::

    # يمكن محاذاة الأبعاد الأخيرة لجعل القراءة أسهل
    >>> x=torch.empty(5,1,4,1)
    >>> y=torch.empty(  3,1,1)
    >>> (x+y).size()
    torch.Size([5, 3, 4, 1])

    # لكن ليس ضروريًا:
    >>> x=torch.empty(1)
    >>> y=torch.empty(3,1,7)
    >>> (x+y).size()
    torch.Size([3, 1, 7])

    >>> x=torch.empty(5,2,4,1)
    >>> y=torch.empty(3,1,1)
    >>> (x+y).size()
    RuntimeError: يجب أن يتطابق حجم tensor a (2) مع حجم tensor b (3) في البعد غير المفرد 1

دلالات في المكان
-------------
أحد التعقيدات هو أن العمليات في المكان لا تسمح لtensor في المكان بتغيير الشكل نتيجة للبث.

على سبيل المثال::

    >>> x=torch.empty(5,3,4,1)
    >>> y=torch.empty(3,1,1)
    >>> (x.add_(y)).size()
    torch.Size([5, 3, 4, 1])

    # لكن:
    >>> x=torch.empty(1,3,1)
    >>> y=torch.empty(3,1,7)
    >>> (x.add_(y)).size()
    RuntimeError: يجب أن يتطابق الحجم الموسع للtensor (1) مع الحجم الموجود (7) في البعد غير المفرد 2.

التوافق مع الإصدارات السابقة
-----------------------
سمحت الإصدارات السابقة من PyTorch لوظائف نقطة معينة بالتنفيذ على وسائط Tensor ذات أشكال مختلفة،
طالما كان عدد العناصر في كل Tensor متساويًا. ثم يتم تنفيذ عملية النقطة الواحدة
من خلال النظر إلى كل Tensor كأبعاد أحادية. تدعم PyTorch الآن البث، ويُعتبر سلوك "الأبعاد الأحادية"
قديمًا وسيؤدي إلى ظهور تحذير Python في الحالات التي لا تكون فيها وسائط Tensor قابلة للبث، ولكن لها نفس عدد العناصر.

لاحظ أن تقديم البث يمكن أن يتسبب في حدوث تغييرات غير متوافقة مع الإصدارات السابقة في الحالة التي
لا يكون فيها وسيطا Tensor لهما نفس الشكل، ولكنهما قابلان للبث ولديهما نفس عدد العناصر.
على سبيل المثال::

    >>> torch.add(torch.ones(4,1), torch.randn(4))

كان من شأنه أن ينتج سابقًا Tensor بحجم: torch.Size([4,1])، ولكنه ينتج الآن Tensor بحجم: torch.Size([4,4]).
وللمساعدة في تحديد الحالات في رمزك حيث قد توجد عدم توافق مع الإصدارات السابقة التي قد تسببها البث،
يمكنك تعيين `torch.utils.backcompat.broadcast_warning.enabled` إلى `True`، والذي سيؤدي إلى ظهور تحذير Python
في مثل هذه الحالات.

على سبيل المثال::

    >>> torch.utils.backcompat.broadcast_warning.enabled=True
    >>> torch.add(torch.ones(4,1), torch.ones(4))
    __main__:1: UserWarning: self وother ليس لهما نفس الشكل، ولكنهما قابلان للبث، ولديهما نفس عدد العناصر.
    تغيير السلوك بطريقة غير متوافقة مع الإصدارات السابقة إلى البث بدلاً من النظر إليها كأبعاد أحادية.