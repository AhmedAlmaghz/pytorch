.. _cpu-threading-torchscript-inference:

خيوطية المعالجة المركزية واستنتاج TorchScript
=====================================

يسمح PyTorch باستخدام خيوط معالجة مركزية متعددة أثناء استنتاج نموذج TorchScript.
يوضح الشكل التالي مستويات مختلفة من التوازي التي قد نجدها في تطبيق نموذجي:

.. image:: cpu_threading_torchscript_inference.svg
   :width: 75%

يقوم خيط استدلال واحد أو أكثر بتنفيذ تمرير للأمام للنموذج على المدخلات المعطاة.
يقوم كل خيط استدلال باستدعاء مترجم JIT الذي ينفذ عمليات النموذج
داخل السطر، واحدة تلو الأخرى. يمكن للنموذج أن يستخدم "fork" TorchScript
بدائي لإطلاق مهمة غير متزامنة. يؤدي تشويك عدة عمليات في نفس الوقت
ينتج عنه مهمة يتم تنفيذها بشكل متوازي. ويعيد مشغل "الشوك" كائن "مستقبل" الذي يمكن استخدامه للتناغم في وقت لاحق، على سبيل المثال:

.. code-block:: python

    @torch.jit.script
    def compute_z(x):
        return torch.mm(x, self.w_z)

    @torch.jit.script
    def forward(x):
        # إطلاق compute_z بشكل غير متزامن:
        fut = torch.jit._fork(compute_z, x)
        # تنفيذ العملية التالية بالتوازي مع compute_z:
        y = torch.mm(x, self.w_y)
        # الانتظار حتى انتهاء compute_z:
        z = torch.jit._wait(fut)
        return y + z


يستخدم PyTorch بركة خيوط واحدة للتوازي بين العمليات، ويتم مشاركة بركة الخيوط هذه
بواسطة جميع مهام الاستدلال التي يتم تشويكها داخل عملية التطبيق.

بالإضافة إلى التوازي بين العمليات، يمكن لـ PyTorch أيضًا استخدام خيوط متعددة
داخل العمليات ('التوازي داخل العمليات'). يمكن أن يكون هذا مفيدًا في العديد من الحالات،
بما في ذلك العمليات الحسابية لكل عنصر على المصفوفات الكبيرة، والتحويلات، وGEMMs، وعمليات البحث عن التعيينات، وغيرها.


خيارات البناء
-------------

يستخدم PyTorch مكتبة ATen الداخلية لتنفيذ العمليات. بالإضافة إلى ذلك،
يمكن أيضًا بناء PyTorch مع دعم المكتبات الخارجية، مثل MKL_ و MKL-DNN_،
لتسريع العمليات الحسابية على وحدة المعالجة المركزية.

تدعم مكتبات ATen و MKL و MKL-DNN التوازي داخل العمليات وتعتمد على
مكتبات الموازاة التالية لتنفيذها:

* OpenMP_ - معيار (ومكتبة، عادة ما يتم شحنه مع المترجم)، يستخدم على نطاق واسع في المكتبات الخارجية؛
* TBB_ - مكتبة موازاة أحدث تم تحسينها للتوازي القائم على المهام والبيئات المتزامنة.

تاريخيا، تم استخدام OpenMP من قبل عدد كبير من المكتبات. إنه معروف
بالسهولة النسبية للاستخدام ودعم التوازي القائم على الحلقات والبدائيات الأخرى.

يتم استخدام TBB إلى حد أقل في المكتبات الخارجية، ولكن، في نفس الوقت،
تمت تهيئته للبيئات المتزامنة. تضمن مؤخرة TBB الخاصة بـ PyTorch أنه
يوجد بركة خيوط منفصلة وأحادية لكل عملية داخل العملية
يتم استخدامه من قبل جميع العمليات التي تعمل في التطبيق.

اعتمادًا على حالة الاستخدام، قد يجد المرء أن مكتبة الموازاة أو الأخرى
خيار أفضل في تطبيقهم.

يسمح PyTorch باختيار مؤخرة الموازاة التي تستخدمها مكتبة ATen والمكتبات الأخرى
في وقت البناء مع خيارات البناء التالية:

+------------+------------------------+-----------------------------+----------------------------------------+
| المكتبة    | خيار البناء           | القيم                       | ملاحظات                                  |
+============+========================+=============================+========================================+
| ATen       | ``ATEN_THREADING``     | ``OMP`` (افتراضي)، ``TBB``  |                                        |
+------------+------------------------+-----------------------------+----------------------------------------+
| MKL        | ``MKL_THREADING``      | (نفس الشيء)                | لتمكين MKL استخدم ``BLAS=MKL``         |
+------------+------------------------+-----------------------------+----------------------------------------+
| MKL-DNN    | ``MKLDNN_CPU_RUNTIME`` | (نفس الشيء)                | لتمكين MKL-DNN استخدم ``USE_MKLDNN=1`` |
+------------+------------------------+-----------------------------+----------------------------------------+

من المستحسن عدم خلط OpenMP و TBB داخل بناء واحد.

يتطلب أي من قيم "TBB" أعلاه إعداد البناء "USE_TBB=1" (افتراضي: OFF).
يتم استخدام إعداد منفصل "USE_OPENMP=1" (افتراضي: ON) للتوازي OpenMP.

واجهة برمجة التطبيقات في وقت التشغيل
--------------------------

تُستخدم واجهة برمجة التطبيقات التالية للتحكم في إعدادات الخيوط:

+------------------------+-----------------------------------------------------------+---------------------------------------------------------+
| نوع التوازي           | الإعدادات                                                  | ملاحظات                                                   |
+========================+===========================================================+=========================================================+
| التوازي بين العمليات  | ``at::set_num_interop_threads``،                          | عدد الخيوط الافتراضي: عدد وحدات المعالجة المركزية.         |
|                        | ``at::get_num_interop_threads`` (C++)                     |                                                         |
|                        |                                                           |                                                         |
|                        | ``set_num_interop_threads``،                              |                                                         |
|                        | ``get_num_interop_threads`` (بايثون، :mod:`torch` module) |                                                         |
+------------------------+-----------------------------------------------------------+                                                         |
| التوازي داخل العمليات  | ``at::set_num_threads``،                                  |                                                         |
|                        | ``at::get_num_threads`` (C++)                             |                                                         |
|                        | ``set_num_threads``،                                      |                                                         |
|                        | ``get_num_threads`` (بايثون، :mod:`torch` module)         |                                                         |
|                        |                                                           |                                                         |
|                        | متغيرات البيئة:                                    |                                                         |
|                        | ``OMP_NUM_THREADS`` و ``MKL_NUM_THREADS``               |                                                         |
+------------------------+-----------------------------------------------------------+---------------------------------------------------------+

بالنسبة لإعدادات التوازي داخل العمليات، فإن ``at::set_num_threads``، ``torch.set_num_threads`` لها الأسبقية دائمًا
على متغيرات البيئة، ويأخذ متغير "MKL_NUM_THREADS" الأسبقية على "OMP_NUM_THREADS".

ضبط عدد الخيوط
------------

يوضح النص البرمجي البسيط التالي كيف يتغير وقت تشغيل الضرب المصفوفة مع عدد الخيوط:

.. code-block:: python

    import timeit
    runtimes = []
    threads = [1] + [t for t in range(2, 49, 2)]
    for t in threads:
        torch.set_num_threads(t)
        r = timeit.timeit(setup = "import torch; x = torch.randn(1024, 1024); y = torch.randn(1024, 1024)", stmt="torch.mm(x, y)", number=100)
        runtimes.append(r)
    # ... التخطيط (الخيوط، runtimes) ...

ينتج عن تشغيل النص البرمجي على نظام به 24 نواة معالجة مركزية فعلية (Xeon E5-2680، بناء OpenMP و MKL) أوقات التشغيل التالية:

.. image:: cpu_threading_runtimes.svg
   :width: 75%

يجب مراعاة الاعتبارات التالية عند ضبط عدد الخيوط داخل العمليات والتوازي بين العمليات:

* عند اختيار عدد الخيوط، يجب تجنب 'الاشتراك المفرط' (استخدام عدد كبير جدًا من الخيوط، مما يؤدي إلى تدهور الأداء). على سبيل المثال، في تطبيق يستخدم بركة خيوط تطبيق كبيرة أو يعتمد اعتمادًا كبيرًا على
  التوازي بين العمليات، فقد يجد المرء تعطيل التوازي داخل العمليات كخيار ممكن (أي عن طريق استدعاء ``set_num_threads(1)``)؛

* في تطبيق نموذجي، قد تواجه مقايضة بين 'الانتظار' (الوقت المستغرق لمعالجة طلب الاستدلال) و'السرعة' (كمية العمل المنجز لكل وحدة زمنية). يمكن أن يكون ضبط عدد الخيوط أداة مفيدة
  لتعديل هذه المقايضة بطريقة أو بأخرى. على سبيل المثال، في التطبيقات الحساسة للانتظار، قد يرغب المرء في زيادة عدد الخيوط داخل العمليات لمعالجة كل طلب بأسرع ما يمكن. وفي الوقت نفسه، قد تضيف التنفيذات المتوازية
  للعمليات الحسابية عبئًا إضافيًا يزيد من مقدار العمل المنجز لكل طلب فردي، مما يقلل من السرعة الإجمالية.

.. warning::
    لا يضمن OpenMP استخدام بركة خيوط منفصلة وأحادية لكل عملية داخل العملية
    سيتم استخدامه في التطبيق. على العكس من ذلك، قد يستخدم خيطان تطبيقان أو خيطان بين العمليات
    قد تستخدم برك خيوط OpenMP مختلفة للعمل داخل العمليات.
    قد يؤدي هذا إلى استخدام عدد كبير من الخيوط بواسطة التطبيق.
    هناك حاجة إلى عناية إضافية في ضبط عدد الخيوط لتجنب
    الاشتراك المفرط في التطبيقات متعددة الخيوط في حالة OpenMP.

.. note::
    يتم تجميع إصدارات PyTorch المسبقة البناء مع دعم OpenMP.

.. note::
    تقوم أداة ``parallel_info`` بطباعة معلومات حول إعدادات الخيوط ويمكن استخدامها للتصحيح.
    يمكن الحصول على إخراج مشابه في بايثون باستخدام مكالمة ``torch.__config__.parallel_info()``.

.. _OpenMP: https://www.openmp.org/
.. _TBB: https://github.com/intel/tbb
.. _MKL: https://software.intel.com/en-us/mkl
.. _MKL-DNN: https://github.com/intel/mkl-dnn