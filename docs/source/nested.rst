torch.nested
============

.. automodule:: torch.nested

مقدمة
++++++

.. warning::

  واجهة برمجة تطبيقات PyTorch لمجموعة التوابع المضمنة هي في مرحلة النموذج الأولي وستتغير في المستقبل القريب.

تسمح NestedTensor للمستخدم بتعبئة قائمة من التوابع في بنية بيانات واحدة وكفؤة.

القيود الوحيد على التوابع المدخلة هو أن أبعادها يجب أن تتطابق.

هذا يمكن من تمثيلات بيانات وصفية أكثر كفاءة والوصول إلى نوى مخصصة الغرض.

تتمثل إحدى تطبيقات NestedTensors في التعبير عن البيانات التسلسلية في مجالات مختلفة.
بينما يتمثل النهج التقليدي في استخدام التسلسلات ذات الطول المتغير، فإن NestedTensor
تمكن المستخدمين من تجاوز الحشو. لا تختلف واجهة برمجة التطبيقات الخاصة باستدعاء العمليات على مجموعة التوابع عن تلك الخاصة بـ "tensor.Tensor" العادية، مما يسمح بالدمج السلس مع النماذج الموجودة،
مع الاختلاف الرئيسي هو: ref: `<construction> <#construction>`__.

نظرًا لأن هذه ميزة نموذج أولي، فإن العمليات المدعومة لا تزال
محدودة. ومع ذلك، نرحب بالقضايا وطلبات الميزات والمساهمات. يمكن العثور على مزيد من المعلومات حول المساهمة في
"في هذه القراءة <https://github.com/pytorch/pytorch/blob/main/aten/src/ATen/native/nested/README.md>`_".

.. _construction:

البناء
+++++

البناء مباشر ويتضمن تمرير قائمة من التوابع إلى تابع البناء "torch.nested.nested_tensor".

>>> a, b = torch.arange(3), torch.arange(5) + 3
>>> a
tensor([0, 1, 2])
>>> b
tensor([3, 4, 5, 6, 7])
>>> nt = torch.nested.nested_tensor([a, b])
>>> nt
nested_tensor([
  tensor([0, 1, 2]),
    tensor([3, 4, 5, 6, 7])
    ])

يمكن اختيار نوع البيانات والجهاز وما إذا كانت الخرائط مطلوبة عبر كلمات أساسية اختيارية المعتادة.

>>> nt = torch.nested.nested_tensor([a, b], dtype=torch.float32, device="cuda", requires_grad=True)
>>> nt
nested_tensor([
  tensor([0., 1., 2.], device='cuda:0', requires_grad=True),
  tensor([3., 4., 5., 6., 7.], device='cuda:0', requires_grad=True)
], device='cuda:0', requires_grad=True)

على غرار "torch.as_tensor"، يمكن استخدام "torch.nested.as_nested_tensor" للحفاظ على تاريخ autograd
من التوابع التي تم تمريرها إلى البناء. لمزيد من المعلومات، راجع القسم الخاص
: ref: `<constructor functions> <#ctor-func>`__.

لكي تكون مجموعة التوابع صالحة، يجب أن تتطابق جميع التوابع الممرورة في البعد، ولكن لا يلزم أن تتطابق أي من السمات الأخرى.

>>> a = torch.randn(3, 50, 70) # image 1
>>> b = torch.randn(3, 128, 64) # image 2
>>> nt = torch.nested.nested_tensor([a, b], dtype=torch.float32)
>>> nt.dim()
4

إذا لم يتطابق أحد الأبعاد، يرمي البناء خطأ.

>>> a = torch.randn(50, 128) # text 1
>>> b = torch.randn(3, 128, 64) # image 2
>>> nt = torch.nested.nested_tensor([a, b], dtype=torch.float32)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
RuntimeError: All Tensors given to nested_tensor must have the same dimension. Found dimension 3 for Tensor at index 1 and dimension 2 for Tensor at index 0.

لاحظ أن التوابع التي يتم تمريرها يتم نسخها في قطعة متجاورة من الذاكرة. تقوم مجموعة التوابع الناتجة
بتخصيص ذاكرة جديدة لتخزينها ولا تحتفظ بأي مرجع.

في الوقت الحالي، ندعم مستوى واحد من التضمين فقط، أي قائمة مسطحة بسيطة من التوابع. في المستقبل
يمكننا إضافة دعم لمستويات متعددة من التضمين، مثل قائمة تتكون بالكامل من قوائم التوابع.
لاحظ أنه بالنسبة لهذا التمديد، من المهم الحفاظ على مستوى متساوٍ من التضمين عبر الإدخالات بحيث يكون لمجموعة التوابع الناتجة
بعد محدد جيدًا. إذا كنت بحاجة إلى هذه الميزة، فيرجى تشجيعك على فتح طلب ميزة حتى نتمكن من تتبعها والتخطيط وفقًا لذلك.

الحجم
++++

على الرغم من أن مجموعة التوابع لا تدعم "size()" (أو "shape")، إلا أنها تدعم "size(i)" إذا كان البعد i منتظمًا.

>>> a = torch.randn(50, 128) # text 1
>>> b = torch.randn(32, 128) # text 2
>>> nt = torch.nested.nested_tensor([a, b], dtype=torch.float32)
>>> nt.size(0)
2
>>> nt.size(1)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
RuntimeError: Given dimension 1 is irregular and does not have a size.
>>> nt.size(2)
128

إذا كانت جميع الأبعاد منتظمة، فإن مجموعة التوابع المقصودة هي دلالياً لا يمكن تمييزها عن "tensor.Tensor" العادي.

>>> a = torch.randn(20, 128) # text 1
>>> nt = torch.nested.nested_tensor([a, a], dtype=torch.float32)
>>> nt.size(0)
2
>>> nt.size(1)
20
>>> nt.size(2)
128
>>> torch.stack(nt.unbind()).size()
torch.Size([2, 20, 128])
>>> torch.stack([a, a]).size()
torch.Size([2, 20, 128])
>>> torch.equal(torch.stack(nt.unbind()), torch.stack([a, a]))
True

في المستقبل، قد نجعل من الأسهل اكتشاف هذا الشرط والتحويل بسلاسة.

يرجى فتح طلب ميزة إذا كنت بحاجة إلى هذه الميزة (أو أي ميزة أخرى ذات صلة في هذا الشأن).

فك التجميع
+++++++

يسمح "unbind" باسترداد عرض للمكونات.

>>> import torch
>>> a = torch.randn(2, 3)
>>> b = torch.randn(3, 4)
>>> nt = torch.nested.nested_tensor([a, b], dtype=torch.float32)
>>> nt
nested_tensor([
  tensor([[ 1.2286, -1.2343, -1.4842],
          [-0.7827,  0.6745,  0.0658]]),
  tensor([[-1.1247, -0.4078, -1.0633,  0.8083],
          [-0.2871, -0.2980,  0.5559,  1.9885],
          [ 0.4074,  2.4855,  0.0733,  0.8285]])
])
>>> nt.unbind()
(tensor([[ 1.2286, -1.2343, -1.4842],
        [-0.7827,  0.6745,  0.0658]]), tensor([[-1.1247, -0.4078, -1.0633,  0.8083],
        [-0.2871, -0.2980,  0.5559,  1.9885],
        [ 0.4074,  2.4855,  0.0733,  0.8285]]))
>>> nt.unbind()[0] is not a
True
>>> nt.unbind()[0].mul_(3)
tensor([[ 3.6858, -3.7030, -4.4525],
        [-2.3481,  2.0236,  0.1975]])
>>> nt
nested_tensor([
  tensor([[ 3.6858, -3.7030, -4.4525],
          [-2.3481,  2.0236,  0.1975]]),
  tensor([[-1.1247, -0.4078, -1.0633,  0.8083],
          [-0.2871, -0.2980,  0.5559,  1.9885],
          [ 0.4074,  2.4855,  0.0733,  0.8285]])
])

لاحظ أن "nt.unbind()[0]" ليس نسخة، ولكنه شريحة من الذاكرة الأساسية، والتي تمثل الإدخال الأول أو المكون لمجموعة التوابع.

.. _constructor functions:

تابع بناء مجموعة التوابع ووظائف التحويل
+++++++++++++++++++++++++++

الوظائف التالية مرتبطة بمجموعة التوابع المضمنة:

.. currentmodule:: torch.nested

.. autofunction:: nested_tensor
.. autofunction:: as_nested_tensor
.. autofunction:: to_padded_tensor

.. _supported operations:

العمليات المدعومة
+++++++++++

في هذا القسم، نلخص العمليات المدعومة حاليًا على
NestedTensor وأي قيود عليها.

.. csv-table::
   :header: "عملية PyTorch", "قيود"
   :widths: 30, 55
   :delim: ;

   :func:`torch.matmul`;  "يدعم الضرب المصفوفي بين مجموعتين من التوابع (>= 3d) حيث
   الأبعاد الأخيرة هي أبعاد المصفوفة والأبعاد الأولى (batch) لها نفس الحجم
   (أي لا يوجد دعم للبث الإذاعي لأبعاد الدفعة حتى الآن)."
   :func:`torch.bmm`; "يدعم ضرب المصفوفة الدُفعي لمجموعتين من التوابع 3-d."
   :func:`torch.nn.Linear`;  "يدعم الإدخال 3-d المضمن ومصفوفة الوزن الكثيفة 2-d."
   :func:`torch.nn.functional.softmax`; "يدعم softmax على طول جميع الأبعاد باستثناء dim=0."
   :func:`torch.nn.Dropout`; "السلوك هو نفسه كما في التوابع العادية."
   :func:`torch.Tensor.masked_fill`; "السلوك هو نفسه كما في التوابع العادية."
   :func:`torch.relu`; "السلوك هو نفسه كما في التوابع العادية."
   :func:`torch.gelu`; "السلوك هو نفسه كما في التوابع العادية."
   :func:`torch.silu`; "السلوك هو نفسه كما في التوابع العادية."
   :func:`torch.abs`; "السلوك هو نفسه كما في التوابع العادية."
   :func:`torch.sgn`; "السلوك هو نفسه كما في التوابع العادية."
   :func:`torch.logical_not`; "السلوك هو نفسه كما في التوابع العادية."
   :func:`torch.neg`; "السلوك هو نفسه كما في التوابع العادية."
   :func:`torch.sub`; "يدعم الطرح العنصري لمجموعتين من التوابع."
   :func:`torch.add`; "يدعم الجمع العنصري لمجموعتين من التوابع. يدعم إضافة قيمة قياسية إلى مجموعة التوابع."
   :func:`torch.mul`; "يدعم الضرب العنصري لمجموعتين من التوابع. يدعم ضرب مجموعة التوابع في قيمة قياسية."
   :func:`torch.select`; "يدعم الاختيار على طول جميع الأبعاد."
   :func:`torch.clone`; "السلوك هو نفسه كما في التوابع العادية."
   :func:`torch.detach`; "السلوك هو نفسه كما في التوابع العادية."
   :func:`torch.unbind`; "يدعم فك التجميع على طول ``dim=0`` فقط."
   :func:`torch.reshape`; "يدعم إعادة التشكيل مع حجم ``dim=0`` المحفوظ (أي لا يمكن تغيير عدد التوابع المضمنة).
   على عكس التوابع العادية، يعني الحجم "1" هنا أن الحجم الحالي موروث.
   على وجه الخصوص، الحجم الصالح الوحيد للبعد غير المنتظم هو "1".
   لم يتم تنفيذ استدلال الحجم بعد وبالتالي لا يمكن أن يكون الحجم "1" للأبعاد الجديدة."
   :func:`torch.Tensor.reshape_as`; "قيد مماثل كما هو الحال بالنسبة لـ ``reshape``."
   :func:`torch.transpose`; "يدعم التحويل عبر جميع الأبعاد باستثناء ``dim=0``."
   :func:`torch.Tensor.view`; "القواعد الخاصة بشكل جديد مماثلة لتلك الخاصة بـ ``reshape``."
   :func:`torch.empty_like`; "السلوك مماثل لذلك في التوابع العادية؛ يعيد مجموعة التوابع الفارغة الجديدة (أي مع القيم غير المستهلة) التي تتطابق مع البنية المضمنة للإدخال."
   :func:`torch.randn_like`; "السلوك مماثل لذلك في التوابع العادية؛ يعيد مجموعة التوابع مع القيم التي يتم تهيئتها بشكل عشوائي وفقًا لتوزيع عادي قياسي يتطابق مع البنية المضمنة للإدخال."
   :func:`torch.zeros_like`; "السلوك مماثل لذلك في التوابع العادية؛ يعيد مجموعة التوابع ذات القيم الصفرية التي تتطابق مع البنية المضمنة للإدخال."
   :func:`torch.nn.LayerNorm`; "الحجة ``normalized_shape`` مقيدة بعدم الامتداد إلى الأبعاد غير المنتظمة لمجموعة التوابع."