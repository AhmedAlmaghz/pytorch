.. _torchinductor-gpu-profiling:

تحليل أداء وحدة معالجة الرسومات (GPU) في تورتش إندكتور
===========================================

يسرد هذا القسم الأوامر وتدفقات العمل المفيدة التي يمكن أن تساعدك في الغوص في أداء نموذج ما في تورتش إندكتور. عندما لا يعمل نموذج ما بالسرعة المتوقعة، فقد ترغب في التحقق من نوى فردية للنموذج. عادة ما تكون النوى التي تستغرق معظم وقت وحدة معالجة الرسومات هي الأكثر أهمية. بعد ذلك، قد ترغب أيضًا في تشغيل نوى فردية مباشرة وفحص أدائها. توفر باي تورتش أدوات لتغطية كل ما سبق ذكره.

متغيرات البيئة ذات الصلة
~~~~~~~~~~~~~~~~~~~

يمكنك استخدام متغيرات البيئة التالية في تحليلك:

-  ``TORCHINDUCTOR_UNIQUE_KERNEL_NAMES``

   -  بشكل افتراضي، تقوم تورتش إندكتور بتسمية نواة ترايتون باسم ``'triton_'``. عندما يتم تمكين هذه المتغير البيئي، يقوم المحفز بتوليد اسم نواة أكثر دلالة في التعقب، على سبيل المثال، ``triton_poi_fused_cat_155`` والذي يحتوي على فئة النواة (``poi`` للعمليات النقطية) والمشغل الأصلي لـ إيتن. يتم تعطيل هذا الإعداد بشكل افتراضي لتحسين فرصة إصابة ذاكرة التخزين المؤقت للتجميع.

-  ``TORCHINDUCTOR_BENCHMARK_KERNEL``

   -  سيتسبب تمكين هذا الإعداد في قيام محفز كودجن بتقييم نوى ترايتون الفردية.

-  ``TORCHINDUCTOR_MAX_AUTOTUNE``

   -  سيقوم محسن تورتش إندكتور بتقييم المزيد من تكوينات ترايتون واختيار التكوين الذي يحقق أفضل نتائج للأداء. سيؤدي هذا إلى زيادة وقت التجميع على أمل تحسين الأداء.

تحليل وقت وحدة معالجة الرسومات للنموذج
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

فيما يلي الخطوات لتحليل وقت التنفيذ لنموذج ما إلى نوى فردية. نأخذ ``mixnet_l`` كمثال.

1. قم بتشغيل نص البرنامج النصي للمقارنة المرجعية للنموذج:

   .. code-block:: bash

      TORCHINDUCTOR_UNIQUE_KERNEL_NAMES=1 TORCHINDUCTOR_BENCHMARK_KERNEL=1
      python -u benchmarks/dynamo/timm_models.py –backend inductor –amp
      –performance –dashboard –only mixnet_l –disable-cudagraphs –training

   .. note:: تعتمد الأداة على اسم النواة لتحديد فئتها. تمكين ``TORCHINDUCTOR_UNIQUE_KERNEL_NAMES`` أمر بالغ الأهمية لذلك.

2. في سجل الإخراج، ابحث عن الأسطر التالية:

   .. code-block:: bash

      **مسار الوحدة المجمعة:
      /tmp/torchinductor_shunting/qz/cqz7hvhood7y3psp7fy6msjxsxyli7qiwiybizdwtjw6ffyq5wwd.py**

لدينا سطر واحد لكل وحدة مجمعة. إذا لم تكن هناك فواصل رسومية إضافية، فسنرى سطرين مثل هذا في السجل، أحدهما للرسم البياني للأمام والآخر للرسم البياني الخلفي.

بالنسبة لأمر المثال الخاص بنا، نحصل على الوحدة المجمعة التالية للرسم البياني للأمام والخلف على التوالي:

-  https://gist.github.com/shunting314/c2a4d8a28b00fcb5586d0e9d9bf77f9f
-  https://gist.github.com/shunting314/48efc83b12ec3ead950052e4a0220b10

3. الآن يمكننا الغوص في الأداء لكل وحدة مجمعة فردية. دعنا نختار الوحدة المجمعة للرسم البياني للأمام لأغراض التوضيح. سأطلق عليه اسم ``fwd.py`` لسهولة الاستخدام. قم بتشغيله مباشرة باستخدام الحجة ``-p``:

   .. code-block:: bash

      **> python fwd.py -p**

راجع سجل الإخراج الكامل في هذا
`مثال جست <https://gist.github.com/shunting314/8243734a38b5733ea78479209c0ae893>`__.

في الإخراج، يمكنك ملاحظة ما يلي:

* نكتب ملف تعقب كروم لملف التعريف حتى نتمكن من تحميل التعقب والتفاعل معه. في السجل، ابحث عن الأسطر التالية للعثور على مسار ملف التعقب:

 **تم كتابة تعقب كروم للملف الشخصي إلى
 /tmp/compiled_module_profile.json**

 سيؤدي تحميل التعقب في كروم (قم بزيارة chrome://tracing في متصفح كروم وتحميل الملف كما اقترح واجهة المستخدم) إلى عرض واجهة المستخدم على النحو التالي:

 .. image:: _static/img/inductor_profiling/trace.png

 يمكنك التكبير والتصغير للتحقق من الملف الشخصي.

* نقوم بالإبلاغ عن النسبة المئوية لوقت وحدة معالجة الرسومات فيما يتعلق بوقت الحائط عن طريق سطر سجل مثل:

  **النسبة المئوية للوقت عندما تكون وحدة معالجة الرسومات مشغولة: 102.88%**

  في بعض الأحيان، قد ترى قيمة أكبر من 100%. والسبب هو أن باي تورتش يستخدم وقت تنفيذ النواة مع تمكين التعريف أثناء استخدام وقت الحائط مع إيقاف تشغيل التعريف. قد يشوه التعريف وقت تنفيذ النواة قليلاً. ولكن بشكل عام، لا ينبغي أن يكون الأمر مهمًا.

  إذا قمنا بتشغيل نموذج مثل ``densenet121`` بحجم دفعة صغير، فسنرى
  نسبة مئوية منخفضة من الوقت عندما تكون وحدة معالجة الرسومات مشغولة:

  ::

     (الرسم البياني للأمام) النسبة المئوية للوقت عندما تكون وحدة معالجة الرسومات مشغولة: 32.69%

  هذا يعني أن النموذج لديه الكثير من النفقات العامة للمعالج. هذا يتسق مع
  حقيقة أن تمكين cudagraphs يحسن أداء densenet121 بشكل كبير.

* يمكننا تحليل وقت وحدة معالجة الرسومات إلى فئات مختلفة من النواة.
  في مثال ``mixnet_l``، نرى

  -  تأخذ النواة النقطية 28.58%
  -  تأخذ نواة التخفيض 13.85%
  -  تأخذ نواة التخفيض المستمر 3.89%
  -  الباقي عبارة عن نوى كوداس/كودن لعمليات الضرب/التنفيذ التي تستغرق 56.57%

  يمكن العثور على هذه المعلومات في سطر الملخص (السطر الأخير)
  من التقرير لكل فئة نواة.

* يمكننا أيضًا التكبير في فئة معينة من النواة. على سبيل المثال،
  دعنا نتحقق من نوى التخفيض:

  .. image:: _static/img/inductor_profiling/kernel_breakdown.png

  يمكننا أن نرى جدولًا مرتبًا لوقت التنفيذ لكل نواة تخفيض فردية. نرى أيضًا عدد المرات التي يتم فيها تنفيذ نواة ما. هذا
  مفيد لعدة أسباب:

  - إذا كانت النواة تستغرق قدرًا ضئيلًا من الوقت، على سبيل المثال، 0.1%،
    فإن تحسينها سيؤدي إلى تحقيق مكاسب إجمالية قدرها 0.1% كحد أقصى. لا يستحق الأمر بذل الكثير من الجهد.
  - إذا كانت النواة تستغرق 2% من الوقت، فإن تحسينها بمقدار الضعف سيؤدي إلى تحقيق مكاسب إجمالية قدرها 1%
    مما يبرر الجهد المبذول.

تقييم نواة ترايتون الفردية
~~~~~~~~~~~~~~~~~~~~~~~~~~

لنفترض أننا نريد إلقاء نظرة فاحصة على
``triton_red_fused\__native_batch_norm_legit_functional_16`` والتي تعد أغلى نواة تخفيض وتستغرق 2.19% من إجمالي وقت الحائط للرسم البياني للأمام.

يمكننا البحث عن اسم النواة في ``fwd.py``، والعثور على تعليق مثل:

**# مسار النواة:
/tmp/torchinductor_shunting/jk/cjk2vm3446xrk7rth7hr6pun7xxo3dnzubwcn6ydrpifal4eykrz.py**

.. image:: _static/img/inductor_profiling/inductor_code.png

سأعيد تسميته بـ k.py لسهولة الاستخدام. إليك رابط لهذا
`الملف <https://gist.github.com/shunting314/96a0afef9dce53d6357bf1633094f358>`__.

``k.py`` هي وحدة بايثون قائمة بذاتها تحتوي على رمز النواة وتقييمها.

سيؤدي تشغيل ``k.py`` مباشرة إلى الإبلاغ عن وقت التنفيذ وعرض النطاق الترددي:

.. image:: _static/img/inductor_profiling/terminal_printout.png

يمكننا التحقق مما إذا كان الحد الأقصى للضبط التلقائي يساعد هذه النواة، عن طريق تشغيل:

.. code-block:: bash

   **TORCHINDUCTOR_MAX_AUTOTUNE=1 python /tmp/k.py**

قد نقوم أيضًا بإضافة المزيد من خوارزميات التخفيض مؤقتًا وتشغيل النص البرمجي
مرة أخرى للتحقق من مدى فائدة ذلك في النواة.