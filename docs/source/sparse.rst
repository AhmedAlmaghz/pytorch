.. automodule:: torch.sparse

.. currentmodule:: torch

.. _sparse-docs:

torch.sparse
=================
تحذير
======

واجهة برمجة التطبيقات PyTorch للتوابع المتقطعة هي حاليًا في مرحلة البيتا وقد تتغير في المستقبل القريب. نرحب بجميع طلبات الميزات وتقارير الأخطاء والاقتراحات العامة كقضايا على GitHub.

لماذا ومتى تستخدم التفرقة
++++++++++++++++++

بشكل افتراضي، يقوم PyTorch بتخزين عناصر :class: `torch.Tensor` بشكل متجاور في الذاكرة المادية. يؤدي هذا إلى تنفيذ فعال لمختلف خوارزميات معالجة المصفوفة التي تتطلب الوصول السريع إلى العناصر.

الآن، قد يقرر بعض المستخدمين تمثيل البيانات مثل مصفوفات المجاورة للرسم البياني، أو الأوزان المقصوصة أو نقاط السحب بواسطة المتوترات التي *معظم قيم العناصر فيها تساوي الصفر*. ندرك أن هذه هي تطبيقات مهمة ونهدف إلى توفير تحسينات للأداء لهذه الحالات الاستخدامية من خلال تنسيقات التخزين المتقطعة.

تم تطوير تنسيقات التخزين المتقطعة المختلفة مثل COO وCSR/CSC وsemi-structured وLIL، إلخ. على مر السنين. على الرغم من اختلافها في التخطيطات الدقيقة، إلا أنها جميعًا تضغط البيانات من خلال التمثيل الفعال لعناصر القيمة الصفرية.

نطلق على القيم غير المضغوطة اسم *محددة* على عكس العناصر المضغوطة، غير المحددة.

من خلال ضغط أصفار متكررة، تهدف تنسيقات التخزين المتقطعة إلى توفير الذاكرة والموارد الحسابية على وحدات المعالجة المركزية ووحدات معالجة الرسومات المختلفة. خاصة بالنسبة لدرجات عالية من التفرقة أو التفرقة المنظمة للغاية، يمكن أن يكون لهذا آثار كبيرة على الأداء. وبالتالي، يمكن اعتبار تنسيقات التخزين المتقطعة كتحسين للأداء.

مثل العديد من تحسينات الأداء الأخرى، قد لا تكون تنسيقات التخزين المتقطعة مفيدة دائمًا. عند تجربة التنسيقات المتقطعة لحالتك الاستخدامية، قد تجد أن وقت التنفيذ يزيد بدلاً من أن ينقص.

يرجى الشعور بالتشجيع على فتح قضية GitHub إذا كنت تتوقع من الناحية التحليلية رؤية زيادة كبيرة في الأداء ولكنك قمت بقياس التدهور بدلاً من ذلك. يساعدنا هذا في تحديد أولويات تنفيذ نوى فعالة وتحسينات أداء أوسع.

نجعل من السهل تجربة تخطيطات التفرقة المختلفة، والتحويل بينها، دون أن يكون لدينا رأي بشأن ما هو الأفضل لتطبيقك المحدد.

نظرة عامة على الوظائف
++++++++++++++++++++++

نريد أن يكون من السهل إنشاء Tensor متقطع من Tensor كثيف معين من خلال توفير روتينات التحويل لكل تخطيط.

في المثال التالي، نقوم بتحويل Tensor ثنائي الأبعاد بتنسيق كثيف (متدرج) افتراضي إلى Tensor ثنائي الأبعاد مدعوم بتنسيق الذاكرة COO. في هذه الحالة، يتم تخزين قيم وفهارس العناصر غير الصفرية فقط.
::
    >>> a = torch.tensor([[0, 2.], [3, 0]])
    >>> a.to_sparse()
    tensor(indices=tensor([[0, 1],
                           [1, 0]]),
           values=tensor([2., 3.]),
           size=(2, 2), nnz=2, layout=torch.sparse_coo)

يدعم PyTorch حاليًا :ref: `COO <sparse-coo-docs>`__، :ref: `CSR <sparse-csr-docs>`__، :ref: `CSC <sparse-csc-docs>`__، :ref: `BSR <sparse-bsr-docs>`__، و:ref: `BSC <sparse-bsc-docs>`__.

لدينا أيضًا تنفيذ نموذجي لدعم :ref: `التفرقة شبه المنظمة <sparse-semi-structured-docs>`__. يرجى الاطلاع على المراجع لمزيد من التفاصيل.

لاحظ أننا نقدم تعميمات طفيفة لهذه التنسيقات.

الدفعات: تتطلب الأجهزة مثل وحدات معالجة الرسومات (GPU) الدفعات لتحقيق الأداء الأمثل، وبالتالي فإننا ندعم أبعاد الدفعات.

نقدم حاليًا إصدارًا بسيطًا جدًا من الدفعات حيث يتم تجميع كل مكون من مكونات التنسيق المتقطع نفسه. يتطلب هذا أيضًا نفس عدد العناصر المحددة لكل إدخال دفعي. في هذا المثال، نقوم ببناء Tensor ثلاثي الأبعاد (مجمّع) بتنسيق CSR من Tensor ثلاثي الأبعاد كثيف.

::
    >>> t = torch.tensor([[[1.، 0]، [2.، 3.]], [[4.، 0]، [5.، 6.]]])
    >>> t.dim()
    3
    >>> t.to_sparse_csr()
    tensor(crow_indices=tensor([[0, 1, 3],
                                [0, 1, 3]]),
           col_indices=tensor([[0, 0, 1],
                               [0, 0, 1]]),
           values=tensor([[1.، 2.، 3.]،
                          [4.، 5.، 6.]])، size=(2، 2، 2)، nnz=3،
           layout=torch.sparse_csr)


الأبعاد الكثيفة: من ناحية أخرى، قد يكون من الأفضل النظر إلى بعض البيانات، مثل Graph embeddings، على أنها مجموعات متقطعة من المتجهات بدلاً من المقاييس.

في هذا المثال، نقوم بإنشاء Tensor ثلاثي الأبعاد بتنسيق Hybrid COO مع بعدين متفرقين وبعد كثيف واحد من Tensor ثلاثي الأبعاد متدرج. إذا كان صف بأكمله في Tensor ثلاثي الأبعاد متدرج يساوي صفرًا، فلن يتم تخزينه. ومع ذلك، إذا كانت أي من القيم في الصف غير صفرية، فسيتم تخزينها بالكامل. يقلل هذا من عدد الفهارس نظرًا لأننا نحتاج إلى فهرس واحد لكل صف بدلاً من واحد لكل عنصر. ولكنه يزيد أيضًا من كمية التخزين للقيم. نظرًا لأنه يمكن فقط إهمال الصفوف التي تكون *تمامًا* صفرًا وأن وجود أي عناصر ذات قيمة غير صفرية يتسبب في تخزين الصف بأكمله.

::
    >>> t = torch.tensor([[[0.، 0]، [1.، 2.]], [[0.، 0]، [3.، 4.]]])
    >>> t.to_sparse(sparse_dim=2)
    tensor(indices=tensor([[0, 1],
                           [1, 1]]),
           values=tensor([[1., 2.],
                          [3., 4.]]),
           size=(2, 2, 2), nnz=2, layout=torch.sparse_coo)


نظرة عامة على المشغل
+++++++++++++++++

من الناحية الأساسية، فإن العمليات على Tensor بتنسيقات التخزين المتقطعة تتصرف بنفس طريقة العمليات على Tensor بتنسيقات التخزين المتدرجة (أو غيرها). تؤثر خصوصيات التخزين، أي التخطيط المادي للبيانات، على أداء عملية ما ولكن لا يجب أن تؤثر على الدلالات.


نعمل بنشاط على زيادة تغطية المشغل للمتوترات المتقطعة. لا ينبغي للمستخدمين أن يتوقعوا نفس مستوى الدعم كما هو الحال بالنسبة للمتوترات الكثيفة بعد.

راجع وثائق :ref: `operator <sparse-ops-docs>`__ للحصول على قائمة.
::
    >>> b = torch.tensor([[0، 0، 1، 2، 3، 0]، [4، 5، 0، 6، 0، 0]])
    >>> b_s = b.to_sparse_csr()
    >>> b_s.cos()
    Traceback (أحدث استدعاء أولاً):
      File "<stdin>"، line 1، in <module>
    RuntimeError: تخطيط Tensor غير مدعوم: SparseCsr
    >>> b_s.sin()
    tensor(crow_indices=tensor([0، 3، 6])،
           col_indices=tensor([2، 3، 4، 0، 1، 3])،
           values=tensor([0.8415، 0.9093، 0.1411، -0.7568، -0.9589، -0.2794])،
           size=(2، 6)، nnz=6، layout=torch.sparse_csr)

كما هو موضح في المثال أعلاه، لا ندعم المشغلين أحاديين غير الصفر مثل cos. لن تتمكن نتيجة عملية أحادية غير صحيحة من الاستفادة من تنسيقات التخزين المتقطعة بنفس القدر مثل الإدخال وقد تؤدي إلى زيادة كارثية في الذاكرة. نعتمد بدلاً من ذلك على المستخدم لتحويله بشكل صريح إلى Tensor كثيف أولاً ثم تشغيل العملية.
::
    >>> b_s.to_dense().cos()
    tensor([[1.0000، -0.4161]،
            [-0.9900، 1.0000]])

نحن ندرك أن بعض المستخدمين يريدون تجاهل الأصفار المضغوطة للعمليات مثل `cos` بدلاً من الحفاظ على الدلالات الدقيقة للعملية. لهذا يمكننا الإشارة إلى torch.masked وMaskedTensor الخاص به، والذي يتم تشغيله بدوره أيضًا بواسطة تنسيقات التخزين المتقطعة والنوى.

لاحظ أيضًا أنه، في الوقت الحالي، لا يملك المستخدم خيار تخطيط الإخراج. على سبيل المثال، يؤدي إضافة Tensor متقطع إلى Tensor متدرج عادي إلى Tensor متدرج. قد يفضل بعض المستخدمين أن يظل هذا متقطعًا، لأنهم يعرفون أن النتيجة ستظل متقطعة بدرجة كافية.
::
    >>> a + b.to_sparse()
    tensor([[0.، 3.]،
            [3.، 0.]])

نحن ندرك أن الوصول إلى نوى يمكنها إنتاج تخطيطات إخراج مختلفة يمكن أن يكون مفيدًا جدًا. قد تستفيد العملية اللاحقة بشكل كبير من تلقي تخطيط معين. نعمل على واجهة برمجة تطبيقات للتحكم في تخطيط النتيجة ونعترف بأنها ميزة مهمة لتخطيط مسار تنفيذ أكثر مثالية لأي نموذج معين.

.. _sparse-semi-structured-docs:

المتوترات المتقطعة شبه المنظمة
++++++++++++++++++++++

.. تحذير ::

   المتوترات المتقطعة شبه المنظمة هي ميزة نموذج أولي حاليًا وقد تتغير. لا تتردد في فتح قضية للإبلاغ عن خطأ أو إذا كان لديك ملاحظات لمشاركتها.

التفرقة شبه المنظمة هي تخطيط بيانات متقطع تم تقديمه لأول مرة في بنية Ampere من NVIDIA. يُشار إليها أيضًا باسم **التفرقة المنظمة الدقيقة** أو **التفرقة المنظمة 2:4**.

يقوم هذا التخطيط المتقطع بتخزين `n` عنصر من كل `2n` عنصر، حيث يتم تحديد `n` بواسطة عرض نوع بيانات Tensor (dtype). نوع البيانات الأكثر استخدامًا هو float16، حيث `n=2`، وبالتالي مصطلح "التفرقة المنظمة 2:4".

تم شرح التفرقة شبه المنظمة بالتفصيل في `منشور مدونة NVIDIA هذا <https://developer.nvidia.com/blog/exploiting-ampere-structured-sparsity-with-cusparselt>`__.

في PyTorch، يتم تنفيذ التفرقة شبه المنظمة عبر Subclass Tensor.

من خلال التفرقة، يمكننا تجاوز ``__torch_dispatch__``، مما يسمح لنا باستخدام نوى متقطعة أسرع عند إجراء ضرب المصفوفة.

يمكننا أيضًا تخزين المتوتر في شكله المضغوط داخل Subclass لتقليل النفقات العامة للذاكرة.

في هذا الشكل المضغوط، يتم تخزين المتوتر المتقطع عن طريق الاحتفاظ فقط بالعناصر *المحددة* وبعض البيانات الوصفية، والتي ترمّز القناع.

.. ملاحظة ::

   يتم تخزين العناصر المحددة والبيانات الوصفية للقناع لمتوتر شبه منظم متقطع معًا في Tensor مضغوط واحد. يتم ضمها إلى بعضها البعض لتشكيل كتلة متجاورة من الذاكرة.

   Tensor المضغوط = [عناصر محددة للمتوتر الأصلي | قناع البيانات الوصفية]

   بالنسبة إلى Tensor بحجم `(r، c)`، نتوقع أن تكون العناصر `m * k // 2` الأولى هي العناصر المحتفظ بها
   والباقي عبارة عن بيانات وصفية.

   لتسهيل الأمر على المستخدم لعرض العناصر المحددة
   والقناع، يمكنك استخدام ``.indices()`` و ``.values()`` للوصول إلى القناع والعناصر المحددة على التوالي.


   - ``.values()`` يعيد العناصر المحددة في Tensor بحجم `(r، c // 2)` وبنفس النوع مثل المصفوفة الكثيفة.

   - ``.indices()`` يعيد قناع البيانات الوصفية في Tensor بحجم `(r، c // 2)` ونوع العنصر ``torch.int16`` إذا كان النوع dtype هو torch.float16 أو torch.bfloat16، ونوع العنصر ``torch.int32`` إذا كان النوع dtype هو torch.int8.


بالنسبة للمتوترات المتقطعة 2:4، فإن النفقات العامة للبيانات الوصفية طفيفة - مجرد 2 بت لكل عنصر محدد.

.. ملاحظة ::

   من المهم ملاحظة أن ``torch.float32`` مدعوم فقط للتفرقة 1:2. لذلك، لا يتبع نفس الصيغة الموضحة أعلاه.

هنا، نقوم بتفصيل كيفية حساب نسبة الضغط (حجم الكثيف / حجم المتقطع) لمتوتر 2:4 متقطع.

دع `(r، c) = tensor.shape` و `e = bitwidth (tensor.dtype)`، لذا `e = 16` لـ ``torch.float16`` و ``torch.bfloat16`` و `e = 8` لـ ``torch.int8``.

.. math ::

   M_ {dense} = r \ times c \ times e \\
   M_ {sparse} = M_ {specified} + M_ {metadata} = r \ times \ frac {c} {2} \ times e + r \ times \ frac {c} {2} \ times 2 = \ frac {rce} {2} + rc = rce (\ frac {1} {2} + \ frac {1} {e})

باستخدام هذه الحسابات، يمكننا تحديد البصمة الكلية للذاكرة لكل من التمثيل الكثيف الأصلي والتمثيل المتقطع الجديد.

هذا يعطينا صيغة بسيطة لنسبة الضغط، والتي تعتمد فقط على عرض بت نوع بيانات المتوتر.

.. math ::

   C = \ frac {M_ {sparse}} {M_ {dense}} = \ frac {1} {2} + \ frac {1} {e}

باستخدام هذه الصيغة، نجد أن نسبة الضغط تبلغ 56.25٪ لـ ``torch.float16`` أو ``torch.bfloat16``، و 62.5٪ لـ ``torch.int8``.

بناء المتوترات المتقطعة شبه المنظمة
يمكنك تحويل مصفوفة كثيفة إلى مصفوفة شبه منظمة نادرة ببساطة باستخدام دالة ``torch.to_sparse_semi_structured``.

يرجى ملاحظة أننا ندعم فقط المصفوفات CUDA حيث أن التوافق مع الأجهزة لقابلية الضغط شبه المنظمة محدود في وحدات معالجة الرسومات NVIDIA.

تُدعم أنواع البيانات التالية لقابلية الضغط شبه المنظمة. لاحظ أن لكل نوع بيانات قيوده الخاصة على الشكل وعامل الضغط.

.. csv-table::
   :header: "نوع بيانات PyTorch", "قيود الشكل", "عامل الضغط", "نمط الضغط"
   :widths: 15, 45, 10, 10
   :delim: ;

   ``torch.float16``; يجب أن تكون المصفوفة ثنائية الأبعاد ويجب أن يكون كل من (r, c) مضاعفًا إيجابيًا لـ 64؛9/16؛2:4
   ``torch.bfloat16``; يجب أن تكون المصفوفة ثنائية الأبعاد ويجب أن يكون كل من (r, c) مضاعفًا إيجابيًا لـ 64؛9/16؛2:4
   ``torch.int8``; يجب أن تكون المصفوفة ثنائية الأبعاد ويجب أن يكون كل من (r, c) مضاعفًا إيجابيًا لـ 128؛10/16؛2:4

لإنشاء مصفوفة نادرة شبه منظمة، ابدأ بإنشاء مصفوفة كثيفة عادية تلتزم بتنسيق 2:4 (أو شبه منظم).
للقيام بذلك، نقوم ببلاط قطاع صغير 1x4 لإنشاء مصفوفة كثيفة float16 بحجم 16x16.
بعد ذلك، يمكننا استدعاء دالة ``to_sparse_semi_structured`` لضغطها من أجل الاستدلال المعجل.
::
    >>> from torch.sparse import to_sparse_semi_structured
    >>> A = torch.Tensor([0, 0, 1, 1]).tile((128, 32)).half().cuda()
    tensor([[0., 0., 1.,  ..., 0., 1., 1.],
            [0., 0., 1.,  ..., 0., 1., 1.],
            [0., 0., 1.,  ..., 0., 1., 1.],
            ...,
            [0., 0., 1.,  ..., 0., 1., 1.],
            [0., 0., 1.,  ..., 0., 1., 1.],
            [0., 0., 1.,  ..., 0., 1., 1.]], device='cuda:0', dtype=torch.float16)
    >>> A_sparse = to_sparse_semi_structured(A)
    SparseSemiStructuredTensor(shape=torch.Size([128, 128]), transposed=False, values=tensor([[1., 1., 1.,  ..., 1., 1., 1.],
            [1., 1., 1.,  ..., 1., 1., 1.],
            [1., 1., 1.,  ..., 1., 1., 1.],
            ...,
            [1., 1., 1.,  ..., 1., 1., 1.],
            [1., 1., 1.,  ..., 1., 1., 1.],
            [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0', dtype=torch.float16), metadata=tensor([[-4370, -4370, -4370,  ..., -4370, -4370, -4370],
            [-4370, -4370, -4370,  ..., -4370, -4370, -4370],
            [-4370, -4370, -4370,  ..., -4370, -4370, -4370],
            ...,
            [-4370, -4370, -4370,  ..., -4370, -4370, -4370],
            [-4370, -4370, -4370,  ..., -4370, -4370, -4370],
            [-4370, -4370, -4370,  ..., -4370, -4370, -4370]], device='cuda:0',
    dtype=torch.int16))

العمليات شبه المنظمة للمصفوفات النادرة
-------------------------------

تدعم العمليات التالية حاليًا المصفوفات النادرة شبه المنظمة:

- torch.addmm(bias, dense, sparse.t())
- torch.mm(dense, sparse)
- torch.mm(sparse, dense)
- aten.linear.default(dense, sparse, bias)
- aten.t.default(sparse)
- aten.t.detach(sparse)

لاستخدام هذه العمليات، مرر ببساطة إخراج ``to_sparse_semi_structured(tensor)`` بدلاً من استخدام ``tensor`` بمجرد أن تكون المصفوفة الخاصة بك تحتوي على أصفار بتنسيق ضغط شبه منظم، كما يلي:
::
    >>> a = torch.Tensor([0, 0, 1, 1]).tile((64, 16)).half().cuda()
    >>> b = torch.rand(64, 64).half().cuda()
    >>> c = torch.mm(a, b)
    >>> a_sparse = to_sparse_semi_structured(a)
    >>> torch.allclose(c, torch.mm(a_sparse, b))
    True

تسريع nn.Linear مع الضغط شبه المنظم
----------------------------------
يمكنك تسريع الطبقات الخطية في نموذجك إذا كانت الأوزان شبه منظمة بالفعل باستخدام الضغط النادر في بضع سطور فقط من التعليمات البرمجية:
::
    >>> input = torch.rand(64, 64).half().cuda()
    >>> mask = torch.Tensor([0, 0, 1, 1]).tile((64, 16)).cuda().bool()
    >>> linear = nn.Linear(64, 64).half().cuda()
    >>> linear.weight = nn.Parameter(to_sparse_semi_structured(linear.weight.masked_fill(~mask, 0)))

.. _sparse-coo-docs:

مصفوفات COO النادرة
++++++++++++++++++

ينفذ PyTorch ما يسمى بتنسيق الإحداثيات، أو تنسيق COO، كواحد من تنسيقات التخزين لتنفيذ المصفوفات النادرة. في تنسيق COO، يتم تخزين العناصر المحددة كمجموعات من مؤشرات العناصر والقيم المقابلة. على وجه التحديد،

  - يتم جمع مؤشرات العناصر المحددة في مصفوفة ``indices`` بحجم ``(ndim، nse)`` ونوع عنصر ``torch.int64``،

  - يتم جمع القيم المقابلة في مصفوفة ``values`` بحجم ``(nse)`` ونوع عنصر عدد صحيح أو نقطة عائمة عشوائي،

حيث ``ndim`` هو أبعاد المصفوفة و ``nse`` هو عدد العناصر المحددة.

.. note::

   تبلغ استهلاك ذاكرة مصفوفة COO النادرة 8 بايت على الأقل ``(ndim * 8 + <حجم نوع العنصر بالبايت>) * nse`` بايت (بالإضافة إلى ثابت

   تبلغ استهلاك ذاكرة المصفوفة ذات الخطوة على الأقل ``product(<شكل المصفوفة>) * <حجم نوع العنصر بالبايت>``.

   على سبيل المثال، تبلغ استهلاك ذاكرة مصفوفة 10000 × 10000 مع 100000 من الأرقام العشرية ذات 32 بت على الأقل ``(2 * 8 + 4) * 100000 = 2000000`` بايت عند استخدام تنسيق مصفوفة COO و ``10000 * 10000 * 4 = 400000000`` بايت عند استخدام تنسيق المصفوفة ذات الخطوة الافتراضية. لاحظ توفير الذاكرة بمقدار 200 ضعف من استخدام تنسيق التخزين COO.

البناء
----

يمكن بناء مصفوفة COO نادرة عن طريق توفير المصفوفتين من المؤشرات والقيم، بالإضافة إلى حجم المصفوفة النادرة (عندما لا يمكن استنتاجها من المصفوفات والمصفوفات) إلى دالة :func: `torch.sparse_coo_tensor`.

لنفترض أننا نريد تحديد مصفوفة نادرة مع الإدخال 3 في الموقع
(0، 2)، الإدخال 4 في الموقع (1، 0)، والإدخال 5 في الموقع (1، 2).
يفترض أن العناصر غير المحددة لها نفس القيمة، وهي قيمة التعبئة، والتي تكون صفرًا بشكل افتراضي. ثم نكتب:
::
    >>> i = [[0, 1, 1],
             [2, 0, 2]]
    >>> v =  [3, 4, 5]
    >>> s = torch.sparse_coo_tensor(i, v, (2, 3))
    >>> s
    tensor(indices=tensor([[0, 1, 1],
                           [2, 0, 2]]),
           values=tensor([3, 4, 5]),
           size=(2, 3), nnz=3, layout=torch.sparse_coo)
    >>> s.to_dense()
    tensor([[0, 0, 3],
            [4, 0, 5]])

لاحظ أن الإدخال "i" ليس قائمة من مجموعات المؤشرات. إذا كنت تريد
لإدخال مؤشراتك بهذه الطريقة، فيجب عليك نقلها قبل تمريرها إلى
منشئ المصفوفة النادرة:
::
    >>> i = [[0, 2], [1, 0], [1, 2]]
    >>> v =  [3,      4,      5    ]
    >>> s = torch.sparse_coo_tensor(list(zip(*i)), v, (2, 3))
    >>> # أو صيغة مكافئة أخرى للحصول على s
    >>> s = torch.sparse_coo_tensor(torch.tensor(i).t(), v, (2, 3))
    >>> torch.sparse_coo_tensor(i.t(), v، torch.Size([2،3])).to_dense()
    tensor([[0, 0, 3],
            [4, 0, 5]])

يمكن بناء مصفوفة COO نادرة فارغة عن طريق تحديد حجمها فقط:

    >>> torch.sparse_coo_tensor(size=(2, 3))
    tensor(indices=tensor([], size=(2, 0)),
           values=tensor([], size=(0,)),
           size=(2, 3), nnz=0, layout=torch.sparse_coo)

.. _sparse-hybrid-coo-docs:

مصفوفات COO الهجينة النادرة
-------------------------

ينفذ PyTorch امتدادًا للمصفوفات النادرة ذات القيم القياسية
إلى المصفوفات النادرة ذات القيم (المتصلة) للمصفوفات. تسمى هذه المصفوفات بالمصفوفات الهجينة.

توسع مصفوفة PyTorch الهجينة COO مصفوفة COO النادرة من خلال السماح
تكون مصفوفة "القيم" متعددة الأبعاد بحيث يكون لدينا:

  - يتم جمع مؤشرات العناصر المحددة في مصفوفة ``indices`` بحجم ``(sparse_dims، nse)`` ونوع عنصر ``torch.int64``،

  - يتم جمع القيم (المصفوفة) المقابلة في مصفوفة ``values`` بحجم ``(nse، dense_dims)`` ونوع عنصر عدد صحيح أو نقطة عائمة عشوائي.

.. note::

   نستخدم مصفوفة (M + K)-dimensional للإشارة إلى مصفوفة N-dimensional نادرة هجينة، حيث M و K هما عدد الأبعاد النادرة والكثيفة، على التوالي، بحيث تكون M + K == N صحيحة.

لنفترض أننا نريد إنشاء مصفوفة (2 + 1) الأبعاد مع الإدخال
[3، 4] في الموقع (0، 2)، الإدخال [5، 6] في الموقع (1، 0)، والإدخال
[7، 8] في الموقع (1، 2). نكتب
::
    >>> i = [[0, 1, 1],
             [2, 0, 2]]
    >>> v =  [[3, 4], [5, 6], [7, 8]]
    >>> s = torch.sparse_coo_tensor(i, v, (2, 3, 2))
    >>> s
    tensor(indices=tensor([[0, 1, 1],
                           [2, 0, 2]]),
           values=tensor([[3, 4],
                          [5, 6],
                          [7, 8]]),
           size=(2, 3, 2), nnz=3, layout=torch.sparse_coo)

    >>> s.to_dense()
    tensor([[[0, 0],
             [0, 0],
             [3, 4]],
            [[5, 6],
             [0, 0],
             [7, 8]]])

بشكل عام، إذا كانت "s" مصفوفة COO نادرة و "M =
s.sparse_dim()``، ``K = s.dense_dim()``، ثم لدينا الدعائم التالية:

  - ``M + K == len(s.shape) == s.ndim`` - أبعاد المصفوفة
    هو مجموع عدد الأبعاد النادرة والكثيفة،
  - ``s.indices().shape == (M, nse)`` - يتم تخزين مؤشرات نادرة بشكل صريح،
  - ``s.values().shape == (nse,) + s.shape[M : M + K]`` - القيم
    من المصفوفة الهجينة هي مصفوفات K-dimensional،
  - ``s.values().layout == torch.strided`` - يتم تخزين القيم كمصفوفات ذات خطوة.

.. note::

   تتبع الأبعاد الكثيفة دائمًا الأبعاد النادرة، أي أن مزج
   الأبعاد النادرة والكثيفة غير مدعوم.

.. note::

   للتأكد من أن المصفوفة النادرة المُنشأة بها مؤشرات وقيم وحجم متسق، يمكن تمكين فحوصات الدعائم لكل إنشاء مصفوفة عبر ``check_invariants=True``
   حجة، أو
   عالميًا باستخدام مثيل :class: `torch.sparse.check_sparse_tensor_invariants`
   مدير السياق. بشكل افتراضي، يتم تعطيل فحوصات الدعائم للمصفوفة النادرة.

.. _sparse-uncoalesced-coo-docs:

مصفوفات COO النادرة غير المدمجة
------------------------------

يسمح تنسيق مصفوفة COO النادرة في PyTorch بمصفوفات نادرة *غير مدمجة*،
حيث قد تكون هناك مؤشرات مكررة في المؤشرات؛ في هذه الحالة،
التفسير هو أن القيمة في هذا المؤشر هي مجموع جميع
إدخالات القيمة المكررة. على سبيل المثال، يمكنك تحديد قيم متعددة،
"3" و "4"، لنفس المؤشر "1"، مما يؤدي إلى مصفوفة 1-D غير مدمجة:
::
    >>> i = [[1, 1]]
    >>> v =  [3, 4]
    >>> s=torch.sparse_coo_tensor(i, v, (3,))
    >>> s
    tensor(indices=tensor([[1, 1]]),
           values=tensor(  [3, 4]),
           size=(3,), nnz=2, layout=torch.sparse_coo)

بينما ستؤدي عملية الدمج إلى تراكم العناصر متعددة القيم
إلى قيمة واحدة باستخدام الجمع:
::
    >>> s.coalesce()
    tensor(indices=tensor([[1]]),
           values=tensor([7]),
           size=(3,), nnz=1, layout=torch.sparse_coo)

بشكل عام، فإن إخراج طريقة :meth: `torch.Tensor.coalesce` عبارة عن مصفوفة نادرة ذات الخصائص التالية:

- مؤشرات العناصر المحددة في المصفوفة فريدة من نوعها،
- يتم فرز المؤشرات بترتيب معجمي،
- :meth: `torch.Tensor.is_coalesced()` إرجاع ``صحيح``.

.. note::

  في الغالب، لا ينبغي أن تهتم بما إذا كانت المصفوفة النادرة مدمجة أم لا، حيث تعمل معظم العمليات بنفس الطريقة
  سواء كان ذلك بالنظر إلى المصفوفة النادرة المدمجة أو غير المدمجة.

  ومع ذلك، يمكن تنفيذ بعض العمليات بكفاءة أكبر على
  المصفوفات النادرة غير المدمجة، والبعض الآخر على المصفوفات المدمجة.

  على سبيل المثال، تتم إضافة المصفوفات النادرة COO عن طريق
  ببساطة ضم مؤشرات المصفوفات وقيمها:
::
    >>> a = torch.sparse_coo_tensor([[1, 1]]، [5، 6]، (2))
    >>> b = torch.sparse_coo_tensor([[0، 0]]، [7
???????????????????
-------------------------------

لنأخذ المثال التالي في الاعتبار:

>>> i = [[[0, 1, 1],
...      [2, 0, 2]]]
>>> v = [[[3, 4], [5, 6], [7, 8]]]
>>> s = torch.sparse_coo_tensor(i, v, (2, 3, 2))

كما ذكرنا سابقًا، فإن Tensor COO المتناثر هو: class:`torch.Tensor`
مثيل وللتمييز بينه وبين مثيلات Tensor التي تستخدم
بعض التخطيطات الأخرى، يمكن استخدام: attr:`torch.Tensor.is_sparse` أو
:attr:`torch.Tensor.layout` الخصائص:
::
>>> isinstance(s, torch.Tensor)
صحيح
>>> s.is_sparse
صحيح
>>> s.layout == torch.sparse_coo
صحيح

يمكن الحصول على عدد الأبعاد المتناثرة والكثيفة باستخدام
الطرق: meth:`torch.Tensor.sparse_dim` و
:meth:`torch.Tensor.dense_dim`، على التوالي. على سبيل المثال:
::
>>> s.sparse_dim()، s.dense_dim()
(2، 1)

إذا كان "s" هو Tensor COO متناثر، فيمكن
يمكن الحصول على تنسيق بيانات COO باستخدام الطرق: meth:`torch.Tensor.indices()` و
:meth:`torch.Tensor.values()`.

.. note::

  حاليًا، يمكن الحصول على تنسيق بيانات COO فقط عندما يكون مثيل tensor
  تم تجميعه:
::
    >>> s.indices()
    RuntimeError: لا يمكن الحصول على المؤشرات في tensor غير مجمع، يرجى استدعاء .coalesce() أولاً

  للحصول على تنسيق بيانات COO لمثيل tensor غير مجمع، استخدم
  :func:`torch.Tensor._values()` و: func:`torch.Tensor._indices()`:
::
    >>> s._indices()
    tensor([[0, 1, 1]،
            [2، 0، 2]])

  .. راجع https://github.com/pytorch/pytorch/pull/45695 للحصول على واجهة برمجة التطبيقات الجديدة.

  .. تحذير::
    سيؤدي استدعاء: meth:`torch.Tensor._values()` إلى إرجاع tensor *منفصل*.
    لتتبع التدرجات، يجب استخدام: meth:`torch.Tensor.coalesce().values()` بدلاً من ذلك.

إن إنشاء Tensor COO متناثر جديد ينتج عنه tensor غير مجمع:

>>> s.is_coalesced()
خطأ

ولكن يمكن إنشاء نسخة مجمعة من Tensor COO المتناثر باستخدام
:meth:`torch.Tensor.coalesce` الطريقة:

>>> s2 = s.coalesce()
>>> s2.indices()
tensor([[0, 1, 1]،
           [2، 0، 2]])

عند العمل مع تنسورات COO متناثرة غير مجمعة، يجب مراعاة الطبيعة التراكمية للبيانات غير المجمعة: قيم المؤشرات نفسها هي شروط مجموع أن تقييم يعطي قيمة عنصر tensor المقابل. على سبيل المثال، يمكن تنفيذ الضرب القياسي في tensor متناثر غير مجمع عن طريق ضرب جميع القيم غير المجمعة في المقياس لأن "c * (a + b) == c * a + c * b" صحيح. ومع ذلك، فإن أي عملية غير خطية، مثل الجذر التربيعي، لا يمكن تنفيذها عن طريق تطبيق العملية على البيانات غير المجمعة لأن "sqrt(a + b) == sqrt(a) + sqrt(b)" لا
يحمل بشكل عام.

يتم دعم الشرائح (بخطوة إيجابية) من tensor COO المتناثر فقط
بالنسبة للأبعاد الكثيفة. يتم دعم الفهرسة لكل من الأبعاد المتناثرة والكثيفة:
::
>>> s[1]
tensor(indices=tensor([[0, 2]])،
           values=tensor([[5, 6]،
                          [7، 8]])،
           size=(3, 2)، nnz=2، layout=torch.sparse_coo)
>>> s[1, 0, 1]
tensor(6)
>>> s[1, 0, 1:]
tensor([6])

في PyTorch، لا يمكن تحديد قيمة تعبئة tensor المتناثر بشكل صريح ويُفترض أنها صفر بشكل عام. ومع ذلك، هناك عمليات قد تفسر قيمة التعبئة بشكل مختلف. على سبيل المثال،: func:`torch.sparse.softmax` يحسب softmax بافتراض أن قيمة التعبئة هي سالب اللانهاية.

.. راجع https://github.com/Quansight-Labs/rfcs/tree/pearu/rfc-fill-value/RFC-0004-sparse-fill-value لواجهة برمجة تطبيقات جديدة

.. _sparse-compressed-docs:

تنسورات مضغوطة متناثرة
+++++++++++++++++++

تمثل تنسورات مضغوطة متناثرة فئة من التنسورات المتناثرة التي لها ميزة مشتركة تتمثل في ضغط مؤشرات بُعد معين باستخدام ترميز يمكّن تحسينات معينة على نوى الجبر الخطي لتنسورات مضغوطة متناثرة. يعتمد هذا الترميز على
`تنسور الصف المتناثر المضغوط (CSR)`__ تنسيق PyTorch تنسورات مضغوطة متناثرة تمدد مع دعم دفعات tensor متناثرة، مما يسمح بقيم tensor متعددة الأبعاد، وتخزين قيم tensor متناثرة في كتل كثيفة.

__ https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_(CSR,_CRS_or_Yale_format)

.. note::

   نستخدم tensor (B + M + K) الأبعاد للإشارة إلى tensor N الأبعاد
   tensor متناثر مضغوط، حيث B، M، و K هي أعداد
   من الأبعاد الدفعية، والمتناثرة، والكثيفة، على التوالي، بحيث
   "B + M + K == N" يحمل. عدد الأبعاد المتناثرة للتنسورات المضغوطة المتناثرة هو دائمًا اثنان، "M == 2".

.. note::

   نقول إن tensor المؤشرات "compressed_indices" يستخدم ترميز CSR
   إذا تم استيفاء الدعوات التالية:

   - "compressed_indices" هو tensor متواصل ذو 32 أو 64 بت
     نوع صحيح
   - شكل "compressed_indices" هو "(*batchsize،
     compressed_dim_size + 1)" حيث "compressed_dim_size" هو
     عدد الأبعاد المضغوطة (على سبيل المثال، الصفوف أو الأعمدة)
   - "compressed_indices[..., 0] == 0" حيث "..." تشير إلى مؤشرات دفعية
   - "compressed_indices[..., compressed_dim_size] == nse" حيث
     "nse" هو عدد العناصر المحددة
   - "0 <= compressed_indices[..., i] - compressed_indices[..., i -
     1] <= plain_dim_size" لـ "i=1، ...، compressed_dim_size"،
     حيث "plain_dim_size" هو عدد الأبعاد العادية
     (متعامد مع الأبعاد المضغوطة، على سبيل المثال، الأعمدة أو الصفوف).

   للتأكد من أن tensor المتناثر الذي تم إنشاؤه له مؤشرات وقيم وحجم متسق، يمكن تمكين فحوصات الدعوات لكل إنشاء tensor عبر "check_invariants=True"
   حجة الكلمة الرئيسية، أو
   بشكل عام باستخدام: class:`torch.sparse.check_sparse_tensor_invariants`
   سياق مدير مثيل. بشكل افتراضي، يتم تعطيل فحوصات الدعوات tensor المتناثرة.

.. note::

   يمكن أن يؤدي تعميم التخطيطات المضغوطة المتناثرة إلى تنسورات N الأبعاد
   إلى بعض الارتباك فيما يتعلق بعدد العناصر المحددة. عندما يحتوي tensor المتناثر المضغوط على أبعاد دفعية، فإن عدد العناصر المحددة
   ستتوافق مع عدد هذه العناصر لكل دفعة. عندما يكون لدى tensor المتناثر المضغوط أبعاد كثيفة
   يتم الآن اعتبار العنصر صفيف K الأبعاد. أيضًا بالنسبة لتخطيطات التنسورات المتناثرة المضغوطة، يتم اعتبار الكتلة ثنائية الأبعاد
   كعنصر يتم تحديده. خذ على سبيل المثال tensor ثلاثي الأبعاد، مع بُعد دفعي واحد بطول "b"، وشكل كتلة "p، q". إذا كان هذا
   يحتوي على tensor "n" من العناصر المحددة، في الواقع لدينا "n"
   يتم تحديد الكتل لكل دفعة. سيكون لهذا tensor "values"
   الشكل "(b، n، p، q)". يأتي هذا التفسير لعدد العناصر المحددة من جميع التخطيطات المضغوطة المتناثرة
   كونها مشتقة من ضغط مصفوفة ثنائية الأبعاد. يتم التعامل مع أبعاد الدفعات ككومة من المصفوفات المتناثرة، وتغير الأبعاد الكثيفة معنى العنصر من
   قيمة قياسية بسيطة إلى صفيف بأبعاده الخاصة.

.. _sparse-csr-docs:

تنسور CSR متناثر
-----------------

الميزة الرئيسية لتنسيق CSR على تنسيق COO هي الاستخدام الأفضل للتخزين وعمليات الحساب الأسرع بكثير مثل الضرب المصفوفة المتناثرة المتجه باستخدام MKL وMAGMA
الخلفيات.

في أبسط الحالات، يتكون tensor CSR المتناثر (0 + 2 + 0) الأبعاد من ثلاثة تنسورات أحادية البعد: "crow_indices"، "col_indices" و
"القيم":

  - يتكون tensor "crow_indices" من مؤشرات الصف المضغوط. هذا هو
    1-D tensor من الحجم "nrows + 1" (عدد
    الصفوف بالإضافة إلى 1). العنصر الأخير من "crow_indices" هو
    عدد العناصر المحددة، "nse". يقوم هذا tensor بتشفير الفهرس في
    "القيم" و "col_indices" اعتمادًا على المكان الذي يبدأ فيه الصف المعطى. كل رقم متتالي في
    tensor مطروحًا من الرقم قبله يشير إلى عدد العناصر في صف معين.

  - يحتوي tensor "col_indices" على مؤشرات عمود كل
    عنصر. هذا هو 1-D tensor من الحجم "nse".

  - يحتوي tensor "values" على قيم عناصر tensor CSR. هذا هو
    1-D tensor من الحجم "nse".

.. note::

   يجب أن يكون نوع عنصر tensor المؤشر "crow_indices" و "col_indices" إما
   "torch.int64" (افتراضي) أو
   "torch.int32". إذا كنت تريد استخدام عمليات المصفوفة الممكّنة من MKL، استخدم
   "torch.int32". هذا هو نتيجة ربط pytorch الافتراضي بـ MKL LP64، والذي يستخدم 32 بت
     فهرسة الأعداد الصحيحة.

في الحالة العامة، يتكون tensor CSR المتناثر (B + 2 + K) الأبعاد من مؤشرين (B + 1) الأبعاد
تنسورات "crow_indices" و "col_indices"، و (1 + K) الأبعاد
tensor "القيم" بحيث

  - "crow_indices.shape == (*batchsize، nrows + 1)"

  - "col_indices.shape == (*batchsize، nse)"

  - "values.shape == (nse، *densesize)"

في حين أن شكل tensor CSR المتناثر هو "(*batchsize، nrows،
ncols، *densesize)" حيث "len(batchsize) == B" و
"len(densesize) == K".

.. note::

   تعتمد دفعات تنسورات CSR المتناثرة: يجب أن يكون عدد
   تكون عناصر محددة في جميع الدفعات هي نفسها. هذا القيد الاصطناعي إلى حد ما
   يسمح بتخزين كفء لمؤشرات دفعات CSR المختلفة.

.. note::

   يمكن الحصول على عدد الأبعاد المتناثرة والكثيفة باستخدام
   :meth:`torch.Tensor.sparse_dim` و: meth:`torch.Tensor.dense_dim`
   الطرق. يمكن حساب أبعاد الدفعة من شكل tensor: "batchsize = tensor.shape[:-tensor.sparse_dim() -
   tensor.dense_dim()]``.

.. note::

   تبلغ استهلاك ذاكرة tensor CSR المتناثر على الأقل
   "(nrows * 8 + (8 + <حجم نوع العنصر بالبايت> *
   prod(densesize)) * nse) * prod(batchsize)" بايت (بالإضافة إلى ثابت
   النفقات العامة من تخزين بيانات tensor الأخرى).

   مع نفس بيانات المثال من: ref:`الملاحظة في تنسور COO المتناثر
   المقدمة<sparse-coo-docs>``، تبلغ استهلاك الذاكرة لمصفوفة 10000 × 10000 مع 100000
   أرقام عائمة غير صفريين تبلغ 32 بت على الأقل "10000 * 8 + (8 + 4 * 1) * 100 000) * 1 = 1 280 000"
   بايت عند استخدام تخطيط tensor CSR. لاحظ التوفير 1.6 و 310 مرة من استخدام تنسيقات التخزين CSR وCOO، على التوالي.

بناء تنسورات CSR
''''''''''''

يمكن بناء تنسورات CSR المتناثرة مباشرة عن طريق استخدام
:func:`torch.sparse_csr_tensor` دالة. يجب على المستخدم توفير مؤشرات الصف والعمود والقيم
تنسورات بشكل منفصل حيث يجب تحديد مؤشرات الصف باستخدام ترميز الضغط CSR. الحجم
الحجة اختيارية وسيتم استنتاجها من "crow_indices" و
"col_indices" إذا لم يكن موجودًا.
::
    >>> crow_indices = torch.tensor([0، 2، 4])
    >>> col_indices = torch.tensor([0، 1، 0، 1])
    >>> values = torch.tensor([1، 2، 3، 4])
    >>> csr = torch.sparse_csr_tensor(crow_indices، col_indices، values، dtype=torch.float64)
    >>> csr
    tensor(crow_indices=tensor([0، 2، 4])،
           col_indices=tensor([0، 1، 0، 1])،
           values=tensor([1.، 2.، 3.، 4.])، size=(2، 2)، nnz=4،
           dtype=torch.float64)
    >>> csr.to_dense()
    tensor([[1.، 2.]،
            [3.، 4. ])، dtype=torch.float64)

.. note::

   يتم حساب قيم الأبعاد المتناثرة في الحجم المخصّص من حجم "crow_indices" و
   القيمة القصوى لمؤشر "col_indices". إذا كان عدد الأعمدة بحاجة إلى أن يكون أكبر من
   في الحجم المخصّص، فيجب تحديد الحجم
   يجب تحديد الحجة بشكل صريح.

أبسط طريقة لبناء tensor CSR المتناثر ثنائي الأبعاد من
tensor (strided) أو tensor COO المتناثر هو استخدام
:meth:`torch.Tensor.to_sparse_csr` الطريقة. سيتم تفسير أي أصفار في tensor (strided)
كقيم مفقودة في tensor المتناثر:
::
    >>> a = torch.tensor([[0، 0، 1، 0]، [1، 2، 0، 0]، [0، 0، 0، 0]]، dtype=torch.float64)
    >>> sp = a.to_sparse_csr()
    >>> sp
    tensor(crow_indices=tensor([0، 1، 3، 3])،
          col_indices=tensor([2، 0، 1])،
          values=tensor([1.، 1.، 2.])، size=(3، 4)، nnz=3، dtype=torch.float64)

عمليات CSR Tensor
'''''''''''''''''''''

يمكن إجراء الضرب المصفوفة المتناثرة المتجه باستخدام
:meth:`tensor.matmul` الطريقة. هذه هي العملية الرياضية الوحيدة
يدعم حاليا على تنسورات CSR.
::
    >>> vec = torch.randn(4، 1، dtype=torch.float64)
    >>> sp.matmul(vec)
    tensor([[0.9078]،
            [1.3180]،
            [0.0000]]، dtype=torch.float64)

.. _sparse-csc-docs:

تنسور CSC متناثر
تنسيق CSC النادر (ضغط العمود النادر) ينفذ تنسيق CSC لتخزين التنسورات ثنائية الأبعاد مع تمديد لدعم دفعات من التنسورات CSC النادرة والقيم التي تكون تنسورات متعددة الأبعاد.

.. note::

   التنسور CSC النادرة هي في الأساس تحويل التنسور CSR النادرة عندما يكون التحويل عبارة عن تبديل الأبعاد النادرة.

على غرار :ref: `التنسورات CSR النادرة <sparse-csr-docs>` ، تتكون التنسور CSC النادرة من ثلاث تنسورات: ``ccol_indices`` ، ``row_indices`` و ``values``:

  - تتكون التنسور ``ccol_indices`` من مؤشرات العمود المضغوطة. هذا هو تنسيق (B + 1) الأبعاد من الشكل ``(*batchsize، ncols + 1)``.
   العنصر الأخير هو عدد العناصر المحددة، ``nse``. يقوم هذا التنسور بتشفير الفهرس في ``القيم`` و
   ``row_indices`` اعتمادًا على المكان الذي يبدأ فيه العمود المعطى. يشير كل رقم متتالي في التنسور مطروحًا منه الرقم قبله إلى عدد العناصر في عمود معين.

  - تحتوي التنسور ``row_indices`` على مؤشرات الصف لكل
    عنصر. هذا هو تنسيق (B + 1) الأبعاد من الشكل ``(*batchsize، nse)``.

  - تحتوي التنسور ``values`` على قيم عناصر CSC
    التنسور. هذا هو تنسيق (1 + K) الأبعاد من الشكل ``(nse، *densesize)``.

بناء تنسرات CSC
''''''''''

يمكن بناء تنسرات CSC النادرة مباشرة باستخدام
:func: `torch.sparse_csc_tensor` الدالة. يجب على المستخدم توفير مؤشرات الصف والعمود والقيم المنفصلة حيث يجب تحديد مؤشرات العمود باستخدام ترميز الضغط CSR. الحجم
الحجة اختيارية وسيتم استنتاجها من ``row_indices`` و
``ccol_indices`` التنسورات إذا لم تكن موجودة.
::
    >>> ccol_indices = torch.tensor([0، 2، 4])
    >>> row_indices = torch.tensor([0، 1، 0، 1])
    >>> values = torch.tensor([1، 2، 3، 4])
    >>> csc = torch.sparse_csc_tensor(ccol_indices، row_indices، values، dtype=torch.float64)
    >>> csc
    tensor(ccol_indices=tensor([0، 2، 4])،
           row_indices=tensor([0، 1، 0، 1])،
           values=tensor([1.، 2.، 3.، 4.])، size=(2، 2)، nnz=4،
           dtype=torch.float64، layout=torch.sparse_csc)
    >>> csc.to_dense()
    tensor([[1.، 3.]،
            [2.، 4.]])

.. note::

   تحتوي دالة البناء التنسرات CSC النادرة على مؤشرات العمود المضغوطة
   الحجة قبل مؤشرات الصف الحجة.

يمكن بناء التنسرات CSC النادرة ذات الأبعاد (0 + 2 + 0) من
أي تنسور ثنائي الأبعاد باستخدام طريقة :meth: `torch.Tensor.to_sparse_csc`
طريقة. سيتم تفسير أي أصفار في التنسور (المسطر) على أنها
قيم مفقودة في التنسور النادرة:
::
    >>> a = torch.tensor ([[0، 0، 1، 0]، [1، 2، 0، 0]، [0، 0، 0، 0]]، dtype=torch.float64)
    >>> sp = a.to_sparse_csc()
    >>> sp
    tensor(ccol_indices=tensor([0، 1، 2، 3، 3])،
           row_indices=tensor([1، 1، 0])،
           values=tensor([1.، 2.، 1.])، size=(3، 4)، nnz=3، dtype=torch.float64،
           layout=torch.sparse_csc)

.. _sparse-bsr-docs:

التنسورات BSR النادرة
-----------------

ينفذ تنسيق BSR النادر (سطر الكتلة المضغوط النادر) تنسيق BSR لتخزين التنسورات ثنائية الأبعاد مع تمديد لدعم دفعات من التنسورات BSR النادرة والقيم التي تكون كتل من التنسورات متعددة الأبعاد.

تتكون التنسور BSR النادرة من ثلاث تنسورات: ``crow_indices`` ،
``col_indices`` و ``values``:

  - تتكون التنسور ``crow_indices`` من مؤشرات الصف المضغوطة. هذا هو تنسيق (B + 1) الأبعاد من الشكل ``(*batchsize،
    nrowblocks + 1)``. العنصر الأخير هو عدد الكتل المحددة،
    ``nse``. يقوم هذا التنسور بتشفير الفهرس في ``القيم`` و
    ``col_indices`` اعتمادًا على المكان الذي تبدأ فيه كتلة العمود المعطاة.
    يشير كل رقم متتالي في التنسور مطروحًا منه الرقم قبله إلى عدد الكتل في صف معين.

  - تحتوي التنسور ``col_indices`` على مؤشرات كتلة العمود لكل
    عنصر. هذا هو تنسيق (B + 1) الأبعاد من الشكل ``(*batchsize،
    nse)``.

  - تحتوي التنسور ``values`` على قيم عناصر التنسور BSR النادرة
    يتم جمعها في كتل ثنائية الأبعاد. هذا هو تنسيق (1 + 2 +
    K) الأبعاد من الشكل ``(nse، nrowblocks، ncolblocks،
    *densesize)``.

بناء تنسورات BSR
'''''''''''''''''''''''''''

يمكن بناء تنسورات BSR النادرة مباشرة باستخدام
:func: `torch.sparse_bsr_tensor` الدالة. يجب على المستخدم توفير مؤشرات كتلة الصف والعمود والقيم المنفصلة حيث يجب تحديد مؤشرات كتلة الصف باستخدام ترميز الضغط CSR.
الحجم
الحجة اختيارية وسيتم استنتاجها من ``crow_indices`` و
``col_indices`` التنسورات إذا لم تكن موجودة.

    >>> crow_indices = torch.tensor([0، 2، 4])
    >>> col_indices = torch.tensor([0، 1، 0، 1])
    >>> values = torch.tensor ([[[0، 1، 2]، [6، 7، 8]]،
    ...                        [[3، 4، 5]، [9، 10، 11]]،
    ...                        [[12، 13، 14]، [18، 19، 20]]،
    ...                        [[15، 16، 17]، [21، 22، 23]]])
    >>> bsr = torch.sparse_bsr_tensor (crow_indices، col_indices، values، dtype=torch.float64)
    >>> bsr
    tensor(crow_indices=tensor([0، 2، 4])،
           col_indices=tensor([0، 1، 0، 1])،
           values=tensor ([[[0.، 1.، 2.]،
                           [6.، 7.، 8. ]]]،
                          [[[3.، 4.، 5.]،
                           [9.، 10.، 11.]]]]،
                          [[[12.، 13.، 14.]،
                           [18.، 19.، 20.]]]]،
                          [[[15.، 16.، 17.]،
                           [21.، 22.، 23.]]]]))،
           size=(4، 6)، nnz=4، dtype=torch.float64، layout=torch.sparse_bsr)
    >>> bsr.to_dense()
    tensor([[0.، 1.، 2.، 3.، 4.، 5.]،
            [6.، 7.، 8.، 9.، 10.، 11.]،
            [12.، 13.، 14.، 15.، 16.، 17.]،
            [18.، 19.، 20.، 21.، 22.، 23.]])

يمكن بناء تنسورات BSR النادرة ذات الأبعاد (0 + 2 + 0) من
أي تنسور ثنائي الأبعاد باستخدام طريقة :meth: `torch.Tensor.to_sparse_bsr`
طريقة تتطلب أيضًا تحديد حجم كتلة القيم:

    >>> dense = torch.tensor ([[0، 1، 2، 3، 4، 5]،
    ...                       [6، 7، 8، 9، 10، 11]،
    ...                       [12، 13، 14، 15، 16، 17]،
    ...                       [18، 19، 20، 21، 22، 23]])
    >>> bsr = dense.to_sparse_bsr (blocksize = (2، 3))
    >>> bsr
    tensor(crow_indices=tensor([0، 2، 4])،
           col_indices=tensor([0، 1، 0، 1])،
           values=tensor ([[[0، 1، 2]،
                           [6، 7، 8]]]]،
                          [[[3، 4، 5]،
                           [9، 10، 11]]]]،
                          [[[12، 13، 14]،
                           [18، 19، 20]]]]،
                          [[[15، 16، 17]،
                           [21، 22، 23]]]]))، size=(4، 6)، nnz=4،
           layout=torch.sparse_bsr)

.. _sparse-bsc-docs:

التنسور BSC النادرة
-----------------

ينفذ تنسيق BSC النادر (ضغط كتلة العمود النادر) تنسيق BSC لتخزين التنسورات ثنائية الأبعاد مع تمديد لدعم دفعات من التنسورات BSC النادرة والقيم التي تكون كتل من التنسورات متعددة الأبعاد.

تتكون التنسور BSC النادرة من ثلاث تنسورات: ``ccol_indices`` ،
``row_indices`` و ``values``:

  - تتكون التنسور ``ccol_indices`` من مؤشرات العمود المضغوطة. هذا هو تنسيق (B + 1) الأبعاد من الشكل ``(*batchsize،
    ncolblocks + 1)``. العنصر الأخير هو عدد الكتل المحددة،
    ``nse``. يقوم هذا التنسور بتشفير الفهرس في ``القيم`` و
    ``row_indices`` اعتمادًا على المكان الذي تبدأ فيه كتلة الصف المعطاة.
    يشير كل رقم متتالي في التنسور مطروحًا منه الرقم قبله إلى عدد الكتل في عمود معين.

  - تحتوي التنسور ``row_indices`` على مؤشرات كتلة الصف لكل
    عنصر. هذا هو تنسيق (B + 1) الأبعاد من الشكل ``(*batchsize،
    nse)``.

  - تحتوي التنسور ``values`` على قيم عناصر التنسور BSC النادرة
    يتم جمعها في كتل ثنائية الأبعاد. هذا هو تنسيق (1 + 2 +
    K) الأبعاد من الشكل ``(nse، nrowblocks، ncolblocks،
    *densesize)``.

بناء تنسورات BSC
''''''''''''

يمكن بناء تنسورات BSC النادرة مباشرة باستخدام
:func: `torch.sparse_bsc_tensor` الدالة. يجب على المستخدم توفير مؤشرات كتلة الصف والعمود والقيم المنفصلة حيث يجب تحديد مؤشرات كتلة العمود باستخدام ترميز الضغط CSR.
الحجم
الحجة اختيارية وسيتم استنتاجها من ``ccol_indices`` و
``row_indices`` التنسورات إذا لم تكن موجودة.

    >>> ccol_indices = torch.tensor([0، 2، 4])
    >>> row_indices = torch.tensor([0، 1، 0، 1])
    >>> values = torch.tensor ([[[0، 1، 2]، [6، 7، 8]]،
    ...                        [[3، 4، 5]، [9، 10، 11]]،
    ...                        [[12، 13، 14]، [18، 19، 20]]،
    ...                        [[15، 16، 17]، [21، 22، 23]]])
    >>> bsc = torch.sparse_bsc_tensor (ccol_indices، row_indices، values، dtype=torch.float64)
    >>> bsc
    tensor(ccol_indices=tensor([0، 2، 4])،
           row_indices=tensor([0، 1، 0، 1])،
           values=tensor ([[[0.، 1.، 2.]،
                           [6.، 7.، 8. ]]]،
                          [[[3.، 4.، 5.]،
                           [9.، 10.، 11.]]]]،
                          [[[12.، 13.، 14.]،
                           [18.، 19.، 20.]]]]،
                          [[[15.، 16.، 17.]،
                           [21.، 22.، 23.]]]]))، size=(4، 6)، nnz=4،
           dtype=torch.float64، layout=torch.sparse_bsc)

أدوات للعمل مع التنسورات المضغوطة النادرة
---------------------------------

جميع التنسورات المضغوطة النادرة - CSR و CSC و BSR و BSC التنسورات -
مفاهيميا متشابهة للغاية في أن بيانات المؤشرات الخاصة بها مقسمة
إلى جزأين: ما يسمى المؤشرات المضغوطة التي تستخدم ترميز CSR، و
ما يسمى المؤشرات العادية التي تكون متعامدة مع
المؤشرات المضغوطة. يسمح ذلك بمشاركة أدوات مختلفة على هذه التنسورات في نفس التطبيقات التي يتم معلمتها بواسطة تخطيط التنسور.

بناء التنسورات المضغوطة النادرة
'''''''''''''''''''

يمكن بناء تنسورات CSR و CSC و BSR و CSC النادرة باستخدام
:func: `torch.sparse_compressed_tensor` الدالة التي لها نفس
واجهة وظائف البناء المذكورة أعلاه
:func: `torch.sparse_csr_tensor` ، :func: `torch.sparse_csc_tensor` ،
:func: `torch.sparse_bsr_tensor` ، و: func: `torch.sparse_bsc_tensor`،
على التوالي، ولكن مع حجة تخطيط إضافية مطلوبة. توضح الأمثلة التالية طريقة لبناء تنسورات CSR و CSC
باستخدام نفس بيانات الإدخال عن طريق تحديد معلمة تخطيط المقابلة إلى
:func: `torch.sparse_compressed_tensor` الدالة:

    >>> compressed_indices = torch.tensor([0، 2، 4])
    >>> plain_indices = torch.tensor([0، 1، 0، 1])
    >>> values = torch.tensor([1، 2، 3، 4])
    >>> csr = torch.sparse_compressed_tensor (compressed_indices، plain_indices، values، layout=torch.sparse_csr)
    >>> csr
    tensor(crow_indices=tensor([0، 2، 4])،
           col_indices=tensor([0، 1، 0، 1])،
           values=tensor([1، 2، 3، 4])، size=(2، 2)، nnz=4،
           layout=torch.sparse_csr)
    >>> csc = torch.sparse_compressed_tensor (compressed_indices، plain_indices، values، layout=torch.sparse_csc)
    >>> csc
    tensor(ccol_indices=tensor([0، 2، 4])،
           row_indices=tensor([0، 1، 0، 1])،
           values=tensor([1، 2، 3، 4])، size=(2، 2)، nnz=4،
           layout=torch.sparse_csc)
    >>> (csr.transpose(0، 1).to_dense() == csc.to_dense()).all()
    tensor(True)

.. _sparse-ops-docs:

العمليات المدعومة
+++++++++++++++

الجبر الخطي العمليات
فيما يلي جدول يلخص عمليات الجبر الخطي المدعومة على المصفوفات المتناثرة حيث قد تختلف تخطيطات المشغلين. هنا، "T[layout]" تشير إلى Tensor ذات تخطيط معين. وبالمثل، "M[layout]" تشير إلى مصفوفة (Tensor ذات بعدين في PyTorch)، و "V[layout]" تشير إلى متجه (Tensor أحادي البعد في PyTorch). بالإضافة إلى ذلك، تشير "f" إلى عدد صحيح (float أو Tensor أبعاده صفرية في PyTorch)، و "*" هي الضرب العنصري، و "@" هي ضرب المصفوفات.

.. csv-table::
   :header: "عملية PyTorch", "Sparse grad؟", "توقيع التخطيط"
   :widths: 20, 5, 60
   :delim: ;

   :func:`torch.mv`;no; ``M[sparse_coo] @ V[strided] -> V[strided]``
   :func:`torch.mv`;no; ``M[sparse_csr] @ V[strided] -> V[strided]``
   :func:`torch.matmul`; no; ``M[sparse_coo] @ M[strided] -> M[strided]``
   :func:`torch.matmul`; no; ``M[sparse_csr] @ M[strided] -> M[strided]``
   :func:`torch.matmul`; no; ``M[SparseSemiStructured] @ M[strided] -> M[strided]``
   :func:`torch.matmul`; no; ``M[strided] @ M[SparseSemiStructured] -> M[strided]``
   :func:`torch.mm`; no; ``M[sparse_coo] @ M[strided] -> M[strided]``
   :func:`torch.mm`; no; ``M[SparseSemiStructured] @ M[strided] -> M[strided]``
   :func:`torch.mm`; no; ``M[strided] @ M[SparseSemiStructured] -> M[strided]``
   :func:`torch.sparse.mm`; yes; ``M[sparse_coo] @ M[strided] -> M[strided]``
   :func:`torch.smm`; no; ``M[sparse_coo] @ M[strided] -> M[sparse_coo]``
   :func:`torch.hspmm`; no; ``M[sparse_coo] @ M[strided] -> M[hybrid sparse_coo]``
   :func:`torch.bmm`; no; ``T[sparse_coo] @ T[strided] -> T[strided]``
   :func:`torch.addmm`; no; ``f * M[strided] + f * (M[sparse_coo] @ M[strided]) -> M[strided]``
   :func:`torch.addmm`; no; ``f * M[strided] + f * (M[SparseSemiStructured] @ M[strided]) -> M[strided]``
   :func:`torch.addmm`; no; ``f * M[strided] + f * (M[strided] @ M[SparseSemiStructured]) -> M[strided]``
   :func:`torch.sparse.addmm`; yes; ``f * M[strided] + f * (M[sparse_coo] @ M[strided]) -> M[strided]``
   :func:`torch.sparse.spsolve`; no; ``SOLVE(M[sparse_csr], V[strided]) -> V[strided]``
   :func:`torch.sspaddmm`; no; ``f * M[sparse_coo] + f * (M[sparse_coo] @ M[strided]) -> M[sparse_coo]``
   :func:`torch.lobpcg`; no; ``GENEIG(M[sparse_coo]) -> M[strided], M[strided]``
   :func:`torch.pca_lowrank`; yes; ``PCA(M[sparse_coo]) -> M[strided], M[strided], M[strided]``
   :func:`torch.svd_lowrank`; yes; ``SVD(M[sparse_coo]) -> M[strided], M[strided], M[strided]``

يشير عمود "Sparse grad؟" إلى ما إذا كانت عملية PyTorch تدعم التشتت فيما يتعلق بحجة المصفوفة المتناثرة. تدعم جميع عمليات PyTorch، باستثناء :func:`torch.smm`، التشتت فيما يتعلق بحجج المصفوفة ذات الخطوة.

.. note::

   حاليًا، لا يدعم PyTorch ضرب المصفوفات مع توقيع التخطيط "M[strided] @ M[sparse_coo]". ومع ذلك، لا تزال التطبيقات قادرة على حساب هذا باستخدام علاقة المصفوفة "D @ S == (S.t() @ D.t()).t()".

أساليب Tensor والمصفوفات المتناثرة
-------------------------

طرق Tensor التالية تتعلق بالمصفوفات المتناثرة:

.. autosummary::
    :toctree: generated
    :nosignatures:

    Tensor.is_sparse
    Tensor.is_sparse_csr
    Tensor.dense_dim
    Tensor.sparse_dim
    Tensor.sparse_mask
    Tensor.to_sparse
    Tensor.to_sparse_coo
    Tensor.to_sparse_csr
    Tensor.to_sparse_csc
    Tensor.to_sparse_bsr
    Tensor.to_sparse_bsc
    Tensor.to_dense
    Tensor.values

طرق Tensor التالية خاصة بمصفوفات COO المتناثرة:

.. autosummary::
    :toctree: generated
    :nosignatures:

    Tensor.coalesce
    Tensor.sparse_resize_
    Tensor.sparse_resize_and_clear_
    Tensor.is_coalesced
    Tensor.indices

الطرق التالية خاصة بـ :ref:`مصفوفات CSR المتناثرة <sparse-csr-docs>` و :ref:`مصفوفات BSR المتناثرة <sparse-bsr-docs>`:

.. autosummary::
    :toctree: generated
    :nosignatures:

    Tensor.crow_indices
    Tensor.col_indices

الطرق التالية خاصة بـ :ref:`مصفوفات CSC المتناثرة <sparse-csc-docs>` و :ref:`مصفوفات BSC المتناثرة <sparse-bsc-docs>`:

.. autosummary::
    :toctree: generated
    :nosignatures:

    Tensor.row_indices
    Tensor.ccol_indices

طرق Tensor التالية تدعم مصفوفات COO المتناثرة:

:meth:`~torch.Tensor.add`
:meth:`~torch.Tensor.add_`
:meth:`~torch.Tensor.addmm`
:meth:`~torch.Tensor.addmm_`
:meth:`~torch.Tensor.any`
:meth:`~torch.Tensor.asin`
:meth:`~torch.Tensor.asin_`
:meth:`~torch.Tensor.arcsin`
:meth:`~torch.Tensor.arcsin_`
:meth:`~torch.Tensor.bmm`
:meth:`~torch.Tensor.clone`
:meth:`~torch.Tensor.deg2rad`
:meth:`~torch.Tensor.deg2rad_`
:meth:`~torch.Tensor.detach`
:meth:`~torch.Tensor.detach_`
:meth:`~torch.Tensor.dim`
:meth:`~torch.Tensor.div`
:meth:`~torch.Tensor.div_`
:meth:`~torch.Tensor.floor_divide`
:meth:`~torch.Tensor.floor_divide_`
:meth:`~torch.Tensor.get_device`
:meth:`~torch.Tensor.index_select`
:meth:`~torch.Tensor.isnan`
:meth:`~torch.Tensor.log1p`
:meth:`~torch.Tensor.log1p_`
:meth:`~torch.Tensor.mm`
:meth:`~torch.Tensor.mul`
:meth:`~torch.Tensor.mul_`
:meth:`~torch.Tensor.mv`
:meth:`~torch.Tensor.narrow_copy`
:meth:`~torch.Tensor.neg`
:meth:`~torch.Tensor.neg_`
:meth:`~torch.Tensor.negative`
:meth:`~torch.Tensor.negative_`
:meth:`~torch.Tensor.numel`
:meth:`~torch.Tensor.rad2deg`
:meth:`~torch.Tensor.rad2deg_`
:meth:`~torch.Tensor.resize_as_`
:meth:`~torch.Tensor.size`
:meth:`~torch.Tensor.pow`
:meth:`~torch.Tensor.sqrt`
:meth:`~torch.Tensor.square`
:meth:`~torch.Tensor.smm`
:meth:`~torch.Tensor.sspaddmm`
:meth:`~torch.Tensor.sub`
:meth:`~torch.Tensor.sub_`
:meth:`~torch.Tensor.t`
:meth:`~torch.Tensor.t_`
:meth:`~torch.Tensor.transpose`
:meth:`~torch.Tensor.transpose_`
:meth:`~torch.Tensor.zero_`

وظائف الشعلة المحددة للمصفوفات المتناثرة
------------------------------------------

.. autosummary::
    :toctree: generated
    :nosignatures:

    sparse_coo_tensor
    sparse_csr_tensor
    sparse_csc_tensor
    sparse_bsr_tensor
    sparse_bsc_tensor
    sparse_compressed_tensor
    sparse.sum
    sparse.addmm
    sparse.sampled_addmm
    sparse.mm
    sspaddmm
    hspmm
    smm
    sparse.softmax
    sparse.spsolve
    sparse.log_softmax
    sparse.spdiags

وظائف أخرى
---------------

تدعم وظائف الشعلة التالية المصفوفات المتناثرة:

:func:`~torch.cat`
:func:`~torch.dstack`
:func:`~torch.empty`
:func:`~torch.empty_like`
:func:`~torch.hstack`
:func:`~torch.index_select`
:func:`~torch.is_complex`
:func:`~torch.is_floating_point`
:func:`~torch.is_nonzero`
:func:`~torch.is_same_size`
:func:`~torch.is_signed`
:func:`~torch.is_tensor`
:func:`~torch.lobpcg`
:func:`~torch.mm`
:func:`~torch.native_norm`
:func:`~torch.pca_lowrank`
:func:`~torch.select`
:func:`~torch.stack`
:func:`~torch.svd_lowrank`
:func:`~torch.unsqueeze`
:func:`~torch.vstack`
:func:`~torch.zeros`
:func:`~torch.zeros_like`

لإدارة التحقق من دقائق المصفوفات المتناثرة، راجع:

.. autosummary::
    :toctree: generated
    :nosignatures:

    sparse.check_sparse_tensor_invariants

لاستخدام المصفوفات المتناثرة مع دالة :func:`~torch.autograd.gradcheck`، راجع:

.. autosummary::
    :toctree: generated
    :nosignatures:

    sparse.as_sparse_gradcheck

الوظائف أحادية الصفرية
-------------------------------

نحن نهدف إلى دعم جميع "الوظائف الأحادية الصفرية": الوظائف ذات الحجة التي ترسم الصفر إلى الصفر.

إذا وجدت أننا نفتقد إلى وظيفة أحادية الصفرية تحتاجها، فيرجى تشجيعك على فتح قضية لطلب ميزة. كما هو الحال دائمًا، يرجى محاولة البحث أولاً قبل فتح قضية.

تدعم المشغلين التاليين حاليًا إدخالات Tensor المتناثرة COO/CSR/CSC/BSR/CSR.

:func:`~torch.abs`
:func:`~torch.asin`
:func:`~torch.asinh`
:func:`~torch.atan`
:func:`~torch.atanh`
:func:`~torch.ceil`
:func:`~torch.conj_physical`
:func:`~torch.floor`
:func:`~torch.log1p`
:func:`~torch.neg`
:func:`~torch.round`
:func:`~torch.sin`
:func:`~torch.sinh`
:func:`~torch.sign`
:func:`~torch.sgn`
:func:`~torch.signbit`
:func:`~torch.tan`
:func:`~torch.tanh`
:func:`~torch.trunc`
:func:`~torch.expm1`
:func:`~torch.sqrt`
:func:`~torch.angle`
:func:`~torch.isinf`
:func:`~torch.isposinf`
:func:`~torch.isneginf`
:func:`~torch.isnan`
:func:`~torch.erf`
:func:`~torch.erfinv`