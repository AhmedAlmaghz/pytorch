.. _distributed-rpc-framework:

إطار عمل RPC الموزع
==================

يوفر إطار عمل RPC الموزع آليات لتدريب النماذج متعددة الآلات من خلال مجموعة من التعليمات البرمجية الأساسية للسماح بالتواصل عن بُعد، وAPI عالية المستوى للتمييز التلقائي للنماذج المقسمة عبر عدة آلات.

.. warning::
     تعتبر واجهات برمجة التطبيقات في حزمة RPC مستقرة. هناك العديد من بنود العمل الجارية لتحسين الأداء ومعالجة الأخطاء، والتي سيتم إصدارها في الإصدارات المستقبلية.

.. warning::
    تم تقديم دعم CUDA في PyTorch 1.9 ولا يزال ميزة **beta**.
    ليست جميع ميزات حزمة RPC متوافقة بعد مع دعم CUDA
    وبالتالي لا يُنصح باستخدامها. تتضمن هذه الميزات غير المدعومة: RRefs
    التوافق مع JIT، dist autograd و dist optimizer، والتعريف. سيتم معالجة هذه
    القيود في الإصدارات المستقبلية.

.. note::
    يرجى الرجوع إلى `نظرة عامة على PyTorch الموزع <https://pytorch.org/tutorials/beginner/dist_overview.html>`__
    للتعرف على مقدمة موجزة لجميع الميزات المتعلقة بالتدريب الموزع.

أساسيات
------

يجعل إطار العمل RPC الموزع من السهل تشغيل الوظائف عن بُعد، ويدعم
الإشارة إلى الكائنات البعيدة دون نسخ البيانات الفعلية، ويوفر
واجهات برمجة التطبيقات للتمييز التلقائي والمحسن للتشغيل الشفاف للخلف
وتحديث المعلمات عبر حدود RPC. يمكن تصنيف هذه الميزات إلى أربع مجموعات من واجهات برمجة التطبيقات.

1) **نداء الإجراء البعيد (RPC)** يدعم تشغيل وظيفة على عامل الوجهة المحددة
   باستخدام الحجج المعطاة والحصول على قيمة الإرجاع مرة أخرى
   أو إنشاء مرجع لقيمة الإرجاع. هناك ثلاث واجهات برمجة تطبيقات RPC رئيسية:
   :meth:`~torch.distributed.rpc.rpc_sync` (متزامن)،
   :meth:`~torch.distributed.rpc.rpc_async` (غير متزامن)، و
   :meth:`~torch.distributed.rpc.remote` (غير متزامن ويعيد مرجعًا
   لقيمة الإرجاع البعيدة). استخدم واجهة برمجة التطبيقات المتزامنة إذا لم يكن بإمكان التعليمات البرمجية للمستخدم المتابعة بدون قيمة الإرجاع. وإلا، استخدم واجهة برمجة التطبيقات غير المتزامنة للحصول
   على مستقبل، وانتظر المستقبل عندما تكون قيمة الإرجاع مطلوبة على
   المتصل. تعد واجهة برمجة التطبيقات :meth:`~torch.distributed.rpc.remote` مفيدة عندما يكون
   المطلوب هو إنشاء شيء عن بُعد ولكن لا يلزم مطلقًا استرجاعه إلى المتصل. تخيل الحالة التي تقوم فيها عملية تشغيل بإعداد خادم معلمات ومدرب. يمكن لعملية التشغيل إنشاء جدول تضمين على خادم المعلمات ثم مشاركة المرجع إلى جدول التضمين مع المدرب، ولكنها لن تستخدم أبدًا جدول التضمين محليًا. في هذه الحالة،
   :meth:`~torch.distributed.rpc.rpc_sync` و
   :meth:`~torch.distributed.rpc.rpc_async` لم يعدا مناسبين، لأنهما
   يعني دائمًا أن قيمة الإرجاع ستتم إعادتها إلى المتصل
   على الفور أو في المستقبل.
2) **المرجع البعيد (RRef)** يعمل كإشارة موزعة إلى مؤشر محلي
   أو كائن بعيد. يمكن مشاركتها مع العمال الآخرين وسيتم التعامل مع العد المرجعي
   بشكل شفاف. لكل RRef مالك واحد فقط ويعيش الكائن فقط على هذا المالك. يمكن للعمال غير المالكين الذين يحملون RRefs الحصول على نسخ من
   الكائن من المالك عن طريق طلب ذلك بشكل صريح. هذا مفيد عندما
   يحتاج عامل إلى الوصول إلى كائن بيانات، ولكنه ليس هو نفسه
   منشئ (المتصل لـ :meth:`~torch.distributed.rpc.remote`) أو مالك الكائن. يعد المحسن الموزع، كما سنناقش أدناه، أحد أمثلة
   حالات الاستخدام هذه.
3) **التدرج التلقائي الموزع** يخيط معًا محركات التدرج التلقائي المحلية على جميع
   العمال المشاركين في تمرير الإرسال، والوصول إليها تلقائيًا أثناء
   تمرير الإرجاع لحساب التدرجات. هذا مفيد إذا
   كان تمرير الإرسال يحتاج إلى امتداد لعدة آلات عند إجراء
   التدريب المتوازي للنماذج الموزعة، وتدريب خادم المعلمات، وما إلى ذلك. مع
   هذه الميزة، لم يعد كود المستخدم بحاجة إلى القلق بشأن كيفية إرسال التدرجات
   عبر حدود RPC والترتيب الذي يجب أن يتم به تشغيل محركات التدرج التلقائي المحلية، والتي يمكن أن تصبح معقدة جدًا حيث توجد مكالمات RPC متداخلة ومتداخلة في تمرير الإرسال.
4) **المحسن الموزع** يأخذ الباني
   :meth:`~torch.optim.Optimizer` (على سبيل المثال: :meth:`~torch.optim.SGD`،
   :meth:`~torch.optim.Adagrad`، إلخ) وقائمة من مراجع المعلمات RRef، وينشئ مثيل
   :meth:`~torch.optim.Optimizer` على كل مالك RRef مميز،
   ويحدّث المعلمات وفقًا لذلك عند تشغيل ``step()``. عندما يكون لديك
   تمريرات إرسال وإرجاع موزعة، ستكون المعلمات والتدرجات مشتتة عبر
   عمال متعددين، وبالتالي فهو يتطلب محسنًا على كل
   من العمال المعنيين. يقوم المحسن الموزع بتغليف جميع هؤلاء المحسنين المحليين
   في واحد، ويوفر بناة واجهة برمجة تطبيقات واضحة و ``step()``.


.. _rpc:

RPC
---

قبل استخدام RPC وبدائيات التدرج التلقائي الموزع، يجب أن يحدث التهيئة. لتهيئة إطار عمل RPC، نحتاج إلى استخدام
:meth:`~torch.distributed.rpc.init_rpc` الذي يقوم بتهيئة إطار عمل RPC
وإطار عمل RRef والتدرج التلقائي الموزع.

.. automodule:: torch.distributed.rpc
.. autofunction:: init_rpc

تسمح واجهات برمجة التطبيقات التالية للمستخدمين بتنفيذ الوظائف عن بُعد بالإضافة إلى إنشاء
مراجع (RRefs) إلى كائنات البيانات البعيدة. في هذه الواجهات، عند تمرير
"Tensor" كحجة أو قيمة إرجاع، سيحاول عامل الوجهة إنشاء
"Tensor" بنفس البيانات الوصفية (أي الشكل، الخطوة، إلخ). نقوم
عن عمد بحظر نقل تنسيقات CUDA لأنه قد يتسبب في تعطل إذا لم تتطابق قوائم الأجهزة على المصدر
وعمال الوجهة. في مثل هذه الحالات، يمكن للتطبيقات دائمًا نقل تنسيقات الإدخال بشكل صريح إلى CPU على المتصل
ونقله إلى الأجهزة المرغوبة على المستدعي إذا لزم الأمر.

.. warning::
  يعد دعم TorchScript في RPC ميزة تجريبية وقد تتغير. منذ
  v1.5.0، ``torch.distributed.rpc`` يدعم استدعاء وظائف TorchScript
  كوظائف RPC مستهدفة، وهذا سيساعد في تحسين التوازي على جانب المستدعي
  نظرًا لأن تنفيذ وظائف TorchScript لا يتطلب GIL.


.. autofunction:: rpc_sync
.. autofunction:: rpc_async
.. autofunction:: remote
.. autofunction:: get_worker_info
.. autofunction:: shutdown
.. autoclass:: WorkerInfo
    :members:


توفر حزمة RPC أيضًا زخارف تسمح للتطبيقات بتحديد
كيفية معاملة وظيفة معينة على جانب المستدعي.


.. autofunction:: torch.distributed.rpc.functions.async_execution


.. _rpc-backends:

الخلفيات
^^^^^^^^

يمكن لوحدة RPC الاستفادة من الخلفيات المختلفة لأداء الاتصال
بين العقد. يمكن تحديد الخلفية التي سيتم استخدامها في الدالة
:func:`~torch.distributed.rpc.init_rpc`، عن طريق تمرير قيمة معينة من
الفئة :class:`~torch.distributed.rpc.BackendType` enum. بغض النظر عن الخلفية المستخدمة، فإن بقية واجهة برمجة تطبيقات RPC لن تتغير. كما تحدد كل خلفية أيضًا فئتها الفرعية الخاصة بها من فئة
:class:`~torch.distributed.rpc.RpcBackendOptions`، ويمكن أيضًا تمرير مثيل منها إلى :func:`~torch.distributed.rpc.init_rpc`
لتكوين سلوك الخلفية.

.. autoclass:: BackendType

.. autoclass:: RpcBackendOptions
    :members:


خلفية TensorPipe
""""""""""""""""""

يستفيد وكيل TensorPipe، وهو الخلفية الافتراضية، من `مكتبة TensorPipe
<https://github.com/pytorch/tensorpipe>`_، والتي توفر بدائية اتصال من نقطة إلى نقطة
مخصصة لتعلم الآلة والتي تتناول بشكل أساسي بعض قيود Gloo. مقارنة بـ Gloo،
فهي تتمتع بميزة كونها غير متزامنة، مما يسمح بحدوث عدد كبير من
عمليات النقل في نفس الوقت، كل منها بسرعته الخاصة، دون حظر بعضها البعض. سيفتح الأنابيب فقط بين أزواج العقد عند الحاجة، عند الطلب، وعندما يفشل أحد العقد، سيتم إغلاق الأنابيب الحادثة فقط، بينما ستستمر جميع الأنابيب الأخرى في العمل بشكل طبيعي. بالإضافة إلى ذلك، فهو قادر على دعم
وسائط نقل متعددة (TCP، بالطبع، ولكن أيضًا الذاكرة المشتركة، NVLink،
InfiniBand، ...) ويمكنه اكتشاف توفرها تلقائيًا والتفاوض بشأن أفضل وسيط نقل يجب استخدامه لكل أنبوب.

تم تقديم خلفية TensorPipe في PyTorch v1.6 وهي قيد التطوير النشط. في الوقت الحالي، فإنه يدعم فقط تنسيقات CPU، مع دعم GPU قادم قريبًا. يأتي مع وسيط نقل قائم على TCP، مثل Gloo. كما أنه قادر على
تجزئة وتعدد تنسيقات كبيرة عبر مقابس وخيوط متعددة من أجل تحقيق عرض نطاق ترددي عالي جدًا. سيكون الوكيل قادرًا على اختيار أفضل وسيط نقل بمفرده، دون أي تدخل مطلوب.

مثال::

    >>> import os
    >>> from torch.distributed import rpc
    >>> os.environ['MASTER_ADDR'] = 'localhost'
    >>> os.environ['MASTER_PORT'] = '29500'
    >>>
    >>> rpc.init_rpc(
    >>>     "worker1"،
    >>>     rank=0،
    >>>     world_size=2،
    >>>     rpc_backend_options=rpc.TensorPipeRpcBackendOptions(
    >>>         num_worker_threads=8،
    >>>         rpc_timeout=20 # مهلة 20 ثانية
    >>>     )
    >>> )
    >>>
    >>> # تخطي استدعاء init_rpc على worker2

.. autoclass:: TensorPipeRpcBackendOptions
    :members:
    :inherited-members:

.. note ::
  لا يقوم إطار عمل RPC بإعادة المحاولة تلقائيًا لأي
  :meth:`~torch.distributed.rpc.rpc_sync`،
  :meth:`~torch.distributed.rpc.rpc_async` و
  :meth:`~torch.distributed.rpc.remote` المكالمات. والسبب هو أنه لا توجد طريقة يمكن أن يحدد بها إطار عمل RPC ما إذا كان الإجراء معيدًا أم لا
  وما إذا كان من الآمن إعادة المحاولة. نتيجة لذلك، تقع على عاتق التطبيق مسؤولية التعامل مع الأخطاء وإعادة المحاولة إذا لزم الأمر. يعتمد الاتصال RPC على TCP ونتيجة لذلك، قد تحدث الأخطاء بسبب فشل الشبكة
  أو مشكلات اتصال الشبكة المتقطعة. في مثل هذه السيناريوهات، يحتاج التطبيق إلى إعادة المحاولة بشكل مناسب مع فترات توقف معقولة لضمان عدم إغراق الشبكة بسبب عمليات إعادة المحاولة العدوانية.

.. _rref:

RRef
----

.. warning ::
    لا يتم حاليًا دعم RRefs عند استخدام تنسيقات CUDA

RRef (Remote REFerence) هو مرجع لقيمة من نوع ما ``T``
(على سبيل المثال ``Tensor``) على عامل بعيد. يحتفظ هذا المقبض بالقيمة البعيدة المشار إليها على المالك، ولكن لا يوجد ما يشير إلى أن القيمة سيتم
نقلها إلى العامل المحلي في المستقبل. يمكن استخدام RRefs في
التدريب متعدد الآلات عن طريق الاحتفاظ بالإشارات إلى `nn.Modules
<https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`_ التي توجد على
عمال آخرين، واستدعاء الوظائف المناسبة لاسترداد أو تعديل معلماتها أثناء التدريب. راجع :ref:`remote-reference-protocol` لمزيد من التفاصيل.

.. autoclass:: PyRRef(RRef)
    :members:
    :inherited-members:


.. toctree::
    :caption: مزيد من المعلومات حول RRef

    rpc/rref

.. _remote_module:

RemoteModule
------------

.. warning ::
    لا يتم حاليًا دعم RemoteModule عند استخدام تنسيقات CUDA

"RemoteModule" هي طريقة سهلة لإنشاء "nn.Module" عن بُعد على عملية مختلفة. يقع الوحدة النمطية الفعلية على مضيف بعيد، ولكن لدى المضيف المحلي مقبض لهذه الوحدة النمطية ويستدعي هذه الوحدة النمطية بطريقة مماثلة لـ "nn.Module" العادية.
ومع ذلك، فإن الاستدعاء يتضمن مكالمات RPC إلى الطرف البعيد ويمكن إجراؤه بشكل غير متزامن إذا لزم الأمر عبر واجهات برمجة التطبيقات الإضافية التي تدعمها RemoteModule.

.. autoclass:: torch.distributed.nn.api.remote_module.RemoteModule
    :members: remote_parameters, get_module_rref


إطار عمل التدرج التلقائي الموزع
-----------------------

.. warning ::
    لا يتم حاليًا دعم التدرج التلقائي الموزع عند استخدام تنسيقات CUDA

توفر هذه الوحدة النمطية إطار عمل تدرج تلقائي موزع يعتمد على RPC يمكن استخدامه لتطبيقات مثل التدريب المتوازي للنماذج. باختصار، قد ترسل التطبيقات وتتلقى تنسيقات تسجيل التدرج عبر RPC. في تمرير الإرسال،
نقوم بتسجيل عندما يتم إرسال تنسيقات تسجيل التدرج عبر RPC وخلال تمرير الإرجاع نستخدم هذه المعلومات لأداء تمرير إرجاع موزع باستخدام RPC. لمزيد من التفاصيل، راجع :ref:`distributed-autograd-design`.

.. automodule:: torch.distributed.autograd
    :members: context, backward, get_gradients

.. toctree::
    :caption: مزيد من المعلومات حول التدرج التلقائي RPC

    rpc/distributed_autograd


المحسن الموزع
----------

راجع صفحة `torch.distributed.optim <https://pytorch.org/docs/main/distributed.optim.html>`__ للاطلاع على الوثائق حول المحسنات الموزعة.

ملاحظات التصميم
------------
تغطي مذكرة تصميم "أوتوغراد" الموزع تصميم إطار "أوتوغراد" الموزع القائم على RPC والذي يفيد في تطبيقات مثل التدريب المتوازي للنماذج.

-  :ref:`distributed-autograd-design`

تغطي مذكرة تصميم RRef تصميم بروتوكول :ref:`rref` (Remote REFerence) المستخدم للإشارة إلى القيم على العمال البعيدين بواسطة الإطار.

-  :ref:`remote-reference-protocol`

الدروس التعليمية
---------
تقدم دروس RPC للمستخدمين إطار عمل RPC، وتقدم العديد من تطبيقات المثال باستخدام واجهات برمجة التطبيقات :ref:`torch.distributed.rpc<distributed-rpc-framework>`، وتوضح كيفية استخدام `البروفايلر <https://pytorch.org/docs/stable/autograd.html#profiler>`__ لمراقبة أداء المهام المعتمدة على RPC.

-  `البدء مع إطار RPC الموزع <https://pytorch.org/tutorials/intermediate/rpc_tutorial.html>`__
-  `تنفيذ خادم المعلمات باستخدام إطار RPC الموزع <https://pytorch.org/tutorials/intermediate/rpc_param_server_tutorial.html>`__
-  `الجمع بين Distributed DataParallel مع Distributed RPC Framework <https://pytorch.org/tutorials/advanced/rpc_ddp_tutorial.html>`__ (يغطي **RemoteModule** أيضًا)
-  `مراقبة أداء المهام المعتمدة على RPC <https://pytorch.org/tutorials/recipes/distributed_rpc_profiling.html>`__
-  `تنفيذ معالجة الدفعات باستخدام RPC <https://pytorch.org/tutorials/intermediate/rpc_async_execution.html>`__
-  `توزيع Pipeline Parallel <https://pytorch.org/tutorials/intermediate/dist_pipeline_parallel_tutorial.html>`__