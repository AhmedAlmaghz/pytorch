.. _torch.compiler_dynamo_deepdive:

نظرة متعمقة على دينامو
================

TorchDynamo (أو ببساطة "داينامو") هو المُتتبع داخل "تورتش.كومبايل" (torch.compile)، وغالبًا ما يكون هو المسؤول عن تلك الأخطاء المجنونة. ومع ذلك، لا يمكننا أن نلوم "داينامو" بشكل أعمى على هذه الأخطاء. فمن أجل تزويد المستخدم بالمرونة التي يوفرها، يُوكل إلى "داينامو" المهمة الشاقة المتمثلة في فهم أي برنامج بايثون. وعلى وجه التحديد، يجب على "داينامو" أن ينفذ جزءًا كبيرًا من لغة برمجة بايثون داخليًا!

في هذا المنشور، سنستعرض التصميم الداخلي لـ "داينامو" من البداية. وسنناقش الوظائف التي يوفرها، وكيفية تنفيذها. وبنهاية هذا المنشور، ستكون لديك فكرة أفضل عن الخطأ الذي حدث عند استخدام "تورتش.كومبايل" (torch.compiled) لبرنامج بايتورتش (PyTorch) وسبب فشل عملية التجميع، أو نجاحها ولكن دون تحقيق السرعة المتوقعة.

مقدمة سهلة لداينامو
---------------

قبل أن نغوص في تفاصيل التنفيذ، دعونا نبدأ بمناقشة ما يفعله "داينامو".

"داينامو" هو مُتتبع. وهذا يعني أنه، بالنظر إلى دالة وإدخالاتها، ينفذ الدالة ويسجل تسلسلًا خطيًا من التعليمات (بدون تدفق التحكم) في رسم بياني. على سبيل المثال، لنأخذ البرنامج التالي:

.. code:: python

   import torch

   @torch.compile
   def mse(x, y):
       z = (x - y) ** 2
       return z.sum()

   x = torch.randn(200)
   y = torch.randn(200)
   mse(x, y)

إذا حفظنا هذا البرنامج في ملف باسم "مثال.باي" (example.py) وقمنا بتشغيله باستخدام

.. code:: bash

   TORCH_LOGS=graph_code python example.py

فسنرى الإخراج الذي قام "داينامو" بتتبعه

.. code:: python

   def forward(l_x_: torch.Tensor, l_y_: torch.Tensor):
       # File: example.py:5, code: z = (x - y) ** 2
       sub = l_x_ - l_y_
       z = sub ** 2
       # File: example.py:6, code: return z.sum()
       sum_1 = z.sum()
       return (sum_1,)

نطلق على هذا اسم **رسم بياني (أو تتبُّع) للدالة بالنسبة للإدخالات المُعطاة**. وهذا يُمثَّل عبر رسم بياني "إف إكس" (FX graph). وسنفكر ببساطة في رسم بياني "إف إكس" على أنه حاوية تخزن قائمة من استدعاءات الدوال.

أول شيء يجب ملاحظته هو أن الرسم البياني عبارة عن تسلسل خطي من عمليات بايتورتش. [1]_ يقوم "داينامو" بتسجيل جميع عمليات بايتورتش وتخزينها بشكل تسلسلي. على سبيل المثال، فإنه يُجزئ "z = (x - y) ** 2" إلى عمليتيه المكونتين، "sub = l_x_ - l_y_" و "z = sub ** 2".

عندما نقول إن التتبع خطي، فإننا نعني أنه لا يوجد تفرع أو أي تدفق للتحكم. ولرؤية ذلك، لنأخذ المثال التالي:

.. code:: python

   import torch

   @torch.compile
   def fn(x, n):
       y = x ** 2
       if n >= 0:
           return (n + 1) * y
       else:
           return y / n

   x = torch.randn(200)
   fn(x, 2)

الذي، عند تنفيذه باستخدام "TORCH_LOGS=graph_code"، يعطي

.. code:: python

   def forward(l_x_: torch.Tensor):
       # File: example.py:5, code: y = x ** 2
       y = l_x_ ** 2
       # File: example.py:7, code: return (n + 1) * y
       mul = 3 * y
       return (mul,)

نلاحظ أن "داينامو" قام بإزالة عبارة "if" تمامًا من التتبع وسجَّل فقط العمليات التي تم تنفيذها مع الإدخالات.

وبالتالي، ينبغي أن يكون من الواضح أن **تتبع الدالة يعتمد على الإدخالات**. وهذا يعني، على وجه التحديد، أن التتبع لا يتم إنشاؤه عند كتابة "@torch.compile"، ولكن عندما يتم تنفيذ الدالة "fn(x, 2)" مع وسائط فعلية.

الشيء المثير للاهتمام الآخر الذي يجب ملاحظته هنا هو أن "داينامو" قام بإزالة وسيط الدالة الثاني. وبدلاً من ذلك، عومل كقيمة ثابتة وسُجلت نتيجة العملية "n + 1" في الرسم البياني. هذه هي ميزة أخرى لـ "داينامو": سيعامل "داينامو" أي قيمة غير تنسيقية كقيمة ثابتة... باستثناء الأعداد الصحيحة. دعونا نرى الآن كيف تُعامل الأعداد الصحيحة بشكل خاص.

الخاصية المميزة الأخيرة لـ "داينامو" هي أنه يعرف كيفية التعامل مع الأشكال الديناميكية. تشير الأشكال الرمزية إلى قدرة "داينامو" على تتبع الأشكال، وبشكل أعم، الأعداد الصحيحة، بدلاً من تركها كقيم ثابتة. يسمح ذلك بتجنب إعادة التجميع ونشر نماذج عامة تعمل لأي حجم في الإنتاج. والأمثلة الرئيسية للأماكن التي تظهر فيها الأشكال الديناميكية هي حجم الدفعة، حيث قد نقوم بتدريب نموذج بحجم دفعة ثابت ولكن بعد ذلك نؤدي الاستدلال لحجم دفعة عشوائي، أو طول التسلسل المتغير الذي يصادفه المرء عند معالجة النص أو الصوت.

يمكننا أن نرى هذا عن طريق تنفيذ المثال أعلاه عدة مرات

.. code:: python

   import torch

   @torch.compile
   def fn(x, n):
       y = x ** 2
       if n >= 0:
           return (n + 1) * y
       else:
           return y / n

   x = torch.randn(200)
   fn(x, 2)
   fn(x, 3)
   fn(x, -2)

في هذه الحالة، يقوم "TORCH_LOGS=graph_code" بتوليد رسمين بيانيين آخرين

.. code:: python

   # Graph for n==2 omitted

   def forward(self, l_x_: torch.Tensor, l_n_: torch.SymInt):
       # File: a.py:5, code: y = x ** 2
       y = l_x_ ** 2

       # File: a.py:7, code: return (n + 1) * y
       add = l_n_ + 1
       mul = add * y
       return (mul,)

.. code:: python

   def forward(self, l_x_: torch.Tensor, l_n_: torch.SymInt):
       # File: a.py:5, code: y = x ** 2
       y = l_x_ ** 2

       # File: a.py:9, code: return y / n
       truediv = y / l_n_
       return (truediv,)

اكتشف "داينامو" أن عددًا صحيحًا واحدًا قد تغيرت قيمته بعد الاستدعاء الأول وبدأ في تتبعه. نلاحظ أن هذه الرسوم البيانية عامة، وتتبع المتغير "n" بشكل رمزي عبر كائن من النوع "SymInt".

إذا قمنا، بعد هذه الاستدعاءات، باستدعاء "fn(x, 4)"، فلن يقوم "داينامو" بإعادة التجميع، بل سيُعيد استخدام الرسم البياني الذي تم تتبعه بالفعل.

ملخص: 1. "داينامو" هو مُتتبع بايثون 2. بالنظر إلى بعض الإدخالات، فإنه يعيد رسمًا بيانيًا "إف إكس" (FX graph) مع دالات بايتورتش التي تم تنفيذها 3. يمكنه أيضًا تتبع الأعداد الصحيحة إذا اكتشف أنها تغيرت بين الاستدعاءات 4. يقوم بتخصيص أي قيمة أخرى ليست تنسورية أو عددًا صحيحًا

بالطبع، يقوم "داينامو" بالعديد من المهام الأخرى، مثل معرفة متى يحتاج إلى إعادة التتبع، وإعادة كتابة بايت كود الدالة، وتنفيذ فواصل الرسم البياني... ولإبقاء المقدمة مختصرة، سنناقش جميع هذه الأمور بشكل متزايد في ما يلي.

PEP 523: إضافة واجهة برمجة تطبيقات لتقييم الإطار إلى CPython
-------------------------------------------------

تخيل الآن أننا كُلفنا بمهمة تنفيذ "داينامو". من أين نبدأ؟ من الملائم لنا أن `PEP 523 <https://peps.python.org/pep-0523/>`__ تم إصداره مع بايثون 3.6. تم تصميم هذا الـ PEP `لتمكين <https://peps.python.org/pep-0523/#a-jit-for-cpython>`__ الأطراف الثالثة من إنشاء مجمعات JIT لـ بايثون. دعونا نرى كيف.

**ملاحظة حول CPython**: يتم تنفيذ CPython داخليًا كـ `آلة مكدس <https://en.wikipedia.org/wiki/Stack_machine>`__. يتم تجميع برنامج بايثون إلى `بايت كود <https://en.wikipedia.org/wiki/Bytecode>`__ يتم تنفيذه بعد ذلك بواسطة هذا المفسر. لمعرفة المزيد عن بايت كود، راجع `وحدة dis <https://docs.python.org/3/library/dis.html>`__ من المكتبة القياسية. راجع أيضًا `وثائق المطورين <https://devguide.python.org/internals/interpreter/>`__ للتعرف على مفسر CPython. سنفترض أن القارئ مُلم بمفهوم آلة المكدس.

يعرض PEP 523 واجهة برمجة تطبيقات حيث يمكن للمستخدم إضافة مفسر مخصص لكل دالة. بعد ذلك، سيستخدم CPython هذا المفسر بدلاً من مفسره الخاص لتنفيذ الدالة. حتى يتمكن من تنفيذ الدالة، يقوم CPython، عند الدخول، بتزويد المفسر المخصص الخاص بالمستخدم بأشياء مثل - بايت كود الدالة - قيمة وسائط الدالة (أي المتغيرات المحلية) وأسمائها - قيمة المتغيرات العالمية وأسمائها - الدوال المدمجة مثل "abs" أو "print"

يمكنك الاطلاع على جميع الحقول `هنا <https://github.com/pytorch/pytorch/blob/e891a3bba9f05697d72776f6e89347231a141f03/torch/csrc/dynamo/eval_frame.c#L50-L59>`__. [2]_

باختصار، يوفر CPython لمفسر المستخدم جميع المعلومات اللازمة لتنفيذ الدالة. [3]_

مع واجهة برمجة التطبيقات هذه، يمكننا تنفيذ مُتتبع عن طريق تنفيذ مفسر يسجل جميع عمليات بايتورتش التي تحدث أثناء التنفيذ في رسم بياني. وهذا بالضبط ما يفعله "داينامو".

يستخدم "داينامو" واجهة برمجة تطبيقات CPython هذه لتفسير جميع هذه الكائنات وتعبئتها في `هيكل بايثون <https://github.com/pytorch/pytorch/blob/e891a3bba9f05697d72776f6e89347231a141f03/torch/csrc/dynamo/eval_frame.c#L93-L108>`__. وبعد أن يفعل ذلك... فإنه يعود من C إلى بايثون. وباستثناء شفرة البرنامج هذه التي تتواصل مع CPython، يتم تنفيذ "داينامو" بالكامل في بايثون.

ينبغي أن يكون من الواضح أن وظيفة مُزيِّن الدالة "@torch.compile" هي تثبيت السقالات اللازمة التي ستنقل بايت كود الدالة والوسائط والمتغيرات العالمية، وما إلى ذلك، إلى "داينامو" عندما يتم استدعاء الدالة. مرة أخرى، لا يقوم "@torch.compile" بتجميع أي شيء بالفعل.

تنفيذ CPython في بايثون
نعود الآن إلى عالم بايثون. لدينا كود بايتكود لوظيفة ما، وجميع السياق اللازم لتنفيذها. على وجه التحديد، وصلنا إلى:

`_convert_frame_assert <https://github.com/pytorch/pytorch/blob/b6df8414601e1e086e830ca9e919e7fdc8874e71/torch/_dynamo/convert_frame.py#L272-L274>`__.

هذه هي الوظيفة التي يعيدها الديكور "torch.compile"! نصل إلى هذه الوظيفة من:

`_dynamo.optimize <https://github.com/pytorch/pytorch/blob/b6df8414601e1e086e830ca9e919e7fdc8874e71/torch/_dynamo/eval_frame.py#L715-L727>`__.

الديكور "torch.compile" هو مجرد واجهة برمجة تطبيقات لطيفة حول "_dynamo.optimize".

قبل الدخول في تنفيذ مفسر بايثون، نريد أن نحدد IR (تمثيل وسيط). على وجه التحديد، نريد لف جميع المتغيرات المحلية والعالمية في فئاتنا الداخلية الخاصة. يسمح لنا هذا بتتبع هذه الكائنات بشكل أفضل وتجميع الكائنات التي يمكن معاملتها بنفس الطريقة في نظر دينامو.

الفئة الأم لهيكل الفئة الداخلية هي "VariableTracker" وتمثل الكائنات المختلفة التي يفهمها دينامو. على سبيل المثال، يمثل "ListVariable" كائن "قائمة"، ويحتفظ داخليًا بـ "قائمة من VariableTrackers". مثال آخر على "VariableTracker" هو "ConstantVariable". يلف ConstantVariable جميع "الكائنات التي تعتبر ثابتة بواسطة دينامو".

لدينا أيضًا فئات فرعية خاصة للكائنات التي تتطلب اهتمامًا خاصًا، مثل "TensorVariable". يتم تحديد جميع هذه الفئات الداخلية في المجلد "torch/_dynamo/variables".

يتم لف كائنات بايثون في فئة "VariableTracker" المقابلة لها في "VariableBuilder._wrap". هذه الوظيفة هي مجرد سلسلة طويلة جدًا من "elif" التي تحاول مطابقة أنماط الإدخالات بايثون بشكل متكرر في نوع "VariableTracker" المناسب.

**نصيحة للتصحيح**. عندما نحصل على نتائج غير متوقعة من دينامو، يكون ذلك في بعض الأحيان بسبب الباني. إذا كانت منطق الباني خاطئة، فقد يقوم دينامو بلف متغير في النوع غير الصحيح من "VariableTracker"، وقد يتسبب ذلك في حدوث مشكلات لاحقًا. من المفيد جدًا إلقاء نظرة على أنواع "VariableTracker" التي تظهر في الأخطاء، وطريقة "VariableTracker" التي تُلقي الاستثناء عند مواجهة خطأ دينامو. على وجه التحديد، نجد في بعض الأحيان أن الكائن يتم تتبعه على أنه "UserDefinedObjectVariable" (هذه هي فئة دينامو العامة)، عندما كان يجب تتبعه كشيء أكثر تحديدًا. في هذه الحالات، يكون منطق "SourceBuilder.__call__" هو غالبًا المذنب.

**نصيحة للتصحيح**. عند تشغيل برنامج باستخدام "TORCH_LOGS=dynamo"، تتم طباعة أحد الآثار التي تتم طباعتها على شكل:

::

   TRACE LOAD_GLOBAL y [TorchInGraphFunctionVariable(<built-in method any>), TensorVariable()]

هذا هو كود البايتكود للبرنامج الأصلي وحالة المكدس في تلك النقطة. هذا مفيد جدًا لمعرفة المكان الذي لم يتم فيه تتبع كائن إلى النوع الصحيح من "VariableTracker".

حسنًا، لذا لدينا IR لمتتبعنا، والآن نحتاج فقط إلى إعادة تنفيذ آلة المكدس CPython. يتم تنفيذه بواسطة "InstructionTranslatorBase" في "symbolic_convert.py".

يحتوي "InstructionTranslatorBase" على حوالي 200 طريقة، تنفذ جميع بايتكودات بايثون تقريبًا. على سبيل المثال، يمكننا أن نرى تنفيذ "BUILD_LIST":

.. code:: python

   def BUILD_LIST(self, inst):
       items = self.popn(inst.argval)
       self.push(ListVariable(items, mutable_local=MutableLocal()))

هذا هو كود البايتكود الذي تم إنشاؤه بواسطة إنشاءات مثل "l = [2، 3، 4]". في هذه الحالة، نظرًا لوجود ثلاثة عناصر، يكون كود البايتكود الذي تم إنشاؤه هو "BUILD_LIST 3". وهذا يعني أننا نخرج العناصر الثلاثة الأولى من المكدس ونضيف كائن قائمة جديدًا إلى أعلى المكدس والذي يتكون من هذه العناصر الثلاثة.

إنشاء الرسم البياني للناتج
-------------------

مع وجود طريقة لتنفيذ رمز بايثون بشكل رمزي، يمكننا استخراج عمليات PyTorch التي تحدث أثناء التنفيذ الرمزي لبرنامج ما نظرًا لبعض الإدخالات. يتم تنفيذه في دينامو عبر كائن "OutputGraph". يتم ربط كائن "OutputGraph" بـ "InstructionTranslator object" ويقوم بتتبع جميع البيانات اللازمة لإنشاء رسم FX البياني الذي سيتم إرجاعه بواسطة دينامو.

جميع المدخلات والعناصر الوسيطة لرسم FX البياني هي "fx.Node"s. في دينامو، يتم لف "fx.Node"s في "fx.Proxy"s. يتم استخدام "fx.Proxy"s لبناء رسم FX البياني. على وجه التحديد، فإنها تسجل كل عملية PyTorch التي يتم إجراؤها عليها في الرسم البياني. يمكنك إنشاء عملية جديدة لإضافتها إلى الرسم البياني عن طريق استدعاء "create_proxy". بعد ذلك، يمكننا إضافته إلى الرسم البياني من خلال وظيفة "wrap_fx_proxy".

يحتفظ الرسم البياني بالعمليات على المصفوفات... والعمليات على الأعداد الصحيحة الرمزية. سنناقش الأعداد الصحيحة الرمزية لاحقًا، ولكننا سنناقش أولاً كيف يعالج دينامو مشكلة صحة مهمة إلى حد ما.

.. _making-dynamo-sound-guards:

جعل دينامو سليمة: الحرس
------------------

في هذه المرحلة، لدينا طريقة لتتبع البرامج التي تتجاهل تدفق التحكم تمامًا. وللقيام بذلك، قمنا بإعادة تنفيذ جميع CPython... إذا كان هذا يبدو مبالغًا فيه بعض الشيء، فهو كذلك. "torch.jit.trace" ينفذ هذا بالفعل دون كل هذه الآلات، إذن ما الذي يعطيه؟

المشكلة مع "torch.jit.trace"، كما هو محذر في وثائقه، هي أنه يعمل فقط إذا لم يكن البرنامج المتبع يعتمد على البيانات. وبعبارة أخرى، سيعمل فقط إذا كان البرنامج نفسه خطيًا. وهذا يعني كتابة برنامجنا دون استخدام if-elses، for-while loops، exceptions. علاوة على ذلك، لا يمكن لأي من المكتبات التي نستخدمها استخدام أي تدفق تحكم! في النهاية، فإن عدم استخدام تدفق التحكم في لغة ديناميكية مثل بايثون هو في الواقع قيد كبير.

يحل JAX هذه المشكلة عن طريق إعادة التتبع دائمًا وتخزين الرسم البياني في ذاكرة التخزين المؤقت بعد إعادة التتبع. من ناحية أخرى، يستخدم دينامو الحرس لتجنب إعادة تتبع البرنامج بأكمله في كل مرة.

الحرس هو افتراض (تعبير منطقي على إدخال) يتم إجراؤه من أجل تخصيص إطار لمجموعة من إدخالات المثال. إعادة استخدام الرسم البياني صالحة فقط إذا كانت هذه الافتراضات صحيحة بالنسبة للإدخالات الجديدة.

على سبيل المثال، يقوم أي إدخال ثابت إلى وظيفة، مثل سلسلة، بتثبيت حارس ينص على أنه يجب أن يكون نوع الإدخال "str" ويساوي السلسلة التي مررناها. تشغيل:

.. code:: python

   import torch

   @torch.compile
   def fn(a, b):
       return a * len(b)

   fn(torch.arange(10), "Hello")

مع "TORCH_LOGS=guards" يطبع (من بين حراس آخرين):

.. code:: python

   ___check_type_id(L['b'], 94334122025024)
   L['b'] == 'Hello'

هذا يعني "ينبغي أن يكون للمتغير المحلي b نوع محدد (str في هذه الحالة، ممثلة بالثابت 9433...) وقيمته يجب أن تكون "Hello". إذا قمنا بعد ذلك بتنفيذ الوظيفة مرة أخرى بتمرير حجة مختلفة:

.. code:: python

   import torch

   @torch.compile
   def fn(a, b):
       return a * len(b)

   fn(torch.arange(10), "Hello")
   fn(torch.arange(10), "Hi")

يمكننا أن نرى الحارس الذي فشل عن طريق تشغيل "TORCH_LOGS=recompiles":

.. code:: python

   Recompiling function fn in script.py:3
   triggered by the following guard failure(s):
        - L['b'] == 'Hello'

يتم تجميع الحرس أثناء "لف إدخالات الوظيفة في الباني" وخلال "تنفيذ البرنامج". سنعرض العديد من الأمثلة الأخرى للحرس في القسم التالي، ولكن دعنا نناقش المصادر أولاً.

يتتبع **المصدر** كيفية إعادة بناء متغير من المتغيرات المحلية أو العالمية الأصلية الموجودة عند دخول الإطار الحالي. على وجه التحديد، يتتبع الكائنات المحلية والعالمية الأصلية وأي من الكائنات التي تحتويها. في:

.. code:: python

   def foo(x: Tensor, y: List[Tensor]):
       a = x * y[0]
       return a * x

يكون لـ "x" و "y" "LocalSource" كمصدر لهما، ويكون لـ "y[0]" "GetItemSource"، والذي يقوم بتخزين "LocalSource" بداخله. من ناحية أخرى، لن يكون لـ "a" مصدر لأنه متغير وسيط لا يوجد إلا داخل رسم FX البياني.

جميع هذه محددة في "torch/_dynamo/source.py". يمكننا أن نرى الحارس الذي تم إنشاؤه بواسطة "GetItemSource" في المثال التالي:

.. code:: python

   import torch

   @torch.compile
   def fn(x, l):
       return x * len(l[0])

   fn(torch.randn(8), ["Hi", "Hello"])

ينشئ الحرس التالي:

.. code:: python

   ___check_type_id(L['l'], 94439025877664)
   len(L['l']) == 2
   ___check_type_id(L['l'][0], 94439025840192)
   L['l'][0] == 'Hi'
   ___check_type_id(L['l'][1], 94439025840192)
   L['l'][1] == 'Hello'

هنا، نرى الرمز الذي تم إنشاؤه بواسطة "GetItemSource" ( "[0]" و "[1]") الذي يقوم بلف "LocalSource" ("L['l']").

في هذه المرحلة، مع المصادر والحرس، يمكننا تنفيذ نظام ذاكرة التخزين المؤقت لتجنب إعادة التجميع دون الحاجة إلى إعادة التتبع في كل مرة. سنناقش بمزيد من التفصيل نظام ذاكرة التخزين المؤقت هذا في الجزء التالي.

لاحظ القارئ اليقظ أن هذا لا يفسر بعد سبب الحاجة إلى التحكم الدقيق جدًا في مفسر بايثون لدرجة إعادة تنفيذه. تعتمد أمثلة الحرس التي أظهرناها على كائنات الإدخال، لذا يمكننا حسابها قبل تنفيذ الوظيفة. وبعبارة أخرى، يمكننا تنفيذ نظام الحرس هذا أعلى "torch.jit.trace" والحصول على نفس الوظائف بجهد أقل... ادخل الأشكال الرمزية.

الأشكال الرمزية
هنا نصك مترجم إلى العربية بنفس تنسيق ReStructuredText:

---------------

ناقشنا في المقدمة نقطة أخرى وهي أن Dynamo يعرف كيفية تتبع الأعداد الصحيحة. ولتنفيذ ذلك، نستخدم فئة رمزية `torch.SymInt <https://github.com/pytorch/pytorch/blob/fb80f05ee2e1cba17892980701bfd5dbce58349f/torch/__init__.py#L244-L249>`__ التي تعمل مثل ``int`` ولكنها تسجل جميع العمليات التي يتم إجراؤها عليها في مخطط FX الناتج. [4]_ لقد رأينا بالفعل هذه الفئة في المقدمة عند تقديم التتبع الرمزي للأعداد الصحيحة.

دعونا الآن نناقش الخصائص الثلاث التي تحدد التتبع الرمزي للشكل في Dynamo، وكيفية تنفيذها.

ثابت بشكل افتراضي
^^^^^^^^^^^^^^^

يفترض Dynamo أن كل عدد صحيح، سواء كان ذلك إدخالا أو شكل مصفوفة، ثابت بشكل افتراضي. وبعبارة أخرى، لن يتم تتبع أي أعداد صحيحة في التنفيذ الأول للدالة. ثم، فقط إذا اكتشف أن عددًا صحيحًا أو شكلًا قد تغيرت قيمته أثناء التنفيذ، فسيتم تتبعه وإنشاء مخطط عام بالنسبة إلى ذلك المتغير.

لقد رأينا بالفعل هذا السلوك في المقدمة باستخدام الأعداد الصحيحة. دعونا الآن نلقي نظرة على مثال باستخدام أشكال المصفوفات.

.. code:: python

   import torch

   @torch.compile
   def fn(a, b):
       return a.shape[0] * a * b

   fn(torch.randn(4, 3), torch.randn(4, 3))
   fn(torch.randn(8, 3), torch.randn(8, 3))

عند تشغيل هذا البرنامج مع ``TORCH_LOGS=graph_code``، نرى أن هاتين المكالمة يتم تتبعهما على النحو التالي:

.. code:: python

   def forward(self, l_a_: torch.Tensor, l_b_: torch.Tensor):
       mul = 4 * l_a_
       mul_1 = mul * l_b_
       return (mul_1,)

   def forward(self, s0: torch.SymInt, l_a_: torch.Tensor, l_b_: torch.Tensor):
       size = l_a_.size()
       getitem = size[0]
       mul = getitem * l_a_
       mul_1 = mul * l_b_
       return (mul_1,)

في المخطط الأول، يتم تتبع الشكل كقيمة ثابتة، ولكن بمجرد تغييره، يتم تتبعه بشكل رمزي باستخدام ``SymInt``\ s. بشكل عام، هناك طريقة أبسط لرؤية أشكال القيم الوسيطة وهي تشغيل البرنامج مع ``TORCH_LOGS=graph_sizes``

::

   TRACED GRAPH TENSOR SIZES
   ===== __compiled_fn_1 =====
   l_a_: (s0, 3)
   l_a_ (concrete): (8, 3)
   l_b_: (s0, 3)
   l_b_ (concrete): (8, 3)
   mul: (s0, 3)
   mul (concrete): (8, 3)
   mul_1: (s0, 3)
   mul_1 (concrete): (8, 3)

حيث يمكننا أن نرى أن البعد الأول لحججي مصفوفة التنس هو ديناميكي، نظرًا لأنه يتم تمثيله بواسطة متغير ``s0``.

يمكننا معرفة كيفية تنفيذ Dynamo لهذا عن طريق تشغيل ``TORCH_LOGS=guards``

.. code:: python

   # Guards first call
   check_tensor(L['a'], torch.float32, device=None, requires_grad=False, size=[4, 3], stride=[3, 1])
   check_tensor(L['b'], torch.float32, device=None, requires_grad=False, size=[4, 3], stride=[3, 1])

   # Guards second call
   check_tensor(L['a'], torch.float32, device=None, requires_grad=False, size=[None, 3], stride=[3, 1])
   check_tensor(L['b'], torch.float32, device=None, requires_grad=False, size=[None, 3], stride=[3, 1])

   L['b'].size()[0] == L['a'].size()[0]
   2 <= L['a'].size()[0]

نرى أنه في المكالمة الأولى، يتحقق الحرس من أن المصفوفات لها أحجام ومسافات ثابتة. تفشل هذه الحراس في التنفيذ الثاني، لذلك يتم إعادة التتبع. نظرًا لأنه كان حارسًا للأعداد الصحيحة الذي فشل، في هذه الحلقة الثانية، فإنه يتتبع هذا العدد الصحيح بشكل رمزي ويقوم بتثبيت حراس أكثر عمومية على هذه النواة الأكثر عمومية.

**نصيحة أداء التجميع**. إذا كنت تعلم أن بعدًا سيختلف في الحجم، فيمكنك تمييزه كديناميكي عن طريق استدعاء `torch._dynamo.mark_dynamic <https://github.com/pytorch/pytorch/blob/66a76516bfc341b2b55bb2056d2faa9c2de46d69/torch/_dynamo/decorators.py#L176>`__ قبل استدعاء ``torch.compile``. سيؤدي هذا إلى تجنب التجميع الأول بشكل ثابت. هناك أيضًا وظائف مساعدة مفيدة مثل ``maybe_mark_dynamic`` أو ``mark_static``. يمكنك أيضًا تتبع جميع الأعداد الصحيحة والأشكال عن طريق استدعاء ``torch.compile(dynamic=True)``. هذا مفيد بشكل أساسي لأغراض التصحيح.

0، 1 متخصصان دائمًا
^^^^^^^^^^^^^^^^^^^^^^^^^^^

بغض النظر عما إذا كنا نحدد بعدًا كديناميكي، إذا مررنا بإدخال حيث يكون هذا البعد 0 أو 1، فسيقوم Dynamo بتتبعه على أنه غير ديناميكي وسيقوم بتوليد مخطط محدد له. هذا هو السبب في أننا نجد حراسًا على شكل ``2 <= L['a'].size()[0]`` في المثال أعلاه.

هناك عدة أسباب لهذا الاختيار. هناك سببان مهمان بشكل خاص - مصفوفة فارغة إذا وفقط إذا كان أي من أبعادها صفرًا - لا يمكن أن تكون المصفوفة متجاورة إلا إذا كان أحد المسافات يساوي واحدًا

لا تنطبق سياسة القرار هذه على أعداد Python الصحيحة العادية؛ إذا كنا نعتقد أن عددًا صحيحًا في Python يجب أن يتم تجميعه ديناميكيًا، فلن نقوم بتخصيصها بشكل افتراضي؛ بدلاً من ذلك، ما إذا كان يتم تخصيصها أم لا يعتمد على استخدامها.

تشكيل البط
^^^^^^^^^^^^

يقوم Dynamo بما نسميه "تشكيل البط". إذا كان هناك عددان صحيحان ديناميكيان لهما نفس القيمة في وقت التتبع، فسوف نفترض أنهما متساويان ونحميها. وهذا يعني فعليًا أنه بدلاً من وجود رمزين ``s0``، ``s1`` في المثال أعلاه، فقد وحدناهما ببساطة إلى ``s0`` وكان الحارس ``L['b'].size()[0] == L['a'].size()[0]``. يمكّن ذلك من إجراء عمليات دمج داخل المترجم أثناء القدرة على إنشاء نوى عامة بما يكفي.

حراس على الأعداد الصحيحة الرمزية
^^^^^^^^^^^^^^^^^^^^^^^

الآن بعد أن فهمنا كيف يتم تنفيذ الأشكال الرمزية على مستوى عالٍ والخصائص التي تمتلكها. الآن، لماذا الأشكال الرمزية أجبرتنا على الطريق الصعب المتمثل في الحصول على تحكم في مفسر CPython؟ ضع في اعتبارك المثال التالي:

.. code:: python

   import torch

   @torch.compile(dynamic=True)
   def fn(a):
       if a.shape[0] * 2 < 16:
           return a
       else:
           return a + 1

   fn(torch.randn(8))

يحتوي هذا الكود على حارس على شكل ``2*L['a'].size()[0] >= 16``. هذه حارس غير تافهة من حيث مدخلات الدالة، ولكن يتم تسجيلها في منتصف تنفيذ البرنامج. والأكثر من ذلك، لا يمكننا معرفة أن هذا الحارس مطلوب حتى نرى شرط "if" الشرطي على حجة ``SymNodeVariable``. مثل هذه الشروط غير مرئية لـ ``torch.jit.trace`` وتتطلب تحليلًا عميقًا لرمز Python.

**نصيحة التصحيح** عند تشغيل هذا الكود مع ``TORCH_LOGS=dynamo``، فإنه يخبرنا بالمكان الذي تمت فيه إضافة هذا الحارس

::

   eval 2*s0 >= 16 [guard added] at script.py:5 in fn (_dynamo/variables/tensor.py:812 in evaluate_expr)

وضع نقطة توقف هناك والنظر في تتبع المكدس مفيد جدًا لفهم المكان الذي جاء منه الحارس.

جعل Dynamo مكتمل: كسور المخطط
بالرغم من كل الأدوات التي ناقشناها، فإن لدينا أداة تتبع يمكنها تتبع عمليات PyTorch على المصفوفات والأعداد الصحيحة، ولديها نظام تخزين مؤقت يعرف متى يمكنه إعادة استخدام مخطط تم تتبعه مسبقًا ومتى يحتاج إلى إعادة التتبع. كل هذا أثناء تنفيذ تعليمات برمجية Python عشوائية!

هناك فقط مشكلة صغيرة واحدة مع هذا. قد يكون بيان "تنفيذ تعليمات برمجية Python عشوائية" عامًا بعض الشيء. ينفذ Dynamo جزءًا جيدًا من Python، ولكن هل ينفذ الأجزاء الأكثر تعقيدًا، مثل الروتينات الفرعية أو async؟ هل ينفذ مكتبة Python القياسية بأكملها؟ لدى NumPy أيضًا واجهة برمجة تطبيقات Python. هل يفهم "torch.compile" أيضًا NumPy؟ وDjango؟ [5] _

النظام البيئي لـ Python هائل، وجزء كبير منه مكتوب بلغات أخرى أكثر كفاءة مثل C++ أو Rust، ويقوم فقط بتعريض روابط Python. لا يوجد أمل في أن يقوم Dynamo بتتبع كائنات Python التي يتم تنفيذها في C++. ماذا يمكن أن تفعل أداة التتبع عندما تجد عملية لا تفهمها؟

الطريقة المعتادة التي تتعامل بها أدوات التتبع الخاصة بالتعلم الآلي مع هذه المشكلة هي إبلاغ المستخدم بالعملية التي تعثرت فيها والتخلي عن التتبع تمامًا. من شأن هذا أن يطرح مشكلة حقيقية في قابلية الاستخدام في حالة PyTorch، حيث اعتاد مستخدموها على المرونة التي توفرها لهم. كمثال من العالم الحقيقي، يستخدم نموذج "doctr_det_predictor" NumPy ومكتبة "cv2" لـ `معالجة نتيجة النموذج <https://github.com/mindee/doctr/blob/f2114758d529ed8d3d00030581638f0520b6b98d8/doctr/models/detection/core.py#L86>`__.

هنا مكان آخر يكون فيه الوصول إلى CPython مثيرًا للاهتمام. بدلاً من إظهار خطأ، يمكن لـ Dynamo أن يجعل CPython ينفذ تلك التعليمات البرمجية المشكلة! للقيام بذلك، يقوم Dynamo بتوليد مخطط واحد في وقت التتبع مع جميع العمليات قبل التعليمات البرمجية المشكلة، ومخطط واحد مع جميع العمليات بعد ذلك. [6] _ بعد ذلك، في وقت التشغيل، سيفوض إلى CPython لتنفيذ المخطط الأول، ثم التعليمات البرمجية المشكلة، ثم المخطط الثاني. وتسمى هذه العملية لإيقاف التتبع وتوليد مخططات متعددة **كسر المخطط**.

اعتراف صغير: لقد كذبت طوال المقدمة والأقسام الأولى. لا يقوم Dynamo بتوليد مخطط واحد، ولكن **مخططات متعددة**! لأغراض عملية، يمكن اعتبار بدء إعادة التتبع بعد مخطط ثانٍ مثل بدء تتبع دالة جديدة. سيكون للمخطط الجديد بعد كسر المخطط حراسه، ومجموعة متغيرات محلية جديدة، وهكذا.

لمناقشة كيفية تنفيذ كسور المخططات، نحتاج أولاً إلى إعادة النظر في كيفية تفاعل Dynamo مع CPython. باستخدام PEP 523، تسمح CPython للمستخدم باستخدام آلية تقييم الإطار الخاصة به. ما لم نناقشه هو أن CPython تعرض أيضًا تقييم الإطار الخاص بها للآخرين لاستخدامها. يستفيد Dynamo من هذا للسماح لمفسر CPython السريع بتشغيل التعليمات البرمجية المترجمة. لعملية بدون كسور في المخطط، تبدو عملية التتبع/التنفيذ الكاملة لبرنامج يستدعي الدالة مرتين بنفس الحجج على النحو التالي:

1. في المكالمة الأولى للدالة

   1. يقوم Dynamo بتتبع الدالة في مخطط FX

      1. يقوم المترجم (Inductor) بتجميع مخطط FX إلى تعليمات برمجية منخفضة المستوى وفعالة... ولكن هذه قصة ليوم آخر

   2. يقوم بإعادة كتابة بايت كود للدالة بحيث تقوم ببساطة باستدعاء الدالة المترجمة
   3. يقوم بإعطاء CPython بايت كود الجديد ويطلب منه تشغيله
      [`هنا <https://github.com/pytorch/pytorch/blob/e891a3bba9f05697d72776f6e89347231a141f03/torch/csrc/dynamo/eval_frame.c#L1006>`__]

2. في المكالمة الثانية للدالة

   1. يتحقق من حراس المكالمة الأولى مقابل الحجج الجديدة
      [`هنا <https://github.com/pytorch/pytorch/blob/e891a3bba9f05697d72776f6e89347231a141f03/torch/csrc/dynamo/eval_frame.c#L658>`__].
      نظرًا لأنها نفس الحجج كما كانت من قبل، فإنها تمر
   2. يطلب من CPython تشغيل بايت كود المرتبط بتلك الحراس
      [`هنا <https://github.com/pytorch/pytorch/blob/e891a3bba9f05697d72776f6e89347231a141f03/torch/csrc/dynamo/eval_frame.c#L972-L975>`__]

تبدو هذه العملية في حد ذاتها معقدة للغاية. لماذا يتم إنشاء بايت كود جديد وطلب تشغيله من CPython بدلاً من مجرد إنشاء ارتباط C++ للدالة المترجمة وتشغيلها؟ حسنًا، يسمح لنا هذا النمط بتنفيذ كسور المخطط! بايت كود الذي تم إنشاؤه بواسطة كسر المخطط له البنية التالية:

1. بايت كود الذي ينفذ المخطط الأول
2. بايت كود يترك المكدس كما لو كان CPython قد نفذ المخطط الأول. كما يقوم بتشغيل أي تعديلات على المتغيرات المحلية أو العالمية التي ستكون مرئية في هذه المرحلة
3. بايت كود الذي جعل Dynamo يكسر المخطط
4. بايت كود الذي ينفذ المخطط الثاني

دعونا نرى هذا في مثال بسيط

.. code:: python

   import torch

   @torch.compile
   def fn(a):
       b = a + 2
       print("Hi")
       return b + a

   fn(torch.randn(4))

يُظهر لنا تشغيل هذا مع ``TORCH_LOGS=bytecode`` بايت كود الأولي وبايت كود المعدل

.. code:: python

   MODIFIED BYTECODE fn script.py line 3
    0 LOAD_GLOBAL              1 (__compiled_fn_0)
    2 LOAD_FAST                0 (a)
    4 CALL_FUNCTION            1
    6 STORE_FAST               3 (graph_out_0)
    8 LOAD_GLOBAL              0 (print)
   10 LOAD_CONST               2 ('Hi')
   12 LOAD_FAST                3 (graph_out_0)
   14 LOAD_CONST               3 (0)
   16 BINARY_SUBSCR
   18 STORE_FAST               1 (b)

   20 CALL_FUNCTION            1
   22 LOAD_GLOBAL              2 (__resume_at_14_1)
   24 ROT_TWO
   26 LOAD_FAST                0 (a)
   28 LOAD_FAST                1 (b)
   30 CALL_FUNCTION            3
   32 RETURN_VALUE

   MODIFIED BYTECODE resume_in_fn script.py line 6
    0 LOAD_GLOBAL              1 (__compiled_fn_2)
    2 LOAD_FAST                2 (b)
    4 LOAD_FAST                1 (a)
    6 CALL_FUNCTION            2
    8 UNPACK_SEQUENCE          1
   10 RETURN_VALUE

يمكننا أن نرى أن بايت كود المعدل منقسم إلى دالتين، ``fn``، والدالة الأصلية، ودالة تسمى ``resume_in_fn``. هذه الدالة الثانية هي دالة تم إنشاؤها بواسطة Dynamo لتنفيذ تنفيذ البرنامج بدءًا من كسر المخطط. يُطلق على هذا غالبًا اسم `دالة الاستمرار <https://en.wikipedia.org/wiki/Continuation>`__. تقوم دالة الاستمرار هذه ببساطة باستدعاء الدالة المترجمة الثانية باستخدام الحجج الصحيحة. تتم إعادة كتابة كود الدالة الأولية لتنفيذ الاستراتيجية التي وصفناها سابقًا

-  L0-4. استدعاء الدالة المترجمة (``a + 2``).
-  L6. قم بتخزين نتيجتها في متغير محلي يسمى ``graph_out_0``. ``graph_out_0`` عبارة عن مجموعة
-  L8-18. اترك المكدس كما لو كان في نقطة كسر المخطط
-  L20. تنفيذ التعليمات البرمجية التي تسببت في كسر المخطط
-  L22-32. استدعاء دالة الاستمرار المترجمة (``a + b``)

يتم تفويض توليد المكدس في Dynamo إلى فئات ``VariableTracker`` الفرعية. تحتوي كل كائن ``VariableTracker`` في Dynamo على طريقة `reconstruct <https://github.com/pytorch/pytorch/blob/e891a3bba9f05697d72776f6e89347231a141f03/torch/_dynamo/variables/lists.py#L307-L309>`__ تقوم بتوليد بايت كود اللازم لإنشاء كائن Python الذي تمثله على المكدس.

**نصيحة التصحيح**. تعرقل كسور المخطط الأداء، وبالتالي، من الأفضل تجنبها. يعد تشغيل برنامج باستخدام ``TORCH_LOGS=graph_breaks`` طريقة رائعة لمعرفة عدد كسور المخطط التي أصابت برنامجنا. تُرجع المعلومات التي تم الحصول عليها من حيث كائنات ``VariableTracker``، لذا فإن نصائح التصحيح المذكورة أعلاه مفيدة أحيانًا أيضًا لمعرفة ما تسبب في كسر المخطط.

الخاتمة
----------

Dynamo عبارة عن قطعة معقدة من البرامج. بمجرد أن تقرر تنفيذ مفسر CPython، فأنت تعلم أنك ستحصل على رحلة. ومع ذلك، نأمل أن تساعد هذه المقالة في توضيحها قليلاً.

يتم تنفيذ Dynamo (معظمها) في Python. لقد تركنا الكثير من الروابط إلى قطع الكود التي ناقشناها. نأمل أن يساعد قراءة هذه القطع من الكود والبحث عن الأماكن التي تستدعيها، أو وضع نقاط توقف عليها والنظر في مكدس الاستدعاءات، في فهم بقية قاعدة الكود.

بالطبع، أفضل طريقة لمعرفة كيفية عمل قطعة من البرامج هي عن طريق توسيعها. في هذه الحالة، فإن أفضل طريقة هي إلقاء نظرة على `قضايا dynamo المفتوحة على
github <https://github.com/pytorch/pytorch/issues?q=is%3Aissue+is%3Aopen+label%3A%22module%3A+dynamo%22+>`__. يتطلب الكثير منها تغييرات طفيفة للغاية في الكود، بمجرد أن تعرف المكان الذي تحتاج إلى إجراء هذه التغييرات فيه.

الحواشي
---------

.. [1] في الأدبيات، يطلق على هذا اسم الرسم البياني الموجه غير الدوري (DAG).

.. [2] يعيش كل هذا الكود الملزم في ``torch/csrc/dynamo/eval_frame.c``.

.. [3] في لغة CPython، يطلق على مجموعة جميع هذه الكائنات اسم `إطار <https://github.com/python/cpython/blob/f26bfe4b25f7e5a4f68fcac26207b7175abad208/Include/internal/pycore_frame.h#L57-L71>`__.

.. [4] هناك أيضًا فئات ``SymBool`` و ``SymFloat``. لا يتم استخدام الأخير كثيرًا في وقت كتابة هذا التقرير.

.. [5] من المثير للاهتمام أنه يفهم تعليمات برمجية NumPy! الق نظرة على `هذه التدوينة <https://pytorch.org/blog/compiling-numpy-code/>`__
   و `الوثائق <https://pytorch.org/docs/main/torch.compiler_faq.html#does-numpy-work-with-torch-compile>`__.
   الآن، هذا ممكن فقط لأننا قمنا بإعادة تنفيذ NumPy باستخدام PyTorch. حظا سعيدا في تنفيذ Django في PyTorch على الرغم من...

.. [6] بافتراض وجود قطعة واحدة فقط من التعليمات البرمجية المشكلة. إذا كان هناك المزيد، فيمكن لـ Dynamo تقسيم التعليمات البرمجية إلى أكبر عدد ممكن من المخططات التي يحتاجها.