torch.utils.mobile_optimizer
==============================

.. warning::
    هذا الـ API هو إصدار تجريبي Beta وقد يتغير في المستقبل القريب.

يدعم Torch mobile الأداة المساعدة "torch.utils.mobile_optimizer.optimize_for_mobile" لتشغيل قائمة من عمليات التحسين مع الوحدات النمطية في وضع التقييم.
تأخذ الطريقة المعلمات التالية: كائن torch.jit.ScriptModule، ومجموعة تحسين blocklisting، وقائمة بالطرق المحفوظة، و backend.

بالنسبة لـ CPU Backend، بشكل افتراضي، إذا كانت قائمة حظر التحسين (blocklist) فارغة أو None، فسيقوم "optimize_for_mobile" بتشغيل التحسينات التالية:
    - **دمج Conv2D و BatchNorm** (خيار حظر blocklisting `mobile_optimizer.MobileOptimizerType.CONV_BN_FUSION`): تقوم عملية التحسين هذه بطي "Conv2d-BatchNorm2d" إلى "Conv2d" في طريقة "forward" لهذه الوحدة النمطية وجميع وحداتها الفرعية. ويتم تحديث وزن وتحيز "Conv2d" بشكل مناظر.
    - **إدراج وطي العمليات المعبأة مسبقًا** (خيار حظر blocklisting `mobile_optimizer.MobileOptimizerType.INSERT_FOLD_PREPACK_OPS`): تقوم عملية التحسين هذه بإعادة كتابة الرسم البياني لاستبدال عمليات الضرب المعقدة 2D وعمليات الضرب الخطي بنظيراتها المعبأة مسبقًا. العمليات المعبأة مسبقًا هي عمليات ذات حالة، بمعنى أنها تتطلب بعض الحالات ليتم إنشاؤها، مثل تعبئة الوزن واستخدام هذه الحالة، أي الأوزان المعبأة مسبقًا، أثناء تنفيذ العملية. XNNPACK هو أحد backends التي توفر عمليات معبأة مسبقًا، مع نوى محسّنة لمنصات الأجهزة المحمولة (مثل معالجات ARM). يسمح تعبئة الوزن بالوصول إلى الذاكرة بكفاءة، وبالتالي تنفيذ نواة أسرع. في الوقت الحالي، تعيد عملية "optimize_for_mobile" كتابة الرسم البياني لاستبدال "Conv2D/Linear" بـ 1) عملية تعبئة الوزن لعمليات الضرب المعقدة 2D/linear في XNNPACK و 2) عملية تأخذ الوزن المعبأ مسبقًا والتنشيط كمدخلات وتولد تنشيطات الإخراج. نظرًا لأنه يلزم تنفيذ (1) مرة واحدة فقط، فإننا نطوي تعبئة الوزن بحيث يتم إجراؤها مرة واحدة فقط عند تحميل النموذج. تقوم هذه العملية من "optimize_for_mobile" بـ 1 و 2 ثم تطوي، أي إزالة، عمليات تعبئة الوزن.
    - **دمج ReLU/Hardtanh**: تدعم عمليات XNNPACK دمج التقييد. أي أن تقييد تنشيط الإخراج يتم كجزء من النواة، بما في ذلك نوى الضرب المعقدة 2D والضرب الخطي. وبالتالي، فإن التقييد يكون مجانيًا بالفعل. وبالتالي، يمكن دمج أي عملية يمكن التعبير عنها كعملية تقييد، مثل "ReLU" أو "hardtanh"، مع عملية "Conv2D" أو "linear" السابقة في XNNPACK. تقوم هذه العملية بإعادة كتابة الرسم البياني عن طريق البحث عن عمليات "ReLU/hardtanh" التي تتبع عمليات "Conv2D/linear" في XNNPACK، والتي تمت كتابتها بواسطة المرور السابق، ودمجها معًا.
    - **إزالة Dropout** (خيار حظر blocklisting `mobile_optimizer.MobileOptimizerType.REMOVE_DROPOUT`): تقوم عملية التحسين هذه بإزالة عقد "dropout" و "dropout_" من هذه الوحدة النمطية عندما يكون التدريب false.
    - **رفع المعلمات المجمعة للضرب المعقدة** (خيار حظر blocklisting `mobile_optimizer.MobileOptimizerType.HOIST_CONV_PACKED_PARAMS`): تقوم عملية التحسين هذه بنقل المعلمات المجمعة للضرب المعقدة إلى الوحدة النمطية الجذرية، بحيث يمكن حذف هياكل الضرب المعقدة. وهذا يقلل من حجم النموذج دون التأثير على القيم العددية.
    - **دمج Add/ReLU** (خيار حظر blocklisting `mobile_optimizer.MobileOptimizerType.FUSE_ADD_RELU`): تقوم هذه العملية بالبحث عن مثيلات عمليات "relu" التي تتبع عمليات "add" ودمجها في عملية "add_relu" واحدة.

بالنسبة لـ Vulkan Backend، بشكل افتراضي، إذا كانت قائمة حظر التحسين (blocklist) فارغة أو None، فسيقوم "optimize_for_mobile" بتشغيل التحسين التالي:
    - **النقل التلقائي إلى وحدة معالجة الرسوميات GPU** (خيار حظر blocklisting `mobile_optimizer.MobileOptimizerType.VULKAN_AUTOMATIC_GPU_TRANSFER`): تقوم عملية التحسين هذه بإعادة كتابة الرسم البياني بحيث يصبح نقل بيانات الإدخال والإخراج إلى وحدة معالجة الرسوميات GPU ومنها جزءًا من النموذج.

سيقوم "optimize_for_mobile" أيضًا باستدعاء تمرير freeze_module الذي يحافظ فقط على طريقة "forward". إذا كان لديك طريقة أخرى تحتاج إلى الحفاظ عليها، فقم بإضافتها إلى قائمة الطرق المحفوظة ومررها إلى الطريقة.

.. currentmodule:: torch.utils.mobile_optimizer
.. autofunction:: optimize_for_mobile