جهاز "ميتا"
===============

جهاز "ميتا" هو جهاز مجرد يشير إلى مصفوفة تسجل البيانات الوصفية فقط، دون أي بيانات فعلية. وللمصفوفات الميتا حالتا استخدام رئيسيتان:

* يمكن تحميل النماذج على جهاز الميتا، مما يسمح بتحميل تمثيل للنماذج دون تحميل المعلمات الفعلية في الذاكرة. يمكن أن يكون هذا مفيدًا إذا كنت بحاجة إلى إجراء تحويلات على النموذج قبل تحميل البيانات الفعلية.

* يمكن تنفيذ معظم العمليات على المصفوفات الميتا، مما ينتج عنه مصفوفات ميتا جديدة تصف النتيجة كما لو كنت قد أجريت العملية على مصفوفة حقيقية. يمكنك استخدام هذا لإجراء تحليل مجرد دون الحاجة إلى إنفاق الوقت على الحوسبة أو المساحة لتمثيل المصفوفات الفعلية. نظرًا لأن المصفوفات الميتا لا تحتوي على بيانات حقيقية، فلا يمكنك إجراء عمليات تعتمد على البيانات مثل :func:`torch.nonzero` أو :meth:`~torch.Tensor.item`. في بعض الحالات، لا تحتوي جميع أنواع الأجهزة (مثل CPU وCUDA) على نفس بيانات التعريف الإخراجية لعملية ما؛ وعادة ما نفضل تمثيل سلوك CUDA بإخلاص في هذا الموقف.

.. warning::

    على الرغم من أنه من الناحية النظرية، يجب أن يكون حساب المصفوفة الميتا أسرع دائمًا من الحساب المكافئ لـ CPU/CUDA، إلا أن العديد من عمليات تنفيذ المصفوفة الميتا مكتوبة بلغة Python ولم يتم نقلها إلى C++ من أجل السرعة، لذا فقد تجد أنك تحصل على انخفاض مطلق في تأخير الإطار مع مصفوفات CPU الصغيرة.

عبارات للعمل مع المصفوفات الميتا
----------------------

يمكن تحميل كائن باستخدام :func:`torch.load` على جهاز الميتا عن طريق تحديد ``map_location='meta'``::

    >>> torch.save(torch.randn(2), 'foo.pt')
    >>> torch.load('foo.pt', map_location='meta')
    tensor(..., device='meta', size=(2,))

إذا كان لديك بعض التعليمات البرمجية التعسفية التي تقوم ببعض إنشاءات المصفوفة دون تحديد جهاز بشكل صريح، فيمكنك تجاوزه لإنشاء جهاز ميتا باستخدام مدير سياق :func:`torch.device`::

    >>> with torch.device('meta'):
    ...     print(torch.randn(30, 30))
    ...
    tensor(..., device='meta', size=(30, 30))

وهذا مفيد بشكل خاص في إنشاء وحدات NN، حيث لا يمكنك غالبًا تمرير جهاز بشكل صريح للتهيئة::

    >>> from torch.nn.modules import Linear
    >>> with torch.device('meta'):
    ...     print(Linear(20, 30))
    ...
    Linear(in_features=20, out_features=30, bias=True)

لا يمكنك تحويل مصفوفة ميتا مباشرة إلى مصفوفة CPU/CUDA، لأن مصفوفة الميتا لا تخزن أي بيانات ولا نعرف القيم الصحيحة للبيانات في المصفوفة الجديدة::

    >>> torch.ones(5, device='meta').to("cpu")
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    NotImplementedError: Cannot copy out of meta tensor; no data!

استخدم دالة مصنع مثل :func:`torch.empty_like` لتحديد كيفية ملء البيانات المفقودة.

تتوفر لدى وحدات NN طريقة ملاءمة :meth:`torch.nn.Module.to_empty` تسمح بنقل الوحدة إلى جهاز آخر، مع ترك جميع المعلمات غير المستهلة. من المتوقع أن تقوم بإعادة تهيئة المعلمات يدويًا::

    >>> from torch.nn.modules import Linear
    >>> with torch.device('meta'):
    ...     m = Linear(20, 30)
    >>> m.to_empty(device="cpu")
    Linear(in_features=20, out_features=30, bias=True)

يحتوي :mod:`torch._subclasses.meta_utils` على مرافق غير موثقة لإنشاء مصفوفة ميتا مكافئة مع درجة عالية من الدقة من مصفوفة تنسر عشوائية. هذه الواجهات البرمجية تجريبية وقد تتغير بطريقة غير متوافقة مع الإصدارات السابقة في أي وقت.