.. Fake tensor
   عربي: تنسور مزيف
=================

كود: `fake_tensor.py <https://github.com/pytorch/pytorch/blob/db4572dbf18f1cf50cf662547e272d3117063747/torch/_subclasses/fake_tensor.py>`_

الدافع
------

عند إجراء التقييم الرمزي لـ Dynamo وتمريرات المترجم، نريد غالبًا أن نتمكن من تشغيل عمليات tensor لفهم أحجام الإخراج/الأنواع/الأجهزة، دون تشغيل هذه العمليات بالفعل (أو حذف بيانات tensor الموجودة مسبقًا)، والتي ستكون أبطأ (إذا كنت تقوم بالكثير من الحسابات) وتستهلك الكثير من الذاكرة (من السيئ أن يحتاج مترجمك إلى استخدام ذاكرة GPU أثناء تجميع البرنامج). Tensor المزيف يشبه tensor الحقيقي من جميع النواحي، باستثناء أنه لا يحتوي فعليًا على أي بيانات. على سبيل المثال، عندما نقوم بالتتبع في Dynamo، يلزم تتبع التعليمات البرمجية لـ Tensor الخاصة بالمستخدم والإجابة عن الأسئلة المتعلقة بالوسيطات (على سبيل المثال، إذا قام المستخدم بتنفيذ عملية شرطية على tensor وسيطة). بدون tensor مزيفة، لن تكون لدينا معلومات دقيقة لهذه الاستعلامات.

وبالمثل، افترض أنك تريد تخزين البيانات الوصفية لـ tensor، على سبيل المثال، على عقدة IR FX (meta ['val']). بدلاً من ذلك، يمكنك تخزين tensor مزيف مباشرة على العقدة، والذي سيوفر لك جميع البيانات الوصفية التي تحتاجها لـ tensor، بما في ذلك الأشياء الدقيقة التي ربما لم تكن قد تعاملت معها (على سبيل المثال، علاقات التكرار).

العمل ذو الصلة
------------

- tensor ميتا هي tensor مع device='meta'. هذا هو في الواقع الكثير مما تريده لـ tensor المزيفة، ولكن لا تقوم tensors الميتا بوضع نماذج للأجهزة، وأحيانًا يختلف سلوك الخطوة باختلاف الجهاز، لذا يمكن أن تحصل tensors المزيفة حقًا على معلومات أكثر دقة بهذه الطريقة. أيضًا، تكون tensors الميتا "عالمية" (فهي موجودة بمفردها، تمامًا مثل وجود tensor CPU/CUDA بمفردها)، في حين أن tensors المزيفة محدودة النطاق إلى FakeTensorMode.

- تسمح لك فئة فرعية tensor بتصنيف فرعي لـ torch.Tensor وتخصيص سلوكها. يتم تنفيذ tensors المزيفة كفئة فرعية tensor؛ وهذا يعني أن معظم تنفيذها يعيش في Python! للحصول على أمثلة أبسط لفئات فرعية tensor، تحقق من `subclass_zoo <https://github.com/albanD/subclass_zoo/>`_.

- تسمح الأشكال الديناميكية بإنشاء tensors بأحجام رمزية بدلاً من الأحجام الملموسة فقط، ونشر هذه الأحجام بشكل رمزي عبر العمليات. تحتفظ الأشكال الديناميكية بالحالة في ShapeEnv، والتي ترتبط دائمًا بـ FakeTensorMode (لذا فإن tensors المزيفة مسؤولة أيضًا عن إدارة الأحجام الرمزية.) بشكل عام، عندما نقوم بتجميع subgraph مع PT2، يكون هناك سياق تتبع مرتبط بهذا التجميع، والذي يحتوي، من بين أشياء أخرى، على FakeTensorMode و (ربما) ShapeEnv.

البنية المعمارية العامة
--------------------

جميع tensors المزيفة مرتبطة بـ FakeTensorMode. لأن الاستخدام الأساسي لـ tensor المزيف هو إجراء تحليل على tensors الحقيقية، فإن سير العمل العام هو أن يكون لديك مجموعة من tensors الحقيقية، وتقوم بتخصيص FakeTensorMode، ثم تستخدم from_real_tensor لتحويل جميع تلك tensors الحقيقية إلى tensors مزيفة، ثم تقوم بأشياء على tensors المزيفة. على وجه الخصوص، يحتفظ FakeTensorMode بجدول تلميحات يقوم بشكل ثابت بتعيين tensors (والتخزين) إلى نفس التخزين. إذا قمت بإنشاء نسخة مزيفة من نفس tensor عدة مرات، فستحصل على نفس tensor المزيفة؛ إذا قمت بإنشاء نسخة مزيفة من tensor التي تتشابه مع tensor أخرى، فستحصل على tensor مزيفة تتشابه مع نفس التخزين المزيف. نظرًا لأن FakeTensors عبارة عن فئات فرعية tensor، إذا قمت بعمليات عليها، فستحصل تلقائيًا على tensor مزيف، ولكن بشكل عام، ستريد إجراء عمليات على tensors المزيفة (على سبيل المثال، إذا كنت تقوم بتشغيل تمريرة FX) مع FakeTensorMode النشطة؛ ما ستفعله عملية tensor هو تشغيل FakeTensorMode تلقائيًا ومحاولة مرة أخرى.

يتم تمثيل tensor المزيف كـ __torch_dispatch__ فئة فرعية tensor من tensor ميتا. وهذا يعني أن tensors المزيفة هي في الواقع tensors جهاز ميتا؛ ثم تستخدم هوكات القابلية للتوسعة، وتحديداً dispatch_device، للكذب بشأن الجهاز الفعلي لـ tensor. كان هذا أحد أكثر الأجزاء المعرضة للأخطاء في tensors المزيفة في الأيام الأولى: في بعض الأحيان، كانت tensors المزيفة جيدة جدًا في الكذب بشأن كونها CPU/CUDA، وما إلى ذلك، وكنت ستنتهي بـ kernel CPU يتم استدعاؤه مع tensor مزيف يحاول إلغاء الإشارة إلى مؤشر البيانات، والذي من الواضح أنه لن ينجح. إذا كنت تقوم بإنهاء عملك بشكل غير متوقع في كود tensor المزيف، فإن هذا هو أول شيء يجب عليك التحقق منه: هل تتبع المكدس C++ في kernel CPU (غير متوقع!) أو kernel ميتا (متوقع!) kernel ميتا يشبه kernel حقيقي، ولكنه يقوم فقط بتخصيص الإخراج، ولا يقوم بأي حسابات بيانات.

يجب أن تحدد فئة فرعية tensor كيفية تنفيذ عمليات مختلفة. فيما يلي الوصفة العامة لـ tensor المزيفة:

- قم بتشغيل kernel ميتا على tensors المزيفة المدخلة، مع إعادة تفسيرها على أنها tensors ميتا. يتم ذلك عبر مدير سياق سحري in_kernel_invocation_manager والذي يوجه PyTorch بالكامل لعرض tensors المزيفة على أنها tensors ميتا الأساسية، بدلاً من "فك" tensors المزيفة إلى tensors ميتا (tensor مزيف هو tensor ميتا). يتم تمثيل tensors المزيفة بهذه الطريقة لتجنب الحاجة إلى الاحتفاظ بمجموعتين من البيانات الوصفية (بيانات tensor الميتا الوصفية، وبيانات tensor المزيفة الوصفية)؛ تضمن علاقة "is a" وجود نسخة واحدة فقط من البيانات الوصفية.

- إذا كنت دالة مصنع، فستقوم بدلاً من ذلك باستدعاء دالة المصنع الأساسية مع device='meta'.

- قم بتحويل tensor الميتا الناتج إلى tensor مزيف، مع حساب الجهاز الذي يجب أن يكون عليه الإخراج (هذا عادة ما يكون بسيطًا، ولكنه ليس كذلك في بعض الأحيان، على سبيل المثال، الترقية المتصاعدة لـ CPU، أو عمليات تحويل الجهاز.)

واجهة برمجة التطبيقات: القطع المهمة
-----------------------

الاستخدام غير PT2 (تحقق من test/test_fake_tensor.py للحصول على مزيد من الأمثلة):

.. code:: python

    # إنشاء وضع مزيف
    من torch._subclasses.fake_tensor import FakeTensorMode
    fake_mode = FakeTensorMode()
    المحول = fake_mode.fake_tensor_converter
    # إنشاء نسخة مزيفة من بعض tensors الحقيقية
    fake_x = converter.from_real_tensor(fake_mode, x)
    مع fake_mode:
        # قم ببعض العمليات على tensors المزيفة
        fake_y = fake_x * 2
        # يتم تحويل عمليات المصنع تلقائيًا إلى نسخ مزيفة في مدير السياق
        fake_z = torch.empty(20)

س: لماذا لديك tensors حقيقية كمدخلات؟

ج: في سياق PT2، يرجع ذلك إلى أنك تقوم عادةً بالتجميع في الوقت المناسب، لذا بالنسبة لجميع المدخلات إلى graph الذي تقوم بتجميعه، لديك بالفعل "المدخلات الحقيقية"، لأنك تقوم بالتجميع أثناء تنفيذ البرنامج.

استخدام PT2 pre-AOTAutograd (هذا غير معتاد، وربما لا تريد القيام بذلك):

.. code:: python


    # وضع مزيف غير ممكن!
    من torch._guards استيراد detect_fake_mode
    fake_mode = detect_fake_mode(args)
    # إذا لم يكن fake_mode None
    المحول = fake_mode.fake_tensor_converter
    fake_args = [converter.from_real_tensor(fake_mode، arg) لـ arg في args]
    مع fake_mode:
    ... قم بأشياء مع args المزيفة، إذا لزم الأمر ...

سيقوم detect_fake_mode بالبحث في عدد من المواقع لمحاولة العثور على "وضع tensor المزيف" المرتبط بدورة الحياة. عادةً ما يتم سحبه من سياق التتبع.

استخدام PT2 post-AOTAutograd:

# تم تمكين الوضع المزيف! عادةً ما تكون example_inputs مزيفة بالفعل
# TODO: ربما نريد تغيير هذا
# لا يزال قم بذلك للوصول إلى الوضع المزيف
fake_mode = detect_fake_mode(example_inputs)
# ولكن بشكل عام، لا يلزم تشغيله

أشياء أخرى مفيدة:

.. code:: python

    من torch._subclasses.fake_tensor استيراد unset_fake_temporarily
    مع unset_fake_temporarily():
        # تم تعطيل الوضع المزيف هنا، يمكنك إجراء حسابات tensor الحقيقية

متى قد تريد تعطيل وضع tensor المزيف؟ عادةً لا تريد القيام بذلك. إحدى الحالات المتخصصة التي وجدنا أنها مفيدة هي تنفيذ انتشار الثوابت على tensors المزيفة: في هذه الحالة، يلزم إجراء بعض حسابات tensor الفعلية على الرغم من أننا في وضع tensor مزيف.

.. code:: python

    FakeTensorProp
    من torch.fx.passes.fake_tensor_prop
    gm: GraphModule
    real_inputs: List [Tensor]
    FakeTensorProp (gm).propagate (* real_inputs)
    # سيؤدي هذا إلى ملء البيانات الوصفية ['val'] على جميع عقد FX باستخدام tensor مزيف
    # أو إذا كان لديك وضع مزيف مسبقًا، فيجب عليك استخدامه
    FakeTensorProp (gm، mode=fake_mode).propagate (* real_inputs)
    # هناك أيضًا propagate_dont_convert_inputs إذا كانت مدخلاتك مزيفة بالفعل
    fake_inputs: List [FakeTensor]
    FakeTensorProp (gm، mode=fake_mode).propagate_dont_convert_inputs (* fake_inputs)

التفاصيل
-------

التحويل التلقائي أم لا؟
في الأصل، لن يقوم FakeTensorMode بتحويل tensors الحقيقية تلقائيًا إذا حاولت إجراء حسابات عليها داخل منطقة FakeTensorMode. كان الدافع وراء ذلك هو منع ما يلي:

.. code:: python

    مع FakeTensorMode():
    real_tensor.t_()

ماذا يجب أن يفعل هذا الكود؟ سيكون من المفاجئ إذا قمنا بالفعل بتعديل البيانات الوصفية على tensor الحقيقي. ولكن في الوقت نفسه، لا توجد فرصة واضحة لإنشاء FakeTensor. لذلك قررنا بحذر جعل هذا يرفع خطأ: "استدعاء المشغلين باستخدام مدخلات tensor غير مزيفة في FakeTensorMode غير مدعوم بعد. يرجى تحويل جميع tensors إلى FakeTensors أولاً."

هذا الخطأ مزعج للغاية في الممارسة العملية. على سبيل المثال، افترض أن لديك وحدة نمطية nn حقيقية وتريد إطعامها بـ tensors مزيفة. يلزمك بطريقة ما إنشاء نسخة مزيفة من الوحدة النمطية nn. وقد أدى هذا إلى FakeCopyMode.

في النهاية، استسلمنا وأضفنا التحويل التلقائي. ومع ذلك، لا يزال هذا غير ممكن بشكل افتراضي في العديد من استخدامات FakeTensorMode.

تحور البيانات الوصفية على tensor المزيف
إذا كان لديك tensor مزيف، وقمت بتعديله، فإن البيانات الوصفية على tensor المزيف تتغير. هذا معقول في حد ذاته، ولكن في بعض الأحيان تريد أيضًا تخزين tensors المزيفة كبيانات وصفية على عقد FX؛ تعديل tensor مزيف أمر سيء لأنه سيؤدي إلى إبطال البيانات الوصفية القديمة!

في الواقع، هناك توتر أساسي هنا، وهو أن tensors المزيفة تحتفظ ببيانات وصفية دقيقة للغاية حول tensors، بما في ذلك هوية الكائن. إذا تغيرت البيانات الوصفية للكائن بمرور الوقت في graph FX، فلا توجد في الواقع أي طريقة لتمثيل هذا التغيير بمرور الوقت. معظم الوقت، نقوم بتحليلات FX الخطيرة على الرسوم البيانية الوظيفية، والتي لا تحتوي على ذلك، ولكن في بعض الأحيان يلزم إجراء تحليل على graph غير وظيفي. ربما كان من الخطأ وضع tensor مزيف في meta ['val']

حول فئة فرعية tensor
-------------------------

يستخدم tensor المزيف كل من نمط الفئة الفرعية ونمط فئة فرعية وضع tensor، حيث يقوم FakeTensor.__torch_dispatch__ بتمكين FakeTensorMode المرتبط بـ tensor المزيف، ثم يعيد التوزيع (يعتمد على FakeTensorMode للقيام بالرفع الثقيل). إذا تلقت عمليات tensor المزيف حجة فئة فرعية لا تعترف بها، فستعيد NotImplemented، مما يمنح الفئة الفرعية الأخرى فرصة للتشغيل أولاً (من المأمول أن يتم تحويلها إلى عمليات tensor عادية)، قبل أن تحاول مرة أخرى. يمكن أن يسبب هذا حلقات لا نهائية.

كيف يتم تنفيذ كل مشغل فردي؟
--------------------------------------------

لسوء الحظ، هناك مجموعة معقدة إلى حد ما من الأماكن التي قد يتم فيها تنفيذ أي مشغل معين. فيما يلي بعض الحالات المهمة التي يجب معرفتها:

- تدعم فئات فرعية tensor انتشار ثابت محدود إذا كان عدد العناصر صغيرًا جدًا (يساعد هذا في التعامل مع بعض الحالات التي نقوم فيها على الفور باستدعاء item() على مثل هذه tensors.)
- لدينا بعض التطبيقات السريعة لبعض المشغلين، والتي يتم تنفيذها بالكامل في tensor المزيف، لأسباب تتعلق بالأداء.
- إذا كنت تستخدم @custom_op لإنشاء tensor مخصص، فسيتم تسجيل هذه المشغلات مباشرةً في tensor المزيف.
- يحتوي tensor المزيف نفسه على بعض الحالات الخاصة الثابتة لعمليات تحويل الجهاز.
- إذا لم يكن هناك تنفيذ ميتا ولا أي تحلل، فسنقوم بإنشاء tensors صفرية مملوءة ومحاولة تشغيل المشغل مباشرة لمعرفة ما ستكون عليه النتائج. يمكن أن يتسبب هذا في حدوث أخطاء segmentation إذا حاول المشغل إجراء الفهرسة باستخدام البيانات، لذا لا نقوم بتشغيله بشكل افتراضي للمشغلات المخصصة.

كيف يعمل المحول؟
----------------------------

نظرًا لأن tensors المزيفة تستخدم في المواقف التي تكون حساسة جدًا للخصائص الدقيقة لـ tensor، فإن tensors المزيفة تقوم بالتحويل بعناية، مع الحفاظ على leaf-ness، يتطلب_grad'ness، التكرار، ومجموعة كاملة من الخصائص الأخرى. يتم الجزء الأكبر من الرفع الثقيل في MetaConverter.

خصائص الأداء
هذا هو النص المترجم إلى اللغة العربية بتنسيق ReStructuredText:

---------------------------

قد تعتقد أن الأنسجة الزائفة سريعة لأنها لا تقوم بأي حسابات للأنسجة. ولكن في الواقع، نحن مقيدون تمامًا بالأعباء الزائدة عند التعامل مع أحجام صغيرة من الأنسجة، بالإضافة إلى أن الأنسجة الزائفة مكتوبة بلغة بايثون، وغالبًا ما نقوم بالكثير من العمل لإجراء عملية حسابية واحدة للأنسجة (لأنها مُنفذة على شكل تحليل). وبالتالي، فإن الأنسجة الزائفة بطيئة جدًا في الممارسة العملية، خاصة عند التعامل مع الأشكال الرمزية. هناك مساران سريعان مهمان نستخدمهما حاليًا في الأنسجة الزائفة ويحدثان فرقًا كبيرًا في الأداء:

- العمليات النقطية لا تمر عبر تفكيكات PrimTorch، بدلاً من ذلك، قمنا بترميز يدوي لقاعدة انتشارها.
- إذا أمكن، يجب علينا ذلك.

أنسجة زائفة للأنسجة الزائفة؟
----------------------------

هناك اهتمام بإرسال الأنسجة الزائفة كمدخلات من المستخدم إلى مكدس PT2، مما يعني أننا سنحتاج إلى القدرة على إنشاء أنسجة زائفة للأنسجة الزائفة. هذا غير مدعوم حاليًا، ولكن قد لا يكون من الصعب تنفيذه.

التفاعل مع الأشكال الديناميكية
-------------------------------

يحتوي كل وضع FakeTensorMode على ShapeEnv، والذي يتتبع جميع المعلومات المتعلقة بالأشكال الرمزية. عادة ما تكون دورات حياتها مرتبطة: فهي تعيش وتموت معًا.

نظرًا لأن FakeTensorMode يحتوي على ShapeEnv (على عكس التطبيقات الميتا)، فإن وظائف الميتا التي تعتمد على البيانات وتتطلب تخصيص SymInt غير مدعوم موجودة في الأنسجة الزائفة. كما تتولى الأنسجة الزائفة مسؤولية الاحتفاظ المؤقت لـ SymInts غير المدعومة، بحيث إذا قمت، على سبيل المثال، بالاستدعاء مرتين على نفس النسيج الزائف، فستحصل على نفس الحجم الرمزي.

موارد أخرى
---------------

`برنامج تعليمي على Colab حول استخدام FakeTensor لتحديد حجم الدفعة القصوى <https://colab.research.google.com/drive/1zjAisRrc8R6uixKsrs1DRm3lwz5MWN68>`_