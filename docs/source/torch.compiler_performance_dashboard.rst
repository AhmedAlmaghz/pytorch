لوحة أداء PyTorch 2.0
=======================

**المؤلف:** `Bin Bao <https://github.com/desertfire>`__ و `Huy Do <https://github.com/huydhn>`__

يتم تتبع أداء PyTorch 2.0 يوميًا على هذا `اللوحة <https://hud.pytorch.org/benchmark/compilers>`__.
تتم عمليات جمع الأداء على 12 عقدة GCP A100 كل ليلة. تحتوي كل عقدة على وحدة معالجة رسومات Nvidia A100 سعة 40 جيجابايت
ومعالج Intel Xeon بستة أنوية بسرعة 2.2 جيجاهرتز. يمكن العثور على ملف سير عمل CI المقابل
`هنا <https://github.com/pytorch/pytorch/blob/main/.github/workflows/inductor-perf-test-nightly.yml>`__.

كيفية قراءة اللوحة؟
----------------

تُظهر صفحة الهبوط جداول لأجنحة المعايير الثلاثة التي نقيسها، `` TorchBench ``، و `` Huggingface ``، و `` TIMM ``،
والرسوم البيانية لمجموعة معايير واحدة مع الإعداد الافتراضي. على سبيل المثال، تعرض الرسوم البيانية الافتراضية حاليًا اتجاه أداء AMP
في الأيام السبعة الماضية لـ `` TorchBench ``. يمكن تحديد قوائم التمرير في أعلى تلك الصفحة
لعرض الجداول والرسوم البيانية بخيارات مختلفة. بالإضافة إلى معدل النجاح، هناك 3 مقاييس أداء رئيسية يتم الإبلاغ عنها هناك: `` متوسط السرعة الهندسي ``،
"متوسط وقت التجميع"، ونسبة "ضغط ذروة استخدام الذاكرة".
يتم مقارنة كل من "متوسط السرعة الهندسي" و "نسبة ضغط ذروة استخدام الذاكرة"
بأداء PyTorch eager، وكلما كان ذلك أفضل. يمكن النقر فوق كل رقم أداء فردي في تلك الجداول،
والذي سيأخذك إلى طريقة عرض مع أرقام مفصلة لجميع الاختبارات في مجموعة المعايير المحددة تلك.

ماذا يتم قياسه على اللوحة؟
---------------------

جميع اختبارات اللوحة محددة في هذا
`الدالة <https://github.com/pytorch/pytorch/blob/3e18d3958be3dfcc36d3ef3c481f064f98ebeaf6/.ci/pytorch/test.sh#L305>`__.
تكون تكوينات الاختبار الدقيقة عرضة للتغيير، ولكن في الوقت الحالي، نقيس أداء الاستدلال والتدريب
مع دقة AMP في أجنحة المعايير الثلاثة. كما نقيس إعدادات مختلفة لـ TorchInductor،
بما في ذلك `` default ``، و `` with_cudagraphs (default + cudagraphs) ``، و `` dynamic (default + dynamic_shapes) ``.

هل يمكنني التحقق مما إذا كان PR الخاص بي يؤثر على أداء TorchInductor على اللوحة قبل الدمج؟
-----------------------------------------------------------------------

يمكن تشغيل لوحة القيادة الفردية يدويًا بالنقر فوق الزر "تشغيل سير العمل"
`هنا <https://github.com/pytorch/pytorch/actions/workflows/inductor-perf-test-nightly.yml>`__
وإرسالها مع فرع PR الخاص بك محددًا. سيبدأ هذا تشغيل لوحة كاملة بتنفيذ تغييراتك.
بمجرد الانتهاء من ذلك، يمكنك التحقق من النتائج عن طريق تحديد اسم الفرع ومعرف الالتزام المقابل
في واجهة مستخدم لوحة الأداء. كن على علم بأن هذا تشغيل CI مكلف. مع الموارد المحدودة، يرجى استخدام هذه الوظيفة بحكمة.

كيف يمكنني تشغيل أي اختبار للأداء محليًا؟
---------------------------------

يمكن العثور على سطور الأوامر الدقيقة المستخدمة أثناء تشغيل لوحة كاملة في سجلات أي تشغيل CI حديث.
`صفحة سير العمل <https://github.com/pytorch/pytorch/actions/workflows/inductor-perf-test-nightly.yml>`__
مكان جيد للبحث عن سجلات بعض التشغيلات الأخيرة.
في تلك السجلات، يمكنك البحث عن أسطر مثل
`` python benchmarks/dynamo/huggingface.py --performance --cold-start-latency --inference --amp --backend inductor --disable-cudagraphs --device cuda``
وتشغيلها محليًا إذا كان لديك وحدة معالجة رسومات (GPU) تعمل مع PyTorch 2.0.
سيقدم `` python benchmarks/dynamo/huggingface.py -h `` لك تفسيرًا مفصلاً لخيارات برنامج المعايير.